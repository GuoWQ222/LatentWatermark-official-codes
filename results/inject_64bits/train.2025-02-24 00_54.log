2025/02/24 00:54:29 INFO {
    "generator":{
        "ddim":{
            "S":50,
            "eta":0.0,
            "shape":[
                4,
                64,
                64
            ],
            "unconditional_guidance_scale":7.5
        },
        "device":"cuda:0",
        "mix_precision":{
            "fp16_scale_growth":0.001,
            "use_fp16":true
        },
        "model":{
            "kwargs":{
                "channels":4,
                "cond_stage_config":{
                    "params":{},
                    "type":"models.generators.stable_diffusion.encoders.modules.FrozenCLIPEmbedder"
                },
                "cond_stage_key":"txt",
                "cond_stage_trainable":false,
                "conditioning_key":"crossattn",
                "first_stage_config":{
                    "params":{
                        "ddconfig":{
                            "attn_resolutions":[],
                            "ch":128,
                            "ch_mult":[
                                1,
                                2,
                                4,
                                4
                            ],
                            "double_z":true,
                            "dropout":0.0,
                            "in_channels":3,
                            "num_res_blocks":2,
                            "out_ch":3,
                            "resolution":512,
                            "z_channels":4
                        },
                        "embed_dim":4,
                        "lossconfig":{
                            "params":{},
                            "type":"torch.nn.Identity"
                        },
                        "use_fp16":true
                    },
                    "type":"models.generators.stable_diffusion.autoencoder.AutoencoderKL"
                },
                "first_stage_key":"image",
                "image_size":64,
                "log_every_t":200,
                "num_timesteps_cond":1,
                "scale_factor":0.18215,
                "timesteps":1000,
                "unet_config":{
                    "params":{
                        "attention_resolutions":[
                            4,
                            2,
                            1
                        ],
                        "channel_mult":[
                            1,
                            2,
                            4,
                            4
                        ],
                        "context_dim":768,
                        "image_size":64,
                        "in_channels":4,
                        "legacy":false,
                        "model_channels":320,
                        "num_heads":8,
                        "num_res_blocks":2,
                        "out_channels":4,
                        "transformer_depth":1,
                        "use_fp16":true,
                        "use_spatial_transformer":true
                    },
                    "type":"models.generators.stable_diffusion.diffusionmodules.openaimodel.UNetModel"
                },
                "use_fp16":true
            },
            "type":"stable_diffusion"
        },
        "optimizer":{
            "kwargs":{
                "lr":1e-05,
                "weight_decay":0.0
            },
            "type":"AdamW"
        },
        "pretrain":{
            "optimizer":{
                "kwargs":{
                    "lr":0.001,
                    "weight_decay":0.0
                },
                "type":"AdamW"
            },
            "scheduler":{
                "decay":{
                    "kwargs":{
                        "step_size":2000
                    },
                    "type":"StepLR"
                }
            }
        },
        "scheduler":{
            "decay":{
                "kwargs":{
                    "milestones":[
                        25000
                    ]
                },
                "type":"MultiStepLR"
            }
        },
        "sd_ckpt":"./sd_ckpts/stable_diffusion_v1_4.pth"
    },
    "loss":{
        "device":"cuda:0",
        "msg_bit_loss":{
            "kwargs":{
                "mode":"regression"
            },
            "scale":2
        },
        "msg_lse_loss":{
            "kwargs":{},
            "scale":1
        },
        "recon_latent_l2_loss":{
            "kwargs":{},
            "scale":1.5
        },
        "recon_lpips_loss":{
            "kwargs":{},
            "scale":1
        }
    },
    "message_model":{
        "device":"cuda:0",
        "model":{
            "kwargs":{
                "bit_num":64,
                "enc_dim":4096,
                "latent_dim":4096,
                "mode":"regression"
            },
            "type":"NaiveMessageModel"
        },
        "optimizer":{
            "kwargs":{
                "lr":1e-05,
                "weight_decay":0.0
            },
            "type":"AdamW"
        },
        "pretrain":{
            "optimizer":{
                "kwargs":{
                    "lr":0.0001,
                    "weight_decay":0.0
                },
                "type":"AdamW"
            },
            "scheduler":{
                "decay":{
                    "kwargs":{
                        "step_size":4000
                    },
                    "type":"StepLR"
                }
            }
        },
        "scheduler":{
            "decay":{
                "kwargs":{
                    "milestones":[
                        12500
                    ]
                },
                "type":"MultiStepLR"
            }
        }
    },
    "task_cfg":{
        "generation_cfg":{
            "batch_size":8,
            "msg_path":"./datafiles/msg_64.npy",
            "num_per_class":1,
            "prompts":"./datafiles/coco_val_2017_captions.txt",
            "save_path":"./results/inject_64bits/images"
        },
        "log_path":"./results/inject_64bits",
        "running_epoch":1,
        "thr_eval":0,
        "thr_stage1":0.99,
        "thr_stage2":0.045,
        "thr_stage3":0.99
    },
    "training_data":{
        "dataloader":{
            "batch_size":2,
            "collate_fn":"collate_fn",
            "num_workers":0,
            "shuffle":true
        },
        "dataset":{
            "data_aug":{},
            "data_json":"./datafiles/captions_train2017.json",
            "preprocess":{
                "norm":{
                    "mean":0.5,
                    "std":0.5
                },
                "random_crop":{
                    "target_size":512
                },
                "rescale":{
                    "min_size":512
                }
            },
            "type":"InjectDataset"
        }
    }
}
2025/02/24 00:54:30 INFO Epoch 0: batch 0/0
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 1.0010 
2025/02/24 00:54:30 INFO Epoch 0: batch 1/1
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9967 
2025/02/24 00:54:30 INFO Epoch 0: batch 2/2
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 1.0015 
2025/02/24 00:54:30 INFO Epoch 0: batch 3/3
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9916 
2025/02/24 00:54:30 INFO Epoch 0: batch 4/4
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9933 
2025/02/24 00:54:30 INFO Epoch 0: batch 5/5
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9953 
2025/02/24 00:54:30 INFO Epoch 0: batch 6/6
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9831 
2025/02/24 00:54:30 INFO Epoch 0: batch 7/7
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9890 
2025/02/24 00:54:30 INFO Epoch 0: batch 8/8
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9717 
2025/02/24 00:54:30 INFO Epoch 0: batch 9/9
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9813 
2025/02/24 00:54:30 INFO Epoch 0: batch 10/10
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9600 
2025/02/24 00:54:30 INFO Epoch 0: batch 11/11
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9730 
2025/02/24 00:54:30 INFO Epoch 0: batch 12/12
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9698 
2025/02/24 00:54:30 INFO Epoch 0: batch 13/13
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9472 
2025/02/24 00:54:30 INFO Epoch 0: batch 14/14
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9571 
2025/02/24 00:54:30 INFO Epoch 0: batch 15/15
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9518 
2025/02/24 00:54:30 INFO Epoch 0: batch 16/16
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9785 
2025/02/24 00:54:30 INFO Epoch 0: batch 17/17
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9616 
2025/02/24 00:54:30 INFO Epoch 0: batch 18/18
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9061 
2025/02/24 00:54:30 INFO Epoch 0: batch 19/19
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9591 
2025/02/24 00:54:30 INFO Epoch 0: batch 20/20
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9190 
2025/02/24 00:54:30 INFO Epoch 0: batch 21/21
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9630 
2025/02/24 00:54:30 INFO Epoch 0: batch 22/22
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9349 
2025/02/24 00:54:30 INFO Epoch 0: batch 23/23
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9177 
2025/02/24 00:54:30 INFO Epoch 0: batch 24/24
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9432 
2025/02/24 00:54:30 INFO Epoch 0: batch 25/25
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9180 
2025/02/24 00:54:30 INFO Epoch 0: batch 26/26
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9198 
2025/02/24 00:54:30 INFO Epoch 0: batch 27/27
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9356 
2025/02/24 00:54:30 INFO Epoch 0: batch 28/28
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9480 
2025/02/24 00:54:30 INFO Epoch 0: batch 29/29
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8797 
2025/02/24 00:54:30 INFO Epoch 0: batch 30/30
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9004 
2025/02/24 00:54:30 INFO Epoch 0: batch 31/31
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9401 
2025/02/24 00:54:30 INFO Epoch 0: batch 32/32
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9292 
2025/02/24 00:54:30 INFO Epoch 0: batch 33/33
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9255 
2025/02/24 00:54:30 INFO Epoch 0: batch 34/34
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8107 
2025/02/24 00:54:30 INFO Epoch 0: batch 35/35
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8788 
2025/02/24 00:54:30 INFO Epoch 0: batch 36/36
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8814 
2025/02/24 00:54:30 INFO Epoch 0: batch 37/37
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8084 
2025/02/24 00:54:30 INFO Epoch 0: batch 38/38
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8521 
2025/02/24 00:54:30 INFO Epoch 0: batch 39/39
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8467 
2025/02/24 00:54:30 INFO Epoch 0: batch 40/40
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8782 
2025/02/24 00:54:30 INFO Epoch 0: batch 41/41
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9025 
2025/02/24 00:54:30 INFO Epoch 0: batch 42/42
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8855 
2025/02/24 00:54:30 INFO Epoch 0: batch 43/43
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9100 
2025/02/24 00:54:30 INFO Epoch 0: batch 44/44
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9021 
2025/02/24 00:54:30 INFO Epoch 0: batch 45/45
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.9161 
2025/02/24 00:54:30 INFO Epoch 0: batch 46/46
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8882 
2025/02/24 00:54:30 INFO Epoch 0: batch 47/47
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8463 
2025/02/24 00:54:30 INFO Epoch 0: batch 48/48
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7463 
2025/02/24 00:54:30 INFO Epoch 0: batch 49/49
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8821 
2025/02/24 00:54:30 INFO Epoch 0: batch 50/50
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8792 
2025/02/24 00:54:30 INFO Epoch 0: batch 51/51
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7996 
2025/02/24 00:54:30 INFO Epoch 0: batch 52/52
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8614 
2025/02/24 00:54:30 INFO Epoch 0: batch 53/53
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8189 
2025/02/24 00:54:30 INFO Epoch 0: batch 54/54
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8437 
2025/02/24 00:54:30 INFO Epoch 0: batch 55/55
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7368 
2025/02/24 00:54:30 INFO Epoch 0: batch 56/56
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7378 
2025/02/24 00:54:30 INFO Epoch 0: batch 57/57
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7879 
2025/02/24 00:54:30 INFO Epoch 0: batch 58/58
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8380 
2025/02/24 00:54:30 INFO Epoch 0: batch 59/59
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8311 
2025/02/24 00:54:30 INFO Epoch 0: batch 60/60
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8434 
2025/02/24 00:54:30 INFO Epoch 0: batch 61/61
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8107 
2025/02/24 00:54:30 INFO Epoch 0: batch 62/62
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8845 
2025/02/24 00:54:30 INFO Epoch 0: batch 63/63
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8762 
2025/02/24 00:54:30 INFO Epoch 0: batch 64/64
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8520 
2025/02/24 00:54:30 INFO Epoch 0: batch 65/65
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8045 
2025/02/24 00:54:30 INFO Epoch 0: batch 66/66
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7652 
2025/02/24 00:54:30 INFO Epoch 0: batch 67/67
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7582 
2025/02/24 00:54:30 INFO Epoch 0: batch 68/68
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7717 
2025/02/24 00:54:30 INFO Epoch 0: batch 69/69
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8728 
2025/02/24 00:54:30 INFO Epoch 0: batch 70/70
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8076 
2025/02/24 00:54:30 INFO Epoch 0: batch 71/71
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7800 
2025/02/24 00:54:30 INFO Epoch 0: batch 72/72
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8115 
2025/02/24 00:54:30 INFO Epoch 0: batch 73/73
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8259 
2025/02/24 00:54:30 INFO Epoch 0: batch 74/74
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7287 
2025/02/24 00:54:30 INFO Epoch 0: batch 75/75
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7988 
2025/02/24 00:54:30 INFO Epoch 0: batch 76/76
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8290 
2025/02/24 00:54:30 INFO Epoch 0: batch 77/77
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8098 
2025/02/24 00:54:30 INFO Epoch 0: batch 78/78
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8715 
2025/02/24 00:54:30 INFO Epoch 0: batch 79/79
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7463 
2025/02/24 00:54:30 INFO Epoch 0: batch 80/80
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7398 
2025/02/24 00:54:30 INFO Epoch 0: batch 81/81
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7552 
2025/02/24 00:54:30 INFO Epoch 0: batch 82/82
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8215 
2025/02/24 00:54:30 INFO Epoch 0: batch 83/83
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6713 
2025/02/24 00:54:30 INFO Epoch 0: batch 84/84
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7368 
2025/02/24 00:54:30 INFO Epoch 0: batch 85/85
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7508 
2025/02/24 00:54:30 INFO Epoch 0: batch 86/86
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8068 
2025/02/24 00:54:30 INFO Epoch 0: batch 87/87
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6678 
2025/02/24 00:54:30 INFO Epoch 0: batch 88/88
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7664 
2025/02/24 00:54:30 INFO Epoch 0: batch 89/89
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8177 
2025/02/24 00:54:30 INFO Epoch 0: batch 90/90
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7109 
2025/02/24 00:54:30 INFO Epoch 0: batch 91/91
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7071 
2025/02/24 00:54:30 INFO Epoch 0: batch 92/92
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7529 
2025/02/24 00:54:30 INFO Epoch 0: batch 93/93
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7644 
2025/02/24 00:54:30 INFO Epoch 0: batch 94/94
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.8009 
2025/02/24 00:54:30 INFO Epoch 0: batch 95/95
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6847 
2025/02/24 00:54:30 INFO Epoch 0: batch 96/96
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7484 
2025/02/24 00:54:30 INFO Epoch 0: batch 97/97
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6927 
2025/02/24 00:54:30 INFO Epoch 0: batch 98/98
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7858 
2025/02/24 00:54:30 INFO Epoch 0: batch 99/99
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7192 
2025/02/24 00:54:30 INFO Epoch 0: batch 100/100
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7389 
2025/02/24 00:54:30 INFO Epoch 0: batch 101/101
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6592 
2025/02/24 00:54:30 INFO Epoch 0: batch 102/102
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6631 
2025/02/24 00:54:30 INFO Epoch 0: batch 103/103
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6427 
2025/02/24 00:54:30 INFO Epoch 0: batch 104/104
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6845 
2025/02/24 00:54:30 INFO Epoch 0: batch 105/105
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7378 
2025/02/24 00:54:30 INFO Epoch 0: batch 106/106
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7032 
2025/02/24 00:54:30 INFO Epoch 0: batch 107/107
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7567 
2025/02/24 00:54:30 INFO Epoch 0: batch 108/108
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.5990 
2025/02/24 00:54:30 INFO Epoch 0: batch 109/109
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6757 
2025/02/24 00:54:30 INFO Epoch 0: batch 110/110
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7195 
2025/02/24 00:54:30 INFO Epoch 0: batch 111/111
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7462 
2025/02/24 00:54:30 INFO Epoch 0: batch 112/112
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7933 
2025/02/24 00:54:30 INFO Epoch 0: batch 113/113
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6685 
2025/02/24 00:54:30 INFO Epoch 0: batch 114/114
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6989 
2025/02/24 00:54:30 INFO Epoch 0: batch 115/115
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6812 
2025/02/24 00:54:30 INFO Epoch 0: batch 116/116
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6992 
2025/02/24 00:54:30 INFO Epoch 0: batch 117/117
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6921 
2025/02/24 00:54:30 INFO Epoch 0: batch 118/118
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6307 
2025/02/24 00:54:30 INFO Epoch 0: batch 119/119
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6860 
2025/02/24 00:54:30 INFO Epoch 0: batch 120/120
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6756 
2025/02/24 00:54:30 INFO Epoch 0: batch 121/121
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7403 
2025/02/24 00:54:30 INFO Epoch 0: batch 122/122
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6227 
2025/02/24 00:54:30 INFO Epoch 0: batch 123/123
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6541 
2025/02/24 00:54:30 INFO Epoch 0: batch 124/124
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7039 
2025/02/24 00:54:30 INFO Epoch 0: batch 125/125
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7441 
2025/02/24 00:54:30 INFO Epoch 0: batch 126/126
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6322 
2025/02/24 00:54:30 INFO Epoch 0: batch 127/127
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6141 
2025/02/24 00:54:30 INFO Epoch 0: batch 128/128
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6824 
2025/02/24 00:54:30 INFO Epoch 0: batch 129/129
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7176 
2025/02/24 00:54:30 INFO Epoch 0: batch 130/130
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7518 
2025/02/24 00:54:30 INFO Epoch 0: batch 131/131
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7089 
2025/02/24 00:54:30 INFO Epoch 0: batch 132/132
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7271 
2025/02/24 00:54:30 INFO Epoch 0: batch 133/133
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7172 
2025/02/24 00:54:30 INFO Epoch 0: batch 134/134
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.6186 
2025/02/24 00:54:30 INFO Epoch 0: batch 135/135
2025/02/24 00:54:30 INFO          m 0.00010 
2025/02/24 00:54:30 INFO          Training stage 1 Training_loss 0.7190 
2025/02/24 00:54:31 INFO Epoch 0: batch 136/136
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.7523 
2025/02/24 00:54:31 INFO Epoch 0: batch 137/137
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.7498 
2025/02/24 00:54:31 INFO Epoch 0: batch 138/138
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6512 
2025/02/24 00:54:31 INFO Epoch 0: batch 139/139
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6204 
2025/02/24 00:54:31 INFO Epoch 0: batch 140/140
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6395 
2025/02/24 00:54:31 INFO Epoch 0: batch 141/141
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5853 
2025/02/24 00:54:31 INFO Epoch 0: batch 142/142
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6898 
2025/02/24 00:54:31 INFO Epoch 0: batch 143/143
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5638 
2025/02/24 00:54:31 INFO Epoch 0: batch 144/144
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6300 
2025/02/24 00:54:31 INFO Epoch 0: batch 145/145
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6470 
2025/02/24 00:54:31 INFO Epoch 0: batch 146/146
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6467 
2025/02/24 00:54:31 INFO Epoch 0: batch 147/147
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5986 
2025/02/24 00:54:31 INFO Epoch 0: batch 148/148
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.7358 
2025/02/24 00:54:31 INFO Epoch 0: batch 149/149
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6318 
2025/02/24 00:54:31 INFO Epoch 0: batch 150/150
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5860 
2025/02/24 00:54:31 INFO Epoch 0: batch 151/151
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.7119 
2025/02/24 00:54:31 INFO Epoch 0: batch 152/152
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6967 
2025/02/24 00:54:31 INFO Epoch 0: batch 153/153
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6481 
2025/02/24 00:54:31 INFO Epoch 0: batch 154/154
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6350 
2025/02/24 00:54:31 INFO Epoch 0: batch 155/155
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6000 
2025/02/24 00:54:31 INFO Epoch 0: batch 156/156
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6830 
2025/02/24 00:54:31 INFO Epoch 0: batch 157/157
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5272 
2025/02/24 00:54:31 INFO Epoch 0: batch 158/158
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6128 
2025/02/24 00:54:31 INFO Epoch 0: batch 159/159
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6411 
2025/02/24 00:54:31 INFO Epoch 0: batch 160/160
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6018 
2025/02/24 00:54:31 INFO Epoch 0: batch 161/161
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5992 
2025/02/24 00:54:31 INFO Epoch 0: batch 162/162
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6157 
2025/02/24 00:54:31 INFO Epoch 0: batch 163/163
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5796 
2025/02/24 00:54:31 INFO Epoch 0: batch 164/164
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5817 
2025/02/24 00:54:31 INFO Epoch 0: batch 165/165
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5048 
2025/02/24 00:54:31 INFO Epoch 0: batch 166/166
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5581 
2025/02/24 00:54:31 INFO Epoch 0: batch 167/167
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5561 
2025/02/24 00:54:31 INFO Epoch 0: batch 168/168
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6038 
2025/02/24 00:54:31 INFO Epoch 0: batch 169/169
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6103 
2025/02/24 00:54:31 INFO Epoch 0: batch 170/170
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6661 
2025/02/24 00:54:31 INFO Epoch 0: batch 171/171
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5805 
2025/02/24 00:54:31 INFO Epoch 0: batch 172/172
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5923 
2025/02/24 00:54:31 INFO Epoch 0: batch 173/173
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6462 
2025/02/24 00:54:31 INFO Epoch 0: batch 174/174
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5948 
2025/02/24 00:54:31 INFO Epoch 0: batch 175/175
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6081 
2025/02/24 00:54:31 INFO Epoch 0: batch 176/176
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4915 
2025/02/24 00:54:31 INFO Epoch 0: batch 177/177
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6169 
2025/02/24 00:54:31 INFO Epoch 0: batch 178/178
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6314 
2025/02/24 00:54:31 INFO Epoch 0: batch 179/179
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5433 
2025/02/24 00:54:31 INFO Epoch 0: batch 180/180
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5065 
2025/02/24 00:54:31 INFO Epoch 0: batch 181/181
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6416 
2025/02/24 00:54:31 INFO Epoch 0: batch 182/182
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5550 
2025/02/24 00:54:31 INFO Epoch 0: batch 183/183
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6844 
2025/02/24 00:54:31 INFO Epoch 0: batch 184/184
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6031 
2025/02/24 00:54:31 INFO Epoch 0: batch 185/185
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6075 
2025/02/24 00:54:31 INFO Epoch 0: batch 186/186
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5562 
2025/02/24 00:54:31 INFO Epoch 0: batch 187/187
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6431 
2025/02/24 00:54:31 INFO Epoch 0: batch 188/188
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5487 
2025/02/24 00:54:31 INFO Epoch 0: batch 189/189
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5777 
2025/02/24 00:54:31 INFO Epoch 0: batch 190/190
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6353 
2025/02/24 00:54:31 INFO Epoch 0: batch 191/191
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5317 
2025/02/24 00:54:31 INFO Epoch 0: batch 192/192
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5397 
2025/02/24 00:54:31 INFO Epoch 0: batch 193/193
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4945 
2025/02/24 00:54:31 INFO Epoch 0: batch 194/194
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5559 
2025/02/24 00:54:31 INFO Epoch 0: batch 195/195
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5421 
2025/02/24 00:54:31 INFO Epoch 0: batch 196/196
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5411 
2025/02/24 00:54:31 INFO Epoch 0: batch 197/197
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5439 
2025/02/24 00:54:31 INFO Epoch 0: batch 198/198
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6431 
2025/02/24 00:54:31 INFO Epoch 0: batch 199/199
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6200 
2025/02/24 00:54:31 INFO Epoch 0: batch 200/200
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4912 
2025/02/24 00:54:31 INFO Epoch 0: batch 201/201
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5070 
2025/02/24 00:54:31 INFO Epoch 0: batch 202/202
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4256 
2025/02/24 00:54:31 INFO Epoch 0: batch 203/203
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5364 
2025/02/24 00:54:31 INFO Epoch 0: batch 204/204
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4435 
2025/02/24 00:54:31 INFO Epoch 0: batch 205/205
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4942 
2025/02/24 00:54:31 INFO Epoch 0: batch 206/206
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6047 
2025/02/24 00:54:31 INFO Epoch 0: batch 207/207
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5317 
2025/02/24 00:54:31 INFO Epoch 0: batch 208/208
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5400 
2025/02/24 00:54:31 INFO Epoch 0: batch 209/209
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5492 
2025/02/24 00:54:31 INFO Epoch 0: batch 210/210
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4430 
2025/02/24 00:54:31 INFO Epoch 0: batch 211/211
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5750 
2025/02/24 00:54:31 INFO Epoch 0: batch 212/212
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5411 
2025/02/24 00:54:31 INFO Epoch 0: batch 213/213
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5222 
2025/02/24 00:54:31 INFO Epoch 0: batch 214/214
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5811 
2025/02/24 00:54:31 INFO Epoch 0: batch 215/215
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4543 
2025/02/24 00:54:31 INFO Epoch 0: batch 216/216
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4739 
2025/02/24 00:54:31 INFO Epoch 0: batch 217/217
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.6029 
2025/02/24 00:54:31 INFO Epoch 0: batch 218/218
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4598 
2025/02/24 00:54:31 INFO Epoch 0: batch 219/219
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5182 
2025/02/24 00:54:31 INFO Epoch 0: batch 220/220
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4396 
2025/02/24 00:54:31 INFO Epoch 0: batch 221/221
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4719 
2025/02/24 00:54:31 INFO Epoch 0: batch 222/222
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5902 
2025/02/24 00:54:31 INFO Epoch 0: batch 223/223
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5605 
2025/02/24 00:54:31 INFO Epoch 0: batch 224/224
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5809 
2025/02/24 00:54:31 INFO Epoch 0: batch 225/225
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5142 
2025/02/24 00:54:31 INFO Epoch 0: batch 226/226
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4419 
2025/02/24 00:54:31 INFO Epoch 0: batch 227/227
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4866 
2025/02/24 00:54:31 INFO Epoch 0: batch 228/228
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5536 
2025/02/24 00:54:31 INFO Epoch 0: batch 229/229
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4806 
2025/02/24 00:54:31 INFO Epoch 0: batch 230/230
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4820 
2025/02/24 00:54:31 INFO Epoch 0: batch 231/231
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5480 
2025/02/24 00:54:31 INFO Epoch 0: batch 232/232
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4582 
2025/02/24 00:54:31 INFO Epoch 0: batch 233/233
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4769 
2025/02/24 00:54:31 INFO Epoch 0: batch 234/234
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4903 
2025/02/24 00:54:31 INFO Epoch 0: batch 235/235
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5128 
2025/02/24 00:54:31 INFO Epoch 0: batch 236/236
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4457 
2025/02/24 00:54:31 INFO Epoch 0: batch 237/237
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5332 
2025/02/24 00:54:31 INFO Epoch 0: batch 238/238
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4509 
2025/02/24 00:54:31 INFO Epoch 0: batch 239/239
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5353 
2025/02/24 00:54:31 INFO Epoch 0: batch 240/240
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5360 
2025/02/24 00:54:31 INFO Epoch 0: batch 241/241
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5507 
2025/02/24 00:54:31 INFO Epoch 0: batch 242/242
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5102 
2025/02/24 00:54:31 INFO Epoch 0: batch 243/243
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4967 
2025/02/24 00:54:31 INFO Epoch 0: batch 244/244
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4609 
2025/02/24 00:54:31 INFO Epoch 0: batch 245/245
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4745 
2025/02/24 00:54:31 INFO Epoch 0: batch 246/246
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4783 
2025/02/24 00:54:31 INFO Epoch 0: batch 247/247
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4779 
2025/02/24 00:54:31 INFO Epoch 0: batch 248/248
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4191 
2025/02/24 00:54:31 INFO Epoch 0: batch 249/249
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4315 
2025/02/24 00:54:31 INFO Epoch 0: batch 250/250
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4785 
2025/02/24 00:54:31 INFO Epoch 0: batch 251/251
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4969 
2025/02/24 00:54:31 INFO Epoch 0: batch 252/252
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4492 
2025/02/24 00:54:31 INFO Epoch 0: batch 253/253
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4145 
2025/02/24 00:54:31 INFO Epoch 0: batch 254/254
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4482 
2025/02/24 00:54:31 INFO Epoch 0: batch 255/255
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4879 
2025/02/24 00:54:31 INFO Epoch 0: batch 256/256
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4765 
2025/02/24 00:54:31 INFO Epoch 0: batch 257/257
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4039 
2025/02/24 00:54:31 INFO Epoch 0: batch 258/258
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4831 
2025/02/24 00:54:31 INFO Epoch 0: batch 259/259
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5433 
2025/02/24 00:54:31 INFO Epoch 0: batch 260/260
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5234 
2025/02/24 00:54:31 INFO Epoch 0: batch 261/261
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5429 
2025/02/24 00:54:31 INFO Epoch 0: batch 262/262
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3874 
2025/02/24 00:54:31 INFO Epoch 0: batch 263/263
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3958 
2025/02/24 00:54:31 INFO Epoch 0: batch 264/264
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4811 
2025/02/24 00:54:31 INFO Epoch 0: batch 265/265
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4347 
2025/02/24 00:54:31 INFO Epoch 0: batch 266/266
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5029 
2025/02/24 00:54:31 INFO Epoch 0: batch 267/267
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4744 
2025/02/24 00:54:31 INFO Epoch 0: batch 268/268
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4140 
2025/02/24 00:54:31 INFO Epoch 0: batch 269/269
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4233 
2025/02/24 00:54:31 INFO Epoch 0: batch 270/270
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4800 
2025/02/24 00:54:31 INFO Epoch 0: batch 271/271
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4095 
2025/02/24 00:54:31 INFO Epoch 0: batch 272/272
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4563 
2025/02/24 00:54:31 INFO Epoch 0: batch 273/273
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5068 
2025/02/24 00:54:31 INFO Epoch 0: batch 274/274
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3394 
2025/02/24 00:54:31 INFO Epoch 0: batch 275/275
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4004 
2025/02/24 00:54:31 INFO Epoch 0: batch 276/276
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4372 
2025/02/24 00:54:31 INFO Epoch 0: batch 277/277
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3982 
2025/02/24 00:54:31 INFO Epoch 0: batch 278/278
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4367 
2025/02/24 00:54:31 INFO Epoch 0: batch 279/279
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4471 
2025/02/24 00:54:31 INFO Epoch 0: batch 280/280
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4370 
2025/02/24 00:54:31 INFO Epoch 0: batch 281/281
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4461 
2025/02/24 00:54:31 INFO Epoch 0: batch 282/282
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4286 
2025/02/24 00:54:31 INFO Epoch 0: batch 283/283
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3928 
2025/02/24 00:54:31 INFO Epoch 0: batch 284/284
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3394 
2025/02/24 00:54:31 INFO Epoch 0: batch 285/285
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4378 
2025/02/24 00:54:31 INFO Epoch 0: batch 286/286
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4347 
2025/02/24 00:54:31 INFO Epoch 0: batch 287/287
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4612 
2025/02/24 00:54:31 INFO Epoch 0: batch 288/288
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3974 
2025/02/24 00:54:31 INFO Epoch 0: batch 289/289
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4659 
2025/02/24 00:54:31 INFO Epoch 0: batch 290/290
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4849 
2025/02/24 00:54:31 INFO Epoch 0: batch 291/291
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4583 
2025/02/24 00:54:31 INFO Epoch 0: batch 292/292
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.5414 
2025/02/24 00:54:31 INFO Epoch 0: batch 293/293
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4281 
2025/02/24 00:54:31 INFO Epoch 0: batch 294/294
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3038 
2025/02/24 00:54:31 INFO Epoch 0: batch 295/295
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3364 
2025/02/24 00:54:31 INFO Epoch 0: batch 296/296
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3925 
2025/02/24 00:54:31 INFO Epoch 0: batch 297/297
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3912 
2025/02/24 00:54:31 INFO Epoch 0: batch 298/298
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3428 
2025/02/24 00:54:31 INFO Epoch 0: batch 299/299
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3523 
2025/02/24 00:54:31 INFO Epoch 0: batch 300/300
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3698 
2025/02/24 00:54:31 INFO Epoch 0: batch 301/301
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4237 
2025/02/24 00:54:31 INFO Epoch 0: batch 302/302
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4209 
2025/02/24 00:54:31 INFO Epoch 0: batch 303/303
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4767 
2025/02/24 00:54:31 INFO Epoch 0: batch 304/304
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4705 
2025/02/24 00:54:31 INFO Epoch 0: batch 305/305
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3848 
2025/02/24 00:54:31 INFO Epoch 0: batch 306/306
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4223 
2025/02/24 00:54:31 INFO Epoch 0: batch 307/307
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4650 
2025/02/24 00:54:31 INFO Epoch 0: batch 308/308
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4176 
2025/02/24 00:54:31 INFO Epoch 0: batch 309/309
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4869 
2025/02/24 00:54:31 INFO Epoch 0: batch 310/310
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3298 
2025/02/24 00:54:31 INFO Epoch 0: batch 311/311
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4097 
2025/02/24 00:54:31 INFO Epoch 0: batch 312/312
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3854 
2025/02/24 00:54:31 INFO Epoch 0: batch 313/313
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3633 
2025/02/24 00:54:31 INFO Epoch 0: batch 314/314
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3819 
2025/02/24 00:54:31 INFO Epoch 0: batch 315/315
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3733 
2025/02/24 00:54:31 INFO Epoch 0: batch 316/316
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4158 
2025/02/24 00:54:31 INFO Epoch 0: batch 317/317
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4147 
2025/02/24 00:54:31 INFO Epoch 0: batch 318/318
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4245 
2025/02/24 00:54:31 INFO Epoch 0: batch 319/319
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3590 
2025/02/24 00:54:31 INFO Epoch 0: batch 320/320
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4026 
2025/02/24 00:54:31 INFO Epoch 0: batch 321/321
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3909 
2025/02/24 00:54:31 INFO Epoch 0: batch 322/322
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3888 
2025/02/24 00:54:31 INFO Epoch 0: batch 323/323
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4085 
2025/02/24 00:54:31 INFO Epoch 0: batch 324/324
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4162 
2025/02/24 00:54:31 INFO Epoch 0: batch 325/325
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3923 
2025/02/24 00:54:31 INFO Epoch 0: batch 326/326
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4048 
2025/02/24 00:54:31 INFO Epoch 0: batch 327/327
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3967 
2025/02/24 00:54:31 INFO Epoch 0: batch 328/328
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4050 
2025/02/24 00:54:31 INFO Epoch 0: batch 329/329
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3891 
2025/02/24 00:54:31 INFO Epoch 0: batch 330/330
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3727 
2025/02/24 00:54:31 INFO Epoch 0: batch 331/331
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3594 
2025/02/24 00:54:31 INFO Epoch 0: batch 332/332
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3915 
2025/02/24 00:54:31 INFO Epoch 0: batch 333/333
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2421 
2025/02/24 00:54:31 INFO Epoch 0: batch 334/334
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3166 
2025/02/24 00:54:31 INFO Epoch 0: batch 335/335
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3679 
2025/02/24 00:54:31 INFO Epoch 0: batch 336/336
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3261 
2025/02/24 00:54:31 INFO Epoch 0: batch 337/337
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3240 
2025/02/24 00:54:31 INFO Epoch 0: batch 338/338
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4022 
2025/02/24 00:54:31 INFO Epoch 0: batch 339/339
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3608 
2025/02/24 00:54:31 INFO Epoch 0: batch 340/340
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3198 
2025/02/24 00:54:31 INFO Epoch 0: batch 341/341
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4113 
2025/02/24 00:54:31 INFO Epoch 0: batch 342/342
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3865 
2025/02/24 00:54:31 INFO Epoch 0: batch 343/343
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3139 
2025/02/24 00:54:31 INFO Epoch 0: batch 344/344
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3020 
2025/02/24 00:54:31 INFO Epoch 0: batch 345/345
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2795 
2025/02/24 00:54:31 INFO Epoch 0: batch 346/346
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4087 
2025/02/24 00:54:31 INFO Epoch 0: batch 347/347
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3398 
2025/02/24 00:54:31 INFO Epoch 0: batch 348/348
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2793 
2025/02/24 00:54:31 INFO Epoch 0: batch 349/349
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3469 
2025/02/24 00:54:31 INFO Epoch 0: batch 350/350
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3123 
2025/02/24 00:54:31 INFO Epoch 0: batch 351/351
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3892 
2025/02/24 00:54:31 INFO Epoch 0: batch 352/352
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3157 
2025/02/24 00:54:31 INFO Epoch 0: batch 353/353
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3046 
2025/02/24 00:54:31 INFO Epoch 0: batch 354/354
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2973 
2025/02/24 00:54:31 INFO Epoch 0: batch 355/355
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3263 
2025/02/24 00:54:31 INFO Epoch 0: batch 356/356
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3815 
2025/02/24 00:54:31 INFO Epoch 0: batch 357/357
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2893 
2025/02/24 00:54:31 INFO Epoch 0: batch 358/358
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3602 
2025/02/24 00:54:31 INFO Epoch 0: batch 359/359
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3071 
2025/02/24 00:54:31 INFO Epoch 0: batch 360/360
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3389 
2025/02/24 00:54:31 INFO Epoch 0: batch 361/361
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3790 
2025/02/24 00:54:31 INFO Epoch 0: batch 362/362
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3132 
2025/02/24 00:54:31 INFO Epoch 0: batch 363/363
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2885 
2025/02/24 00:54:31 INFO Epoch 0: batch 364/364
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4599 
2025/02/24 00:54:31 INFO Epoch 0: batch 365/365
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.2667 
2025/02/24 00:54:31 INFO Epoch 0: batch 366/366
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3274 
2025/02/24 00:54:31 INFO Epoch 0: batch 367/367
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3154 
2025/02/24 00:54:31 INFO Epoch 0: batch 368/368
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3579 
2025/02/24 00:54:31 INFO Epoch 0: batch 369/369
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3518 
2025/02/24 00:54:31 INFO Epoch 0: batch 370/370
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3487 
2025/02/24 00:54:31 INFO Epoch 0: batch 371/371
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.4695 
2025/02/24 00:54:31 INFO Epoch 0: batch 372/372
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3076 
2025/02/24 00:54:31 INFO Epoch 0: batch 373/373
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3394 
2025/02/24 00:54:31 INFO Epoch 0: batch 374/374
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3376 
2025/02/24 00:54:31 INFO Epoch 0: batch 375/375
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3501 
2025/02/24 00:54:31 INFO Epoch 0: batch 376/376
2025/02/24 00:54:31 INFO          m 0.00010 
2025/02/24 00:54:31 INFO          Training stage 1 Training_loss 0.3121 
2025/02/24 00:54:32 INFO Epoch 0: batch 377/377
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3181 
2025/02/24 00:54:32 INFO Epoch 0: batch 378/378
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3505 
2025/02/24 00:54:32 INFO Epoch 0: batch 379/379
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2681 
2025/02/24 00:54:32 INFO Epoch 0: batch 380/380
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2783 
2025/02/24 00:54:32 INFO Epoch 0: batch 381/381
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3164 
2025/02/24 00:54:32 INFO Epoch 0: batch 382/382
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2895 
2025/02/24 00:54:32 INFO Epoch 0: batch 383/383
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3055 
2025/02/24 00:54:32 INFO Epoch 0: batch 384/384
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2448 
2025/02/24 00:54:32 INFO Epoch 0: batch 385/385
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2912 
2025/02/24 00:54:32 INFO Epoch 0: batch 386/386
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2670 
2025/02/24 00:54:32 INFO Epoch 0: batch 387/387
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3511 
2025/02/24 00:54:32 INFO Epoch 0: batch 388/388
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2872 
2025/02/24 00:54:32 INFO Epoch 0: batch 389/389
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3636 
2025/02/24 00:54:32 INFO Epoch 0: batch 390/390
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3186 
2025/02/24 00:54:32 INFO Epoch 0: batch 391/391
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2586 
2025/02/24 00:54:32 INFO Epoch 0: batch 392/392
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2485 
2025/02/24 00:54:32 INFO Epoch 0: batch 393/393
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2911 
2025/02/24 00:54:32 INFO Epoch 0: batch 394/394
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2277 
2025/02/24 00:54:32 INFO Epoch 0: batch 395/395
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3205 
2025/02/24 00:54:32 INFO Epoch 0: batch 396/396
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3268 
2025/02/24 00:54:32 INFO Epoch 0: batch 397/397
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2465 
2025/02/24 00:54:32 INFO Epoch 0: batch 398/398
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3199 
2025/02/24 00:54:32 INFO Epoch 0: batch 399/399
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2652 
2025/02/24 00:54:32 INFO Epoch 0: batch 400/400
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3772 
2025/02/24 00:54:32 INFO Epoch 0: batch 401/401
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3976 
2025/02/24 00:54:32 INFO Epoch 0: batch 402/402
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2593 
2025/02/24 00:54:32 INFO Epoch 0: batch 403/403
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2690 
2025/02/24 00:54:32 INFO Epoch 0: batch 404/404
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2822 
2025/02/24 00:54:32 INFO Epoch 0: batch 405/405
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2440 
2025/02/24 00:54:32 INFO Epoch 0: batch 406/406
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2588 
2025/02/24 00:54:32 INFO Epoch 0: batch 407/407
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2672 
2025/02/24 00:54:32 INFO Epoch 0: batch 408/408
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2917 
2025/02/24 00:54:32 INFO Epoch 0: batch 409/409
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3027 
2025/02/24 00:54:32 INFO Epoch 0: batch 410/410
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3296 
2025/02/24 00:54:32 INFO Epoch 0: batch 411/411
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3031 
2025/02/24 00:54:32 INFO Epoch 0: batch 412/412
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2668 
2025/02/24 00:54:32 INFO Epoch 0: batch 413/413
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2806 
2025/02/24 00:54:32 INFO Epoch 0: batch 414/414
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2922 
2025/02/24 00:54:32 INFO Epoch 0: batch 415/415
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3070 
2025/02/24 00:54:32 INFO Epoch 0: batch 416/416
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2938 
2025/02/24 00:54:32 INFO Epoch 0: batch 417/417
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3128 
2025/02/24 00:54:32 INFO Epoch 0: batch 418/418
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2858 
2025/02/24 00:54:32 INFO Epoch 0: batch 419/419
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2574 
2025/02/24 00:54:32 INFO Epoch 0: batch 420/420
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2822 
2025/02/24 00:54:32 INFO Epoch 0: batch 421/421
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2789 
2025/02/24 00:54:32 INFO Epoch 0: batch 422/422
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2549 
2025/02/24 00:54:32 INFO Epoch 0: batch 423/423
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2822 
2025/02/24 00:54:32 INFO Epoch 0: batch 424/424
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2622 
2025/02/24 00:54:32 INFO Epoch 0: batch 425/425
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3328 
2025/02/24 00:54:32 INFO Epoch 0: batch 426/426
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3316 
2025/02/24 00:54:32 INFO Epoch 0: batch 427/427
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2232 
2025/02/24 00:54:32 INFO Epoch 0: batch 428/428
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2441 
2025/02/24 00:54:32 INFO Epoch 0: batch 429/429
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2808 
2025/02/24 00:54:32 INFO Epoch 0: batch 430/430
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2913 
2025/02/24 00:54:32 INFO Epoch 0: batch 431/431
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2165 
2025/02/24 00:54:32 INFO Epoch 0: batch 432/432
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2490 
2025/02/24 00:54:32 INFO Epoch 0: batch 433/433
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2042 
2025/02/24 00:54:32 INFO Epoch 0: batch 434/434
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2770 
2025/02/24 00:54:32 INFO Epoch 0: batch 435/435
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2959 
2025/02/24 00:54:32 INFO Epoch 0: batch 436/436
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2867 
2025/02/24 00:54:32 INFO Epoch 0: batch 437/437
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2059 
2025/02/24 00:54:32 INFO Epoch 0: batch 438/438
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3208 
2025/02/24 00:54:32 INFO Epoch 0: batch 439/439
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3422 
2025/02/24 00:54:32 INFO Epoch 0: batch 440/440
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2936 
2025/02/24 00:54:32 INFO Epoch 0: batch 441/441
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2473 
2025/02/24 00:54:32 INFO Epoch 0: batch 442/442
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2408 
2025/02/24 00:54:32 INFO Epoch 0: batch 443/443
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2815 
2025/02/24 00:54:32 INFO Epoch 0: batch 444/444
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2535 
2025/02/24 00:54:32 INFO Epoch 0: batch 445/445
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2173 
2025/02/24 00:54:32 INFO Epoch 0: batch 446/446
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3041 
2025/02/24 00:54:32 INFO Epoch 0: batch 447/447
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3058 
2025/02/24 00:54:32 INFO Epoch 0: batch 448/448
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2711 
2025/02/24 00:54:32 INFO Epoch 0: batch 449/449
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3356 
2025/02/24 00:54:32 INFO Epoch 0: batch 450/450
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3120 
2025/02/24 00:54:32 INFO Epoch 0: batch 451/451
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2691 
2025/02/24 00:54:32 INFO Epoch 0: batch 452/452
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2783 
2025/02/24 00:54:32 INFO Epoch 0: batch 453/453
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2933 
2025/02/24 00:54:32 INFO Epoch 0: batch 454/454
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3169 
2025/02/24 00:54:32 INFO Epoch 0: batch 455/455
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2199 
2025/02/24 00:54:32 INFO Epoch 0: batch 456/456
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2211 
2025/02/24 00:54:32 INFO Epoch 0: batch 457/457
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2274 
2025/02/24 00:54:32 INFO Epoch 0: batch 458/458
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2669 
2025/02/24 00:54:32 INFO Epoch 0: batch 459/459
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3293 
2025/02/24 00:54:32 INFO Epoch 0: batch 460/460
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2319 
2025/02/24 00:54:32 INFO Epoch 0: batch 461/461
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2444 
2025/02/24 00:54:32 INFO Epoch 0: batch 462/462
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2969 
2025/02/24 00:54:32 INFO Epoch 0: batch 463/463
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2085 
2025/02/24 00:54:32 INFO Epoch 0: batch 464/464
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2700 
2025/02/24 00:54:32 INFO Epoch 0: batch 465/465
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1821 
2025/02/24 00:54:32 INFO Epoch 0: batch 466/466
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2408 
2025/02/24 00:54:32 INFO Epoch 0: batch 467/467
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2351 
2025/02/24 00:54:32 INFO Epoch 0: batch 468/468
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2486 
2025/02/24 00:54:32 INFO Epoch 0: batch 469/469
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2535 
2025/02/24 00:54:32 INFO Epoch 0: batch 470/470
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2859 
2025/02/24 00:54:32 INFO Epoch 0: batch 471/471
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2355 
2025/02/24 00:54:32 INFO Epoch 0: batch 472/472
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2849 
2025/02/24 00:54:32 INFO Epoch 0: batch 473/473
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2699 
2025/02/24 00:54:32 INFO Epoch 0: batch 474/474
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2713 
2025/02/24 00:54:32 INFO Epoch 0: batch 475/475
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2841 
2025/02/24 00:54:32 INFO Epoch 0: batch 476/476
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1935 
2025/02/24 00:54:32 INFO Epoch 0: batch 477/477
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2141 
2025/02/24 00:54:32 INFO Epoch 0: batch 478/478
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2666 
2025/02/24 00:54:32 INFO Epoch 0: batch 479/479
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2364 
2025/02/24 00:54:32 INFO Epoch 0: batch 480/480
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2473 
2025/02/24 00:54:32 INFO Epoch 0: batch 481/481
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2574 
2025/02/24 00:54:32 INFO Epoch 0: batch 482/482
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2500 
2025/02/24 00:54:32 INFO Epoch 0: batch 483/483
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2031 
2025/02/24 00:54:32 INFO Epoch 0: batch 484/484
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1606 
2025/02/24 00:54:32 INFO Epoch 0: batch 485/485
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2792 
2025/02/24 00:54:32 INFO Epoch 0: batch 486/486
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2212 
2025/02/24 00:54:32 INFO Epoch 0: batch 487/487
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2024 
2025/02/24 00:54:32 INFO Epoch 0: batch 488/488
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2438 
2025/02/24 00:54:32 INFO Epoch 0: batch 489/489
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1992 
2025/02/24 00:54:32 INFO Epoch 0: batch 490/490
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1989 
2025/02/24 00:54:32 INFO Epoch 0: batch 491/491
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2591 
2025/02/24 00:54:32 INFO Epoch 0: batch 492/492
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2721 
2025/02/24 00:54:32 INFO Epoch 0: batch 493/493
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1758 
2025/02/24 00:54:32 INFO Epoch 0: batch 494/494
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1744 
2025/02/24 00:54:32 INFO Epoch 0: batch 495/495
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2223 
2025/02/24 00:54:32 INFO Epoch 0: batch 496/496
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2140 
2025/02/24 00:54:32 INFO Epoch 0: batch 497/497
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2087 
2025/02/24 00:54:32 INFO Epoch 0: batch 498/498
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2350 
2025/02/24 00:54:32 INFO Epoch 0: batch 499/499
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1840 
2025/02/24 00:54:32 INFO Epoch 0: batch 500/500
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2503 
2025/02/24 00:54:32 INFO Epoch 0: batch 501/501
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1996 
2025/02/24 00:54:32 INFO Epoch 0: batch 502/502
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1875 
2025/02/24 00:54:32 INFO Epoch 0: batch 503/503
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2746 
2025/02/24 00:54:32 INFO Epoch 0: batch 504/504
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1979 
2025/02/24 00:54:32 INFO Epoch 0: batch 505/505
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2191 
2025/02/24 00:54:32 INFO Epoch 0: batch 506/506
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1941 
2025/02/24 00:54:32 INFO Epoch 0: batch 507/507
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1915 
2025/02/24 00:54:32 INFO Epoch 0: batch 508/508
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2323 
2025/02/24 00:54:32 INFO Epoch 0: batch 509/509
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2113 
2025/02/24 00:54:32 INFO Epoch 0: batch 510/510
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2209 
2025/02/24 00:54:32 INFO Epoch 0: batch 511/511
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2091 
2025/02/24 00:54:32 INFO Epoch 0: batch 512/512
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2617 
2025/02/24 00:54:32 INFO Epoch 0: batch 513/513
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.3288 
2025/02/24 00:54:32 INFO Epoch 0: batch 514/514
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2086 
2025/02/24 00:54:32 INFO Epoch 0: batch 515/515
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2384 
2025/02/24 00:54:32 INFO Epoch 0: batch 516/516
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2044 
2025/02/24 00:54:32 INFO Epoch 0: batch 517/517
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2208 
2025/02/24 00:54:32 INFO Epoch 0: batch 518/518
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1725 
2025/02/24 00:54:32 INFO Epoch 0: batch 519/519
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2052 
2025/02/24 00:54:32 INFO Epoch 0: batch 520/520
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1665 
2025/02/24 00:54:32 INFO Epoch 0: batch 521/521
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2002 
2025/02/24 00:54:32 INFO Epoch 0: batch 522/522
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1826 
2025/02/24 00:54:32 INFO Epoch 0: batch 523/523
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1968 
2025/02/24 00:54:32 INFO Epoch 0: batch 524/524
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2161 
2025/02/24 00:54:32 INFO Epoch 0: batch 525/525
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2397 
2025/02/24 00:54:32 INFO Epoch 0: batch 526/526
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1956 
2025/02/24 00:54:32 INFO Epoch 0: batch 527/527
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2705 
2025/02/24 00:54:32 INFO Epoch 0: batch 528/528
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2622 
2025/02/24 00:54:32 INFO Epoch 0: batch 529/529
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2775 
2025/02/24 00:54:32 INFO Epoch 0: batch 530/530
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1851 
2025/02/24 00:54:32 INFO Epoch 0: batch 531/531
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2025 
2025/02/24 00:54:32 INFO Epoch 0: batch 532/532
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1711 
2025/02/24 00:54:32 INFO Epoch 0: batch 533/533
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1445 
2025/02/24 00:54:32 INFO Epoch 0: batch 534/534
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1694 
2025/02/24 00:54:32 INFO Epoch 0: batch 535/535
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2185 
2025/02/24 00:54:32 INFO Epoch 0: batch 536/536
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2340 
2025/02/24 00:54:32 INFO Epoch 0: batch 537/537
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1914 
2025/02/24 00:54:32 INFO Epoch 0: batch 538/538
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2042 
2025/02/24 00:54:32 INFO Epoch 0: batch 539/539
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1585 
2025/02/24 00:54:32 INFO Epoch 0: batch 540/540
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2278 
2025/02/24 00:54:32 INFO Epoch 0: batch 541/541
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1914 
2025/02/24 00:54:32 INFO Epoch 0: batch 542/542
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1789 
2025/02/24 00:54:32 INFO Epoch 0: batch 543/543
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2318 
2025/02/24 00:54:32 INFO Epoch 0: batch 544/544
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1597 
2025/02/24 00:54:32 INFO Epoch 0: batch 545/545
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1971 
2025/02/24 00:54:32 INFO Epoch 0: batch 546/546
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1399 
2025/02/24 00:54:32 INFO Epoch 0: batch 547/547
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2034 
2025/02/24 00:54:32 INFO Epoch 0: batch 548/548
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1607 
2025/02/24 00:54:32 INFO Epoch 0: batch 549/549
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2136 
2025/02/24 00:54:32 INFO Epoch 0: batch 550/550
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1860 
2025/02/24 00:54:32 INFO Epoch 0: batch 551/551
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2014 
2025/02/24 00:54:32 INFO Epoch 0: batch 552/552
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1804 
2025/02/24 00:54:32 INFO Epoch 0: batch 553/553
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2092 
2025/02/24 00:54:32 INFO Epoch 0: batch 554/554
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1526 
2025/02/24 00:54:32 INFO Epoch 0: batch 555/555
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2016 
2025/02/24 00:54:32 INFO Epoch 0: batch 556/556
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1800 
2025/02/24 00:54:32 INFO Epoch 0: batch 557/557
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1877 
2025/02/24 00:54:32 INFO Epoch 0: batch 558/558
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1769 
2025/02/24 00:54:32 INFO Epoch 0: batch 559/559
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1975 
2025/02/24 00:54:32 INFO Epoch 0: batch 560/560
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1597 
2025/02/24 00:54:32 INFO Epoch 0: batch 561/561
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1625 
2025/02/24 00:54:32 INFO Epoch 0: batch 562/562
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2091 
2025/02/24 00:54:32 INFO Epoch 0: batch 563/563
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1762 
2025/02/24 00:54:32 INFO Epoch 0: batch 564/564
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1701 
2025/02/24 00:54:32 INFO Epoch 0: batch 565/565
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2299 
2025/02/24 00:54:32 INFO Epoch 0: batch 566/566
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1831 
2025/02/24 00:54:32 INFO Epoch 0: batch 567/567
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1381 
2025/02/24 00:54:32 INFO Epoch 0: batch 568/568
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1431 
2025/02/24 00:54:32 INFO Epoch 0: batch 569/569
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1669 
2025/02/24 00:54:32 INFO Epoch 0: batch 570/570
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1685 
2025/02/24 00:54:32 INFO Epoch 0: batch 571/571
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2291 
2025/02/24 00:54:32 INFO Epoch 0: batch 572/572
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1668 
2025/02/24 00:54:32 INFO Epoch 0: batch 573/573
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1916 
2025/02/24 00:54:32 INFO Epoch 0: batch 574/574
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1697 
2025/02/24 00:54:32 INFO Epoch 0: batch 575/575
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1978 
2025/02/24 00:54:32 INFO Epoch 0: batch 576/576
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1181 
2025/02/24 00:54:32 INFO Epoch 0: batch 577/577
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2387 
2025/02/24 00:54:32 INFO Epoch 0: batch 578/578
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1749 
2025/02/24 00:54:32 INFO Epoch 0: batch 579/579
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1425 
2025/02/24 00:54:32 INFO Epoch 0: batch 580/580
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1318 
2025/02/24 00:54:32 INFO Epoch 0: batch 581/581
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1129 
2025/02/24 00:54:32 INFO Epoch 0: batch 582/582
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1696 
2025/02/24 00:54:32 INFO Epoch 0: batch 583/583
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1701 
2025/02/24 00:54:32 INFO Epoch 0: batch 584/584
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1478 
2025/02/24 00:54:32 INFO Epoch 0: batch 585/585
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1177 
2025/02/24 00:54:32 INFO Epoch 0: batch 586/586
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1498 
2025/02/24 00:54:32 INFO Epoch 0: batch 587/587
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1879 
2025/02/24 00:54:32 INFO Epoch 0: batch 588/588
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1890 
2025/02/24 00:54:32 INFO Epoch 0: batch 589/589
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1755 
2025/02/24 00:54:32 INFO Epoch 0: batch 590/590
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1700 
2025/02/24 00:54:32 INFO Epoch 0: batch 591/591
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1530 
2025/02/24 00:54:32 INFO Epoch 0: batch 592/592
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1537 
2025/02/24 00:54:32 INFO Epoch 0: batch 593/593
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1324 
2025/02/24 00:54:32 INFO Epoch 0: batch 594/594
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1545 
2025/02/24 00:54:32 INFO Epoch 0: batch 595/595
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1393 
2025/02/24 00:54:32 INFO Epoch 0: batch 596/596
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1327 
2025/02/24 00:54:32 INFO Epoch 0: batch 597/597
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1558 
2025/02/24 00:54:32 INFO Epoch 0: batch 598/598
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1413 
2025/02/24 00:54:32 INFO Epoch 0: batch 599/599
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1765 
2025/02/24 00:54:32 INFO Epoch 0: batch 600/600
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1201 
2025/02/24 00:54:32 INFO Epoch 0: batch 601/601
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1320 
2025/02/24 00:54:32 INFO Epoch 0: batch 602/602
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1704 
2025/02/24 00:54:32 INFO Epoch 0: batch 603/603
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.2071 
2025/02/24 00:54:32 INFO Epoch 0: batch 604/604
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1625 
2025/02/24 00:54:32 INFO Epoch 0: batch 605/605
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1427 
2025/02/24 00:54:32 INFO Epoch 0: batch 606/606
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1355 
2025/02/24 00:54:32 INFO Epoch 0: batch 607/607
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1551 
2025/02/24 00:54:32 INFO Epoch 0: batch 608/608
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1354 
2025/02/24 00:54:32 INFO Epoch 0: batch 609/609
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1456 
2025/02/24 00:54:32 INFO Epoch 0: batch 610/610
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1659 
2025/02/24 00:54:32 INFO Epoch 0: batch 611/611
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1701 
2025/02/24 00:54:32 INFO Epoch 0: batch 612/612
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1472 
2025/02/24 00:54:32 INFO Epoch 0: batch 613/613
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1265 
2025/02/24 00:54:32 INFO Epoch 0: batch 614/614
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1527 
2025/02/24 00:54:32 INFO Epoch 0: batch 615/615
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1388 
2025/02/24 00:54:32 INFO Epoch 0: batch 616/616
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1819 
2025/02/24 00:54:32 INFO Epoch 0: batch 617/617
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1910 
2025/02/24 00:54:32 INFO Epoch 0: batch 618/618
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1381 
2025/02/24 00:54:32 INFO Epoch 0: batch 619/619
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1552 
2025/02/24 00:54:32 INFO Epoch 0: batch 620/620
2025/02/24 00:54:32 INFO          m 0.00010 
2025/02/24 00:54:32 INFO          Training stage 1 Training_loss 0.1599 
2025/02/24 00:54:33 INFO Epoch 0: batch 621/621
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1306 
2025/02/24 00:54:33 INFO Epoch 0: batch 622/622
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1498 
2025/02/24 00:54:33 INFO Epoch 0: batch 623/623
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1582 
2025/02/24 00:54:33 INFO Epoch 0: batch 624/624
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1250 
2025/02/24 00:54:33 INFO Epoch 0: batch 625/625
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1836 
2025/02/24 00:54:33 INFO Epoch 0: batch 626/626
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1474 
2025/02/24 00:54:33 INFO Epoch 0: batch 627/627
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1427 
2025/02/24 00:54:33 INFO Epoch 0: batch 628/628
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1690 
2025/02/24 00:54:33 INFO Epoch 0: batch 629/629
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1165 
2025/02/24 00:54:33 INFO Epoch 0: batch 630/630
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1174 
2025/02/24 00:54:33 INFO Epoch 0: batch 631/631
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1191 
2025/02/24 00:54:33 INFO Epoch 0: batch 632/632
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1395 
2025/02/24 00:54:33 INFO Epoch 0: batch 633/633
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1560 
2025/02/24 00:54:33 INFO Epoch 0: batch 634/634
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1222 
2025/02/24 00:54:33 INFO Epoch 0: batch 635/635
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1331 
2025/02/24 00:54:33 INFO Epoch 0: batch 636/636
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1227 
2025/02/24 00:54:33 INFO Epoch 0: batch 637/637
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1372 
2025/02/24 00:54:33 INFO Epoch 0: batch 638/638
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1593 
2025/02/24 00:54:33 INFO Epoch 0: batch 639/639
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1774 
2025/02/24 00:54:33 INFO Epoch 0: batch 640/640
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1718 
2025/02/24 00:54:33 INFO Epoch 0: batch 641/641
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1511 
2025/02/24 00:54:33 INFO Epoch 0: batch 642/642
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1172 
2025/02/24 00:54:33 INFO Epoch 0: batch 643/643
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1753 
2025/02/24 00:54:33 INFO Epoch 0: batch 644/644
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1417 
2025/02/24 00:54:33 INFO Epoch 0: batch 645/645
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1225 
2025/02/24 00:54:33 INFO Epoch 0: batch 646/646
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1715 
2025/02/24 00:54:33 INFO Epoch 0: batch 647/647
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1651 
2025/02/24 00:54:33 INFO Epoch 0: batch 648/648
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1930 
2025/02/24 00:54:33 INFO Epoch 0: batch 649/649
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1372 
2025/02/24 00:54:33 INFO Epoch 0: batch 650/650
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1630 
2025/02/24 00:54:33 INFO Epoch 0: batch 651/651
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1144 
2025/02/24 00:54:33 INFO Epoch 0: batch 652/652
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1310 
2025/02/24 00:54:33 INFO Epoch 0: batch 653/653
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1260 
2025/02/24 00:54:33 INFO Epoch 0: batch 654/654
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1308 
2025/02/24 00:54:33 INFO Epoch 0: batch 655/655
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1715 
2025/02/24 00:54:33 INFO Epoch 0: batch 656/656
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1148 
2025/02/24 00:54:33 INFO Epoch 0: batch 657/657
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1267 
2025/02/24 00:54:33 INFO Epoch 0: batch 658/658
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1113 
2025/02/24 00:54:33 INFO Epoch 0: batch 659/659
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1736 
2025/02/24 00:54:33 INFO Epoch 0: batch 660/660
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1289 
2025/02/24 00:54:33 INFO Epoch 0: batch 661/661
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1711 
2025/02/24 00:54:33 INFO Epoch 0: batch 662/662
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1306 
2025/02/24 00:54:33 INFO Epoch 0: batch 663/663
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1070 
2025/02/24 00:54:33 INFO Epoch 0: batch 664/664
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1512 
2025/02/24 00:54:33 INFO Epoch 0: batch 665/665
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1664 
2025/02/24 00:54:33 INFO Epoch 0: batch 666/666
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1188 
2025/02/24 00:54:33 INFO Epoch 0: batch 667/667
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1082 
2025/02/24 00:54:33 INFO Epoch 0: batch 668/668
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1011 
2025/02/24 00:54:33 INFO Epoch 0: batch 669/669
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0989 
2025/02/24 00:54:33 INFO Epoch 0: batch 670/670
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1752 
2025/02/24 00:54:33 INFO Epoch 0: batch 671/671
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:33 INFO Epoch 0: batch 672/672
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1095 
2025/02/24 00:54:33 INFO Epoch 0: batch 673/673
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1012 
2025/02/24 00:54:33 INFO Epoch 0: batch 674/674
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1711 
2025/02/24 00:54:33 INFO Epoch 0: batch 675/675
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1340 
2025/02/24 00:54:33 INFO Epoch 0: batch 676/676
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1517 
2025/02/24 00:54:33 INFO Epoch 0: batch 677/677
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1182 
2025/02/24 00:54:33 INFO Epoch 0: batch 678/678
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1117 
2025/02/24 00:54:33 INFO Epoch 0: batch 679/679
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1736 
2025/02/24 00:54:33 INFO Epoch 0: batch 680/680
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0945 
2025/02/24 00:54:33 INFO Epoch 0: batch 681/681
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1266 
2025/02/24 00:54:33 INFO Epoch 0: batch 682/682
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1203 
2025/02/24 00:54:33 INFO Epoch 0: batch 683/683
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1475 
2025/02/24 00:54:33 INFO Epoch 0: batch 684/684
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1161 
2025/02/24 00:54:33 INFO Epoch 0: batch 685/685
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1115 
2025/02/24 00:54:33 INFO Epoch 0: batch 686/686
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0927 
2025/02/24 00:54:33 INFO Epoch 0: batch 687/687
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1063 
2025/02/24 00:54:33 INFO Epoch 0: batch 688/688
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1361 
2025/02/24 00:54:33 INFO Epoch 0: batch 689/689
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1345 
2025/02/24 00:54:33 INFO Epoch 0: batch 690/690
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0800 
2025/02/24 00:54:33 INFO Epoch 0: batch 691/691
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1536 
2025/02/24 00:54:33 INFO Epoch 0: batch 692/692
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1302 
2025/02/24 00:54:33 INFO Epoch 0: batch 693/693
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1139 
2025/02/24 00:54:33 INFO Epoch 0: batch 694/694
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0997 
2025/02/24 00:54:33 INFO Epoch 0: batch 695/695
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1134 
2025/02/24 00:54:33 INFO Epoch 0: batch 696/696
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1118 
2025/02/24 00:54:33 INFO Epoch 0: batch 697/697
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1140 
2025/02/24 00:54:33 INFO Epoch 0: batch 698/698
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0989 
2025/02/24 00:54:33 INFO Epoch 0: batch 699/699
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1029 
2025/02/24 00:54:33 INFO Epoch 0: batch 700/700
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1482 
2025/02/24 00:54:33 INFO Epoch 0: batch 701/701
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1044 
2025/02/24 00:54:33 INFO Epoch 0: batch 702/702
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1256 
2025/02/24 00:54:33 INFO Epoch 0: batch 703/703
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0931 
2025/02/24 00:54:33 INFO Epoch 0: batch 704/704
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:33 INFO Epoch 0: batch 705/705
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1098 
2025/02/24 00:54:33 INFO Epoch 0: batch 706/706
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1359 
2025/02/24 00:54:33 INFO Epoch 0: batch 707/707
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1106 
2025/02/24 00:54:33 INFO Epoch 0: batch 708/708
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1009 
2025/02/24 00:54:33 INFO Epoch 0: batch 709/709
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1007 
2025/02/24 00:54:33 INFO Epoch 0: batch 710/710
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1000 
2025/02/24 00:54:33 INFO Epoch 0: batch 711/711
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1257 
2025/02/24 00:54:33 INFO Epoch 0: batch 712/712
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1038 
2025/02/24 00:54:33 INFO Epoch 0: batch 713/713
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1348 
2025/02/24 00:54:33 INFO Epoch 0: batch 714/714
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1385 
2025/02/24 00:54:33 INFO Epoch 0: batch 715/715
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1304 
2025/02/24 00:54:33 INFO Epoch 0: batch 716/716
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1373 
2025/02/24 00:54:33 INFO Epoch 0: batch 717/717
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0995 
2025/02/24 00:54:33 INFO Epoch 0: batch 718/718
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1095 
2025/02/24 00:54:33 INFO Epoch 0: batch 719/719
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1063 
2025/02/24 00:54:33 INFO Epoch 0: batch 720/720
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1663 
2025/02/24 00:54:33 INFO Epoch 0: batch 721/721
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1095 
2025/02/24 00:54:33 INFO Epoch 0: batch 722/722
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1180 
2025/02/24 00:54:33 INFO Epoch 0: batch 723/723
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0857 
2025/02/24 00:54:33 INFO Epoch 0: batch 724/724
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1243 
2025/02/24 00:54:33 INFO Epoch 0: batch 725/725
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1113 
2025/02/24 00:54:33 INFO Epoch 0: batch 726/726
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1064 
2025/02/24 00:54:33 INFO Epoch 0: batch 727/727
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1137 
2025/02/24 00:54:33 INFO Epoch 0: batch 728/728
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0974 
2025/02/24 00:54:33 INFO Epoch 0: batch 729/729
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0806 
2025/02/24 00:54:33 INFO Epoch 0: batch 730/730
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0933 
2025/02/24 00:54:33 INFO Epoch 0: batch 731/731
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1260 
2025/02/24 00:54:33 INFO Epoch 0: batch 732/732
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1407 
2025/02/24 00:54:33 INFO Epoch 0: batch 733/733
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1054 
2025/02/24 00:54:33 INFO Epoch 0: batch 734/734
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:33 INFO Epoch 0: batch 735/735
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0997 
2025/02/24 00:54:33 INFO Epoch 0: batch 736/736
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1109 
2025/02/24 00:54:33 INFO Epoch 0: batch 737/737
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1166 
2025/02/24 00:54:33 INFO Epoch 0: batch 738/738
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1002 
2025/02/24 00:54:33 INFO Epoch 0: batch 739/739
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:33 INFO Epoch 0: batch 740/740
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:33 INFO Epoch 0: batch 741/741
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0928 
2025/02/24 00:54:33 INFO Epoch 0: batch 742/742
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1185 
2025/02/24 00:54:33 INFO Epoch 0: batch 743/743
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1053 
2025/02/24 00:54:33 INFO Epoch 0: batch 744/744
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1185 
2025/02/24 00:54:33 INFO Epoch 0: batch 745/745
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:33 INFO Epoch 0: batch 746/746
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:33 INFO Epoch 0: batch 747/747
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:33 INFO Epoch 0: batch 748/748
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0816 
2025/02/24 00:54:33 INFO Epoch 0: batch 749/749
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0941 
2025/02/24 00:54:33 INFO Epoch 0: batch 750/750
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0977 
2025/02/24 00:54:33 INFO Epoch 0: batch 751/751
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0954 
2025/02/24 00:54:33 INFO Epoch 0: batch 752/752
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0871 
2025/02/24 00:54:33 INFO Epoch 0: batch 753/753
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:33 INFO Epoch 0: batch 754/754
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0974 
2025/02/24 00:54:33 INFO Epoch 0: batch 755/755
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0973 
2025/02/24 00:54:33 INFO Epoch 0: batch 756/756
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:33 INFO Epoch 0: batch 757/757
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0901 
2025/02/24 00:54:33 INFO Epoch 0: batch 758/758
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:33 INFO Epoch 0: batch 759/759
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1122 
2025/02/24 00:54:33 INFO Epoch 0: batch 760/760
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0876 
2025/02/24 00:54:33 INFO Epoch 0: batch 761/761
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1019 
2025/02/24 00:54:33 INFO Epoch 0: batch 762/762
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:33 INFO Epoch 0: batch 763/763
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:33 INFO Epoch 0: batch 764/764
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0962 
2025/02/24 00:54:33 INFO Epoch 0: batch 765/765
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:33 INFO Epoch 0: batch 766/766
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1243 
2025/02/24 00:54:33 INFO Epoch 0: batch 767/767
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1077 
2025/02/24 00:54:33 INFO Epoch 0: batch 768/768
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:33 INFO Epoch 0: batch 769/769
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0922 
2025/02/24 00:54:33 INFO Epoch 0: batch 770/770
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0988 
2025/02/24 00:54:33 INFO Epoch 0: batch 771/771
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0971 
2025/02/24 00:54:33 INFO Epoch 0: batch 772/772
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1052 
2025/02/24 00:54:33 INFO Epoch 0: batch 773/773
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0966 
2025/02/24 00:54:33 INFO Epoch 0: batch 774/774
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0881 
2025/02/24 00:54:33 INFO Epoch 0: batch 775/775
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:33 INFO Epoch 0: batch 776/776
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1070 
2025/02/24 00:54:33 INFO Epoch 0: batch 777/777
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1008 
2025/02/24 00:54:33 INFO Epoch 0: batch 778/778
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:33 INFO Epoch 0: batch 779/779
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:33 INFO Epoch 0: batch 780/780
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1099 
2025/02/24 00:54:33 INFO Epoch 0: batch 781/781
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1008 
2025/02/24 00:54:33 INFO Epoch 0: batch 782/782
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0886 
2025/02/24 00:54:33 INFO Epoch 0: batch 783/783
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:33 INFO Epoch 0: batch 784/784
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:33 INFO Epoch 0: batch 785/785
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:33 INFO Epoch 0: batch 786/786
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:33 INFO Epoch 0: batch 787/787
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:33 INFO Epoch 0: batch 788/788
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0935 
2025/02/24 00:54:33 INFO Epoch 0: batch 789/789
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:33 INFO Epoch 0: batch 790/790
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:33 INFO Epoch 0: batch 791/791
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:33 INFO Epoch 0: batch 792/792
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0861 
2025/02/24 00:54:33 INFO Epoch 0: batch 793/793
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1252 
2025/02/24 00:54:33 INFO Epoch 0: batch 794/794
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:33 INFO Epoch 0: batch 795/795
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:33 INFO Epoch 0: batch 796/796
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:33 INFO Epoch 0: batch 797/797
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:33 INFO Epoch 0: batch 798/798
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0897 
2025/02/24 00:54:33 INFO Epoch 0: batch 799/799
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1049 
2025/02/24 00:54:33 INFO Epoch 0: batch 800/800
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:33 INFO Epoch 0: batch 801/801
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:33 INFO Epoch 0: batch 802/802
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0960 
2025/02/24 00:54:33 INFO Epoch 0: batch 803/803
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0886 
2025/02/24 00:54:33 INFO Epoch 0: batch 804/804
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1052 
2025/02/24 00:54:33 INFO Epoch 0: batch 805/805
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0901 
2025/02/24 00:54:33 INFO Epoch 0: batch 806/806
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0921 
2025/02/24 00:54:33 INFO Epoch 0: batch 807/807
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0964 
2025/02/24 00:54:33 INFO Epoch 0: batch 808/808
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:33 INFO Epoch 0: batch 809/809
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:33 INFO Epoch 0: batch 810/810
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:33 INFO Epoch 0: batch 811/811
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1024 
2025/02/24 00:54:33 INFO Epoch 0: batch 812/812
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0982 
2025/02/24 00:54:33 INFO Epoch 0: batch 813/813
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:33 INFO Epoch 0: batch 814/814
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:33 INFO Epoch 0: batch 815/815
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:33 INFO Epoch 0: batch 816/816
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:33 INFO Epoch 0: batch 817/817
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:33 INFO Epoch 0: batch 818/818
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:33 INFO Epoch 0: batch 819/819
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:33 INFO Epoch 0: batch 820/820
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:33 INFO Epoch 0: batch 821/821
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0991 
2025/02/24 00:54:33 INFO Epoch 0: batch 822/822
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:33 INFO Epoch 0: batch 823/823
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:33 INFO Epoch 0: batch 824/824
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0967 
2025/02/24 00:54:33 INFO Epoch 0: batch 825/825
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1037 
2025/02/24 00:54:33 INFO Epoch 0: batch 826/826
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0936 
2025/02/24 00:54:33 INFO Epoch 0: batch 827/827
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:33 INFO Epoch 0: batch 828/828
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:33 INFO Epoch 0: batch 829/829
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:33 INFO Epoch 0: batch 830/830
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1073 
2025/02/24 00:54:33 INFO Epoch 0: batch 831/831
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:33 INFO Epoch 0: batch 832/832
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:33 INFO Epoch 0: batch 833/833
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:33 INFO Epoch 0: batch 834/834
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:33 INFO Epoch 0: batch 835/835
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:33 INFO Epoch 0: batch 836/836
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:33 INFO Epoch 0: batch 837/837
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:33 INFO Epoch 0: batch 838/838
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1018 
2025/02/24 00:54:33 INFO Epoch 0: batch 839/839
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1048 
2025/02/24 00:54:33 INFO Epoch 0: batch 840/840
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:33 INFO Epoch 0: batch 841/841
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:33 INFO Epoch 0: batch 842/842
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:33 INFO Epoch 0: batch 843/843
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0799 
2025/02/24 00:54:33 INFO Epoch 0: batch 844/844
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:33 INFO Epoch 0: batch 845/845
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0809 
2025/02/24 00:54:33 INFO Epoch 0: batch 846/846
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0936 
2025/02/24 00:54:33 INFO Epoch 0: batch 847/847
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:33 INFO Epoch 0: batch 848/848
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:33 INFO Epoch 0: batch 849/849
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:33 INFO Epoch 0: batch 850/850
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:33 INFO Epoch 0: batch 851/851
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:33 INFO Epoch 0: batch 852/852
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:33 INFO Epoch 0: batch 853/853
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:33 INFO Epoch 0: batch 854/854
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:33 INFO Epoch 0: batch 855/855
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0986 
2025/02/24 00:54:33 INFO Epoch 0: batch 856/856
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.1149 
2025/02/24 00:54:33 INFO Epoch 0: batch 857/857
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:33 INFO Epoch 0: batch 858/858
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0676 
2025/02/24 00:54:33 INFO Epoch 0: batch 859/859
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:33 INFO Epoch 0: batch 860/860
2025/02/24 00:54:33 INFO          m 0.00010 
2025/02/24 00:54:33 INFO          Training stage 1 Training_loss 0.0961 
2025/02/24 00:54:33 INFO Epoch 0: batch 861/861
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0577 
2025/02/24 00:54:34 INFO Epoch 0: batch 862/862
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0928 
2025/02/24 00:54:34 INFO Epoch 0: batch 863/863
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:34 INFO Epoch 0: batch 864/864
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:34 INFO Epoch 0: batch 865/865
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:34 INFO Epoch 0: batch 866/866
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0848 
2025/02/24 00:54:34 INFO Epoch 0: batch 867/867
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:34 INFO Epoch 0: batch 868/868
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0891 
2025/02/24 00:54:34 INFO Epoch 0: batch 869/869
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:34 INFO Epoch 0: batch 870/870
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:34 INFO Epoch 0: batch 871/871
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:34 INFO Epoch 0: batch 872/872
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:34 INFO Epoch 0: batch 873/873
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0626 
2025/02/24 00:54:34 INFO Epoch 0: batch 874/874
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0984 
2025/02/24 00:54:34 INFO Epoch 0: batch 875/875
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:34 INFO Epoch 0: batch 876/876
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:34 INFO Epoch 0: batch 877/877
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:34 INFO Epoch 0: batch 878/878
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:34 INFO Epoch 0: batch 879/879
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0527 
2025/02/24 00:54:34 INFO Epoch 0: batch 880/880
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:34 INFO Epoch 0: batch 881/881
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0853 
2025/02/24 00:54:34 INFO Epoch 0: batch 882/882
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0809 
2025/02/24 00:54:34 INFO Epoch 0: batch 883/883
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:34 INFO Epoch 0: batch 884/884
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0970 
2025/02/24 00:54:34 INFO Epoch 0: batch 885/885
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:34 INFO Epoch 0: batch 886/886
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:34 INFO Epoch 0: batch 887/887
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:34 INFO Epoch 0: batch 888/888
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:34 INFO Epoch 0: batch 889/889
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:34 INFO Epoch 0: batch 890/890
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:34 INFO Epoch 0: batch 891/891
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:34 INFO Epoch 0: batch 892/892
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:34 INFO Epoch 0: batch 893/893
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0523 
2025/02/24 00:54:34 INFO Epoch 0: batch 894/894
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:34 INFO Epoch 0: batch 895/895
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:34 INFO Epoch 0: batch 896/896
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:34 INFO Epoch 0: batch 897/897
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:34 INFO Epoch 0: batch 898/898
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1092 
2025/02/24 00:54:34 INFO Epoch 0: batch 899/899
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0907 
2025/02/24 00:54:34 INFO Epoch 0: batch 900/900
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1066 
2025/02/24 00:54:34 INFO Epoch 0: batch 901/901
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0912 
2025/02/24 00:54:34 INFO Epoch 0: batch 902/902
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0954 
2025/02/24 00:54:34 INFO Epoch 0: batch 903/903
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:34 INFO Epoch 0: batch 904/904
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0928 
2025/02/24 00:54:34 INFO Epoch 0: batch 905/905
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:34 INFO Epoch 0: batch 906/906
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0986 
2025/02/24 00:54:34 INFO Epoch 0: batch 907/907
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:34 INFO Epoch 0: batch 908/908
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:34 INFO Epoch 0: batch 909/909
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:34 INFO Epoch 0: batch 910/910
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0909 
2025/02/24 00:54:34 INFO Epoch 0: batch 911/911
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1061 
2025/02/24 00:54:34 INFO Epoch 0: batch 912/912
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:34 INFO Epoch 0: batch 913/913
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:34 INFO Epoch 0: batch 914/914
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:34 INFO Epoch 0: batch 915/915
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:34 INFO Epoch 0: batch 916/916
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0815 
2025/02/24 00:54:34 INFO Epoch 0: batch 917/917
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:34 INFO Epoch 0: batch 918/918
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0549 
2025/02/24 00:54:34 INFO Epoch 0: batch 919/919
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:34 INFO Epoch 0: batch 920/920
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0918 
2025/02/24 00:54:34 INFO Epoch 0: batch 921/921
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1058 
2025/02/24 00:54:34 INFO Epoch 0: batch 922/922
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0927 
2025/02/24 00:54:34 INFO Epoch 0: batch 923/923
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:34 INFO Epoch 0: batch 924/924
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0825 
2025/02/24 00:54:34 INFO Epoch 0: batch 925/925
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:34 INFO Epoch 0: batch 926/926
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:34 INFO Epoch 0: batch 927/927
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:34 INFO Epoch 0: batch 928/928
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0972 
2025/02/24 00:54:34 INFO Epoch 0: batch 929/929
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:34 INFO Epoch 0: batch 930/930
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:34 INFO Epoch 0: batch 931/931
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0959 
2025/02/24 00:54:34 INFO Epoch 0: batch 932/932
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:34 INFO Epoch 0: batch 933/933
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:34 INFO Epoch 0: batch 934/934
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:34 INFO Epoch 0: batch 935/935
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:34 INFO Epoch 0: batch 936/936
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:34 INFO Epoch 0: batch 937/937
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:34 INFO Epoch 0: batch 938/938
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0976 
2025/02/24 00:54:34 INFO Epoch 0: batch 939/939
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:34 INFO Epoch 0: batch 940/940
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1085 
2025/02/24 00:54:34 INFO Epoch 0: batch 941/941
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:34 INFO Epoch 0: batch 942/942
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:34 INFO Epoch 0: batch 943/943
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:34 INFO Epoch 0: batch 944/944
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1031 
2025/02/24 00:54:34 INFO Epoch 0: batch 945/945
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:34 INFO Epoch 0: batch 946/946
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:34 INFO Epoch 0: batch 947/947
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:34 INFO Epoch 0: batch 948/948
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:34 INFO Epoch 0: batch 949/949
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:34 INFO Epoch 0: batch 950/950
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:34 INFO Epoch 0: batch 951/951
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0910 
2025/02/24 00:54:34 INFO Epoch 0: batch 952/952
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1066 
2025/02/24 00:54:34 INFO Epoch 0: batch 953/953
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:34 INFO Epoch 0: batch 954/954
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0670 
2025/02/24 00:54:34 INFO Epoch 0: batch 955/955
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:34 INFO Epoch 0: batch 956/956
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:34 INFO Epoch 0: batch 957/957
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:34 INFO Epoch 0: batch 958/958
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0536 
2025/02/24 00:54:34 INFO Epoch 0: batch 959/959
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1053 
2025/02/24 00:54:34 INFO Epoch 0: batch 960/960
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0553 
2025/02/24 00:54:34 INFO Epoch 0: batch 961/961
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:34 INFO Epoch 0: batch 962/962
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:34 INFO Epoch 0: batch 963/963
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:34 INFO Epoch 0: batch 964/964
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:34 INFO Epoch 0: batch 965/965
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:34 INFO Epoch 0: batch 966/966
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:34 INFO Epoch 0: batch 967/967
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:34 INFO Epoch 0: batch 968/968
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0848 
2025/02/24 00:54:34 INFO Epoch 0: batch 969/969
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0981 
2025/02/24 00:54:34 INFO Epoch 0: batch 970/970
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:34 INFO Epoch 0: batch 971/971
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0871 
2025/02/24 00:54:34 INFO Epoch 0: batch 972/972
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:34 INFO Epoch 0: batch 973/973
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:34 INFO Epoch 0: batch 974/974
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:34 INFO Epoch 0: batch 975/975
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0982 
2025/02/24 00:54:34 INFO Epoch 0: batch 976/976
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:34 INFO Epoch 0: batch 977/977
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0995 
2025/02/24 00:54:34 INFO Epoch 0: batch 978/978
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1089 
2025/02/24 00:54:34 INFO Epoch 0: batch 979/979
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:34 INFO Epoch 0: batch 980/980
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:34 INFO Epoch 0: batch 981/981
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0544 
2025/02/24 00:54:34 INFO Epoch 0: batch 982/982
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0963 
2025/02/24 00:54:34 INFO Epoch 0: batch 983/983
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0881 
2025/02/24 00:54:34 INFO Epoch 0: batch 984/984
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:34 INFO Epoch 0: batch 985/985
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:34 INFO Epoch 0: batch 986/986
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:34 INFO Epoch 0: batch 987/987
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:34 INFO Epoch 0: batch 988/988
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:34 INFO Epoch 0: batch 989/989
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:34 INFO Epoch 0: batch 990/990
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:34 INFO Epoch 0: batch 991/991
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:34 INFO Epoch 0: batch 992/992
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:34 INFO Epoch 0: batch 993/993
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:34 INFO Epoch 0: batch 994/994
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:34 INFO Epoch 0: batch 995/995
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:34 INFO Epoch 0: batch 996/996
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:34 INFO Epoch 0: batch 997/997
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:34 INFO Epoch 0: batch 998/998
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:34 INFO Epoch 0: batch 999/999
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:34 INFO Epoch 0: batch 1000/1000
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:34 INFO Epoch 0: batch 1001/1001
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0877 
2025/02/24 00:54:34 INFO Epoch 0: batch 1002/1002
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:34 INFO Epoch 0: batch 1003/1003
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:34 INFO Epoch 0: batch 1004/1004
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:34 INFO Epoch 0: batch 1005/1005
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0547 
2025/02/24 00:54:34 INFO Epoch 0: batch 1006/1006
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:34 INFO Epoch 0: batch 1007/1007
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:34 INFO Epoch 0: batch 1008/1008
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:34 INFO Epoch 0: batch 1009/1009
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:34 INFO Epoch 0: batch 1010/1010
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:34 INFO Epoch 0: batch 1011/1011
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:34 INFO Epoch 0: batch 1012/1012
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:34 INFO Epoch 0: batch 1013/1013
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:34 INFO Epoch 0: batch 1014/1014
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:34 INFO Epoch 0: batch 1015/1015
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:34 INFO Epoch 0: batch 1016/1016
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:34 INFO Epoch 0: batch 1017/1017
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:34 INFO Epoch 0: batch 1018/1018
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:34 INFO Epoch 0: batch 1019/1019
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1027 
2025/02/24 00:54:34 INFO Epoch 0: batch 1020/1020
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0968 
2025/02/24 00:54:34 INFO Epoch 0: batch 1021/1021
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:34 INFO Epoch 0: batch 1022/1022
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:34 INFO Epoch 0: batch 1023/1023
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:34 INFO Epoch 0: batch 1024/1024
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:34 INFO Epoch 0: batch 1025/1025
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0831 
2025/02/24 00:54:34 INFO Epoch 0: batch 1026/1026
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:34 INFO Epoch 0: batch 1027/1027
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:34 INFO Epoch 0: batch 1028/1028
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:34 INFO Epoch 0: batch 1029/1029
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:34 INFO Epoch 0: batch 1030/1030
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0961 
2025/02/24 00:54:34 INFO Epoch 0: batch 1031/1031
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:34 INFO Epoch 0: batch 1032/1032
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:34 INFO Epoch 0: batch 1033/1033
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:34 INFO Epoch 0: batch 1034/1034
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1197 
2025/02/24 00:54:34 INFO Epoch 0: batch 1035/1035
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0932 
2025/02/24 00:54:34 INFO Epoch 0: batch 1036/1036
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0894 
2025/02/24 00:54:34 INFO Epoch 0: batch 1037/1037
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0885 
2025/02/24 00:54:34 INFO Epoch 0: batch 1038/1038
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:34 INFO Epoch 0: batch 1039/1039
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:34 INFO Epoch 0: batch 1040/1040
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:34 INFO Epoch 0: batch 1041/1041
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:34 INFO Epoch 0: batch 1042/1042
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:34 INFO Epoch 0: batch 1043/1043
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1000 
2025/02/24 00:54:34 INFO Epoch 0: batch 1044/1044
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:34 INFO Epoch 0: batch 1045/1045
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0642 
2025/02/24 00:54:34 INFO Epoch 0: batch 1046/1046
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0928 
2025/02/24 00:54:34 INFO Epoch 0: batch 1047/1047
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:34 INFO Epoch 0: batch 1048/1048
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:34 INFO Epoch 0: batch 1049/1049
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:34 INFO Epoch 0: batch 1050/1050
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:34 INFO Epoch 0: batch 1051/1051
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:34 INFO Epoch 0: batch 1052/1052
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0911 
2025/02/24 00:54:34 INFO Epoch 0: batch 1053/1053
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:34 INFO Epoch 0: batch 1054/1054
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0881 
2025/02/24 00:54:34 INFO Epoch 0: batch 1055/1055
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0497 
2025/02/24 00:54:34 INFO Epoch 0: batch 1056/1056
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0862 
2025/02/24 00:54:34 INFO Epoch 0: batch 1057/1057
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:34 INFO Epoch 0: batch 1058/1058
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:34 INFO Epoch 0: batch 1059/1059
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:34 INFO Epoch 0: batch 1060/1060
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:34 INFO Epoch 0: batch 1061/1061
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0922 
2025/02/24 00:54:34 INFO Epoch 0: batch 1062/1062
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:34 INFO Epoch 0: batch 1063/1063
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0965 
2025/02/24 00:54:34 INFO Epoch 0: batch 1064/1064
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0614 
2025/02/24 00:54:34 INFO Epoch 0: batch 1065/1065
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0587 
2025/02/24 00:54:34 INFO Epoch 0: batch 1066/1066
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0589 
2025/02/24 00:54:34 INFO Epoch 0: batch 1067/1067
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:34 INFO Epoch 0: batch 1068/1068
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1031 
2025/02/24 00:54:34 INFO Epoch 0: batch 1069/1069
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.1073 
2025/02/24 00:54:34 INFO Epoch 0: batch 1070/1070
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0799 
2025/02/24 00:54:34 INFO Epoch 0: batch 1071/1071
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:34 INFO Epoch 0: batch 1072/1072
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:34 INFO Epoch 0: batch 1073/1073
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:34 INFO Epoch 0: batch 1074/1074
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:34 INFO Epoch 0: batch 1075/1075
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:34 INFO Epoch 0: batch 1076/1076
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:34 INFO Epoch 0: batch 1077/1077
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:34 INFO Epoch 0: batch 1078/1078
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:34 INFO Epoch 0: batch 1079/1079
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:34 INFO Epoch 0: batch 1080/1080
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:34 INFO Epoch 0: batch 1081/1081
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:34 INFO Epoch 0: batch 1082/1082
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0874 
2025/02/24 00:54:34 INFO Epoch 0: batch 1083/1083
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:34 INFO Epoch 0: batch 1084/1084
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:34 INFO Epoch 0: batch 1085/1085
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:34 INFO Epoch 0: batch 1086/1086
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0585 
2025/02/24 00:54:34 INFO Epoch 0: batch 1087/1087
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:34 INFO Epoch 0: batch 1088/1088
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:34 INFO Epoch 0: batch 1089/1089
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:34 INFO Epoch 0: batch 1090/1090
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:34 INFO Epoch 0: batch 1091/1091
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:34 INFO Epoch 0: batch 1092/1092
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0894 
2025/02/24 00:54:34 INFO Epoch 0: batch 1093/1093
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:34 INFO Epoch 0: batch 1094/1094
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:34 INFO Epoch 0: batch 1095/1095
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0883 
2025/02/24 00:54:34 INFO Epoch 0: batch 1096/1096
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:34 INFO Epoch 0: batch 1097/1097
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:34 INFO Epoch 0: batch 1098/1098
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:34 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:34 INFO Epoch 0: batch 1099/1099
2025/02/24 00:54:34 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:35 INFO Epoch 0: batch 1100/1100
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:35 INFO Epoch 0: batch 1101/1101
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:35 INFO Epoch 0: batch 1102/1102
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:35 INFO Epoch 0: batch 1103/1103
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0842 
2025/02/24 00:54:35 INFO Epoch 0: batch 1104/1104
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0921 
2025/02/24 00:54:35 INFO Epoch 0: batch 1105/1105
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:35 INFO Epoch 0: batch 1106/1106
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:35 INFO Epoch 0: batch 1107/1107
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:35 INFO Epoch 0: batch 1108/1108
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:35 INFO Epoch 0: batch 1109/1109
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0570 
2025/02/24 00:54:35 INFO Epoch 0: batch 1110/1110
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:35 INFO Epoch 0: batch 1111/1111
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:35 INFO Epoch 0: batch 1112/1112
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:35 INFO Epoch 0: batch 1113/1113
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:35 INFO Epoch 0: batch 1114/1114
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:35 INFO Epoch 0: batch 1115/1115
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:35 INFO Epoch 0: batch 1116/1116
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:35 INFO Epoch 0: batch 1117/1117
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0591 
2025/02/24 00:54:35 INFO Epoch 0: batch 1118/1118
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:35 INFO Epoch 0: batch 1119/1119
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0626 
2025/02/24 00:54:35 INFO Epoch 0: batch 1120/1120
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0573 
2025/02/24 00:54:35 INFO Epoch 0: batch 1121/1121
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:35 INFO Epoch 0: batch 1122/1122
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:35 INFO Epoch 0: batch 1123/1123
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:35 INFO Epoch 0: batch 1124/1124
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:35 INFO Epoch 0: batch 1125/1125
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0969 
2025/02/24 00:54:35 INFO Epoch 0: batch 1126/1126
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:35 INFO Epoch 0: batch 1127/1127
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0542 
2025/02/24 00:54:35 INFO Epoch 0: batch 1128/1128
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0869 
2025/02/24 00:54:35 INFO Epoch 0: batch 1129/1129
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:35 INFO Epoch 0: batch 1130/1130
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0885 
2025/02/24 00:54:35 INFO Epoch 0: batch 1131/1131
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:35 INFO Epoch 0: batch 1132/1132
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:35 INFO Epoch 0: batch 1133/1133
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:35 INFO Epoch 0: batch 1134/1134
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:35 INFO Epoch 0: batch 1135/1135
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:35 INFO Epoch 0: batch 1136/1136
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:35 INFO Epoch 0: batch 1137/1137
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0520 
2025/02/24 00:54:35 INFO Epoch 0: batch 1138/1138
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:35 INFO Epoch 0: batch 1139/1139
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:35 INFO Epoch 0: batch 1140/1140
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:35 INFO Epoch 0: batch 1141/1141
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0566 
2025/02/24 00:54:35 INFO Epoch 0: batch 1142/1142
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:35 INFO Epoch 0: batch 1143/1143
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:35 INFO Epoch 0: batch 1144/1144
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:35 INFO Epoch 0: batch 1145/1145
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0563 
2025/02/24 00:54:35 INFO Epoch 0: batch 1146/1146
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:35 INFO Epoch 0: batch 1147/1147
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:35 INFO Epoch 0: batch 1148/1148
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:35 INFO Epoch 0: batch 1149/1149
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:35 INFO Epoch 0: batch 1150/1150
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:35 INFO Epoch 0: batch 1151/1151
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:35 INFO Epoch 0: batch 1152/1152
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:35 INFO Epoch 0: batch 1153/1153
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:35 INFO Epoch 0: batch 1154/1154
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0918 
2025/02/24 00:54:35 INFO Epoch 0: batch 1155/1155
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:35 INFO Epoch 0: batch 1156/1156
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:35 INFO Epoch 0: batch 1157/1157
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:35 INFO Epoch 0: batch 1158/1158
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0607 
2025/02/24 00:54:35 INFO Epoch 0: batch 1159/1159
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:35 INFO Epoch 0: batch 1160/1160
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:35 INFO Epoch 0: batch 1161/1161
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.1125 
2025/02/24 00:54:35 INFO Epoch 0: batch 1162/1162
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:35 INFO Epoch 0: batch 1163/1163
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:35 INFO Epoch 0: batch 1164/1164
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0604 
2025/02/24 00:54:35 INFO Epoch 0: batch 1165/1165
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:35 INFO Epoch 0: batch 1166/1166
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:35 INFO Epoch 0: batch 1167/1167
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:35 INFO Epoch 0: batch 1168/1168
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:35 INFO Epoch 0: batch 1169/1169
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:35 INFO Epoch 0: batch 1170/1170
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0952 
2025/02/24 00:54:35 INFO Epoch 0: batch 1171/1171
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:35 INFO Epoch 0: batch 1172/1172
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0542 
2025/02/24 00:54:35 INFO Epoch 0: batch 1173/1173
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:35 INFO Epoch 0: batch 1174/1174
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0558 
2025/02/24 00:54:35 INFO Epoch 0: batch 1175/1175
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:35 INFO Epoch 0: batch 1176/1176
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:35 INFO Epoch 0: batch 1177/1177
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:35 INFO Epoch 0: batch 1178/1178
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:35 INFO Epoch 0: batch 1179/1179
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:35 INFO Epoch 0: batch 1180/1180
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0470 
2025/02/24 00:54:35 INFO Epoch 0: batch 1181/1181
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:35 INFO Epoch 0: batch 1182/1182
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:35 INFO Epoch 0: batch 1183/1183
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:35 INFO Epoch 0: batch 1184/1184
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:35 INFO Epoch 0: batch 1185/1185
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:35 INFO Epoch 0: batch 1186/1186
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:35 INFO Epoch 0: batch 1187/1187
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:35 INFO Epoch 0: batch 1188/1188
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:35 INFO Epoch 0: batch 1189/1189
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0676 
2025/02/24 00:54:35 INFO Epoch 0: batch 1190/1190
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:35 INFO Epoch 0: batch 1191/1191
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:35 INFO Epoch 0: batch 1192/1192
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:35 INFO Epoch 0: batch 1193/1193
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:35 INFO Epoch 0: batch 1194/1194
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:35 INFO Epoch 0: batch 1195/1195
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:35 INFO Epoch 0: batch 1196/1196
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0542 
2025/02/24 00:54:35 INFO Epoch 0: batch 1197/1197
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:35 INFO Epoch 0: batch 1198/1198
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:35 INFO Epoch 0: batch 1199/1199
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0587 
2025/02/24 00:54:35 INFO Epoch 0: batch 1200/1200
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0869 
2025/02/24 00:54:35 INFO Epoch 0: batch 1201/1201
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0531 
2025/02/24 00:54:35 INFO Epoch 0: batch 1202/1202
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:35 INFO Epoch 0: batch 1203/1203
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:35 INFO Epoch 0: batch 1204/1204
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:35 INFO Epoch 0: batch 1205/1205
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0550 
2025/02/24 00:54:35 INFO Epoch 0: batch 1206/1206
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:35 INFO Epoch 0: batch 1207/1207
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:35 INFO Epoch 0: batch 1208/1208
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0871 
2025/02/24 00:54:35 INFO Epoch 0: batch 1209/1209
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:35 INFO Epoch 0: batch 1210/1210
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:35 INFO Epoch 0: batch 1211/1211
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:35 INFO Epoch 0: batch 1212/1212
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:35 INFO Epoch 0: batch 1213/1213
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.1077 
2025/02/24 00:54:35 INFO Epoch 0: batch 1214/1214
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:35 INFO Epoch 0: batch 1215/1215
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:35 INFO Epoch 0: batch 1216/1216
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:35 INFO Epoch 0: batch 1217/1217
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.1065 
2025/02/24 00:54:35 INFO Epoch 0: batch 1218/1218
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0809 
2025/02/24 00:54:35 INFO Epoch 0: batch 1219/1219
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:35 INFO Epoch 0: batch 1220/1220
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:35 INFO Epoch 0: batch 1221/1221
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:35 INFO Epoch 0: batch 1222/1222
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:35 INFO Epoch 0: batch 1223/1223
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:35 INFO Epoch 0: batch 1224/1224
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:35 INFO Epoch 0: batch 1225/1225
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:35 INFO Epoch 0: batch 1226/1226
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:35 INFO Epoch 0: batch 1227/1227
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:35 INFO Epoch 0: batch 1228/1228
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:35 INFO Epoch 0: batch 1229/1229
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:35 INFO Epoch 0: batch 1230/1230
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:35 INFO Epoch 0: batch 1231/1231
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:35 INFO Epoch 0: batch 1232/1232
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:35 INFO Epoch 0: batch 1233/1233
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:35 INFO Epoch 0: batch 1234/1234
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:35 INFO Epoch 0: batch 1235/1235
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:35 INFO Epoch 0: batch 1236/1236
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:35 INFO Epoch 0: batch 1237/1237
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:35 INFO Epoch 0: batch 1238/1238
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:35 INFO Epoch 0: batch 1239/1239
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:35 INFO Epoch 0: batch 1240/1240
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:35 INFO Epoch 0: batch 1241/1241
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:35 INFO Epoch 0: batch 1242/1242
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:35 INFO Epoch 0: batch 1243/1243
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.1017 
2025/02/24 00:54:35 INFO Epoch 0: batch 1244/1244
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:35 INFO Epoch 0: batch 1245/1245
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:35 INFO Epoch 0: batch 1246/1246
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:35 INFO Epoch 0: batch 1247/1247
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:35 INFO Epoch 0: batch 1248/1248
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:35 INFO Epoch 0: batch 1249/1249
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:35 INFO Epoch 0: batch 1250/1250
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0937 
2025/02/24 00:54:35 INFO Epoch 0: batch 1251/1251
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:35 INFO Epoch 0: batch 1252/1252
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:35 INFO Epoch 0: batch 1253/1253
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:35 INFO Epoch 0: batch 1254/1254
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:35 INFO Epoch 0: batch 1255/1255
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:35 INFO Epoch 0: batch 1256/1256
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:35 INFO Epoch 0: batch 1257/1257
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:35 INFO Epoch 0: batch 1258/1258
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:35 INFO Epoch 0: batch 1259/1259
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0905 
2025/02/24 00:54:35 INFO Epoch 0: batch 1260/1260
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0909 
2025/02/24 00:54:35 INFO Epoch 0: batch 1261/1261
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:35 INFO Epoch 0: batch 1262/1262
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:35 INFO Epoch 0: batch 1263/1263
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:35 INFO Epoch 0: batch 1264/1264
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0850 
2025/02/24 00:54:35 INFO Epoch 0: batch 1265/1265
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:35 INFO Epoch 0: batch 1266/1266
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0575 
2025/02/24 00:54:35 INFO Epoch 0: batch 1267/1267
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:35 INFO Epoch 0: batch 1268/1268
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:35 INFO Epoch 0: batch 1269/1269
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0522 
2025/02/24 00:54:35 INFO Epoch 0: batch 1270/1270
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:35 INFO Epoch 0: batch 1271/1271
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:35 INFO Epoch 0: batch 1272/1272
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:35 INFO Epoch 0: batch 1273/1273
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:35 INFO Epoch 0: batch 1274/1274
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:35 INFO Epoch 0: batch 1275/1275
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:35 INFO Epoch 0: batch 1276/1276
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:35 INFO Epoch 0: batch 1277/1277
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:35 INFO Epoch 0: batch 1278/1278
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:35 INFO Epoch 0: batch 1279/1279
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:35 INFO Epoch 0: batch 1280/1280
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:35 INFO Epoch 0: batch 1281/1281
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:35 INFO Epoch 0: batch 1282/1282
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:35 INFO Epoch 0: batch 1283/1283
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:35 INFO Epoch 0: batch 1284/1284
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:35 INFO Epoch 0: batch 1285/1285
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0842 
2025/02/24 00:54:35 INFO Epoch 0: batch 1286/1286
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:35 INFO Epoch 0: batch 1287/1287
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:35 INFO Epoch 0: batch 1288/1288
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:35 INFO Epoch 0: batch 1289/1289
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:35 INFO Epoch 0: batch 1290/1290
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:35 INFO Epoch 0: batch 1291/1291
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0574 
2025/02/24 00:54:35 INFO Epoch 0: batch 1292/1292
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:35 INFO Epoch 0: batch 1293/1293
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:35 INFO Epoch 0: batch 1294/1294
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:35 INFO Epoch 0: batch 1295/1295
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:35 INFO Epoch 0: batch 1296/1296
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:35 INFO Epoch 0: batch 1297/1297
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:35 INFO Epoch 0: batch 1298/1298
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:35 INFO Epoch 0: batch 1299/1299
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:35 INFO Epoch 0: batch 1300/1300
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:35 INFO Epoch 0: batch 1301/1301
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0969 
2025/02/24 00:54:35 INFO Epoch 0: batch 1302/1302
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:35 INFO Epoch 0: batch 1303/1303
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0589 
2025/02/24 00:54:35 INFO Epoch 0: batch 1304/1304
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0661 
2025/02/24 00:54:35 INFO Epoch 0: batch 1305/1305
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0967 
2025/02/24 00:54:35 INFO Epoch 0: batch 1306/1306
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:35 INFO Epoch 0: batch 1307/1307
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:35 INFO Epoch 0: batch 1308/1308
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0504 
2025/02/24 00:54:35 INFO Epoch 0: batch 1309/1309
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:35 INFO Epoch 0: batch 1310/1310
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:35 INFO Epoch 0: batch 1311/1311
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0997 
2025/02/24 00:54:35 INFO Epoch 0: batch 1312/1312
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:35 INFO Epoch 0: batch 1313/1313
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:35 INFO Epoch 0: batch 1314/1314
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:35 INFO Epoch 0: batch 1315/1315
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:35 INFO Epoch 0: batch 1316/1316
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:35 INFO Epoch 0: batch 1317/1317
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:35 INFO Epoch 0: batch 1318/1318
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0543 
2025/02/24 00:54:35 INFO Epoch 0: batch 1319/1319
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:35 INFO Epoch 0: batch 1320/1320
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:35 INFO Epoch 0: batch 1321/1321
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0575 
2025/02/24 00:54:35 INFO Epoch 0: batch 1322/1322
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:35 INFO Epoch 0: batch 1323/1323
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:35 INFO Epoch 0: batch 1324/1324
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:35 INFO Epoch 0: batch 1325/1325
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0907 
2025/02/24 00:54:35 INFO Epoch 0: batch 1326/1326
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:35 INFO Epoch 0: batch 1327/1327
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:35 INFO Epoch 0: batch 1328/1328
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:35 INFO Epoch 0: batch 1329/1329
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:35 INFO Epoch 0: batch 1330/1330
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:35 INFO Epoch 0: batch 1331/1331
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0586 
2025/02/24 00:54:35 INFO Epoch 0: batch 1332/1332
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:35 INFO Epoch 0: batch 1333/1333
2025/02/24 00:54:35 INFO          m 0.00010 
2025/02/24 00:54:35 INFO          Training stage 1 Training_loss 0.1082 
2025/02/24 00:54:36 INFO Epoch 0: batch 1334/1334
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1092 
2025/02/24 00:54:36 INFO Epoch 0: batch 1335/1335
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:36 INFO Epoch 0: batch 1336/1336
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:36 INFO Epoch 0: batch 1337/1337
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1001 
2025/02/24 00:54:36 INFO Epoch 0: batch 1338/1338
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:36 INFO Epoch 0: batch 1339/1339
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:36 INFO Epoch 0: batch 1340/1340
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0560 
2025/02/24 00:54:36 INFO Epoch 0: batch 1341/1341
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:36 INFO Epoch 0: batch 1342/1342
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:36 INFO Epoch 0: batch 1343/1343
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:36 INFO Epoch 0: batch 1344/1344
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:36 INFO Epoch 0: batch 1345/1345
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0883 
2025/02/24 00:54:36 INFO Epoch 0: batch 1346/1346
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:36 INFO Epoch 0: batch 1347/1347
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0984 
2025/02/24 00:54:36 INFO Epoch 0: batch 1348/1348
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:36 INFO Epoch 0: batch 1349/1349
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0570 
2025/02/24 00:54:36 INFO Epoch 0: batch 1350/1350
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0869 
2025/02/24 00:54:36 INFO Epoch 0: batch 1351/1351
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:36 INFO Epoch 0: batch 1352/1352
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:36 INFO Epoch 0: batch 1353/1353
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0814 
2025/02/24 00:54:36 INFO Epoch 0: batch 1354/1354
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:36 INFO Epoch 0: batch 1355/1355
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0938 
2025/02/24 00:54:36 INFO Epoch 0: batch 1356/1356
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0925 
2025/02/24 00:54:36 INFO Epoch 0: batch 1357/1357
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:36 INFO Epoch 0: batch 1358/1358
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:36 INFO Epoch 0: batch 1359/1359
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0582 
2025/02/24 00:54:36 INFO Epoch 0: batch 1360/1360
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:36 INFO Epoch 0: batch 1361/1361
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0557 
2025/02/24 00:54:36 INFO Epoch 0: batch 1362/1362
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:36 INFO Epoch 0: batch 1363/1363
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0543 
2025/02/24 00:54:36 INFO Epoch 0: batch 1364/1364
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:36 INFO Epoch 0: batch 1365/1365
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:36 INFO Epoch 0: batch 1366/1366
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0815 
2025/02/24 00:54:36 INFO Epoch 0: batch 1367/1367
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1158 
2025/02/24 00:54:36 INFO Epoch 0: batch 1368/1368
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:36 INFO Epoch 0: batch 1369/1369
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:36 INFO Epoch 0: batch 1370/1370
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:36 INFO Epoch 0: batch 1371/1371
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:36 INFO Epoch 0: batch 1372/1372
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:36 INFO Epoch 0: batch 1373/1373
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0488 
2025/02/24 00:54:36 INFO Epoch 0: batch 1374/1374
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:36 INFO Epoch 0: batch 1375/1375
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:36 INFO Epoch 0: batch 1376/1376
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0567 
2025/02/24 00:54:36 INFO Epoch 0: batch 1377/1377
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:36 INFO Epoch 0: batch 1378/1378
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:36 INFO Epoch 0: batch 1379/1379
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0521 
2025/02/24 00:54:36 INFO Epoch 0: batch 1380/1380
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:36 INFO Epoch 0: batch 1381/1381
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:36 INFO Epoch 0: batch 1382/1382
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:36 INFO Epoch 0: batch 1383/1383
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0994 
2025/02/24 00:54:36 INFO Epoch 0: batch 1384/1384
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:36 INFO Epoch 0: batch 1385/1385
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:36 INFO Epoch 0: batch 1386/1386
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:36 INFO Epoch 0: batch 1387/1387
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:36 INFO Epoch 0: batch 1388/1388
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:36 INFO Epoch 0: batch 1389/1389
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:36 INFO Epoch 0: batch 1390/1390
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:36 INFO Epoch 0: batch 1391/1391
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:36 INFO Epoch 0: batch 1392/1392
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:36 INFO Epoch 0: batch 1393/1393
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:36 INFO Epoch 0: batch 1394/1394
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:36 INFO Epoch 0: batch 1395/1395
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:36 INFO Epoch 0: batch 1396/1396
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:36 INFO Epoch 0: batch 1397/1397
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0626 
2025/02/24 00:54:36 INFO Epoch 0: batch 1398/1398
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:36 INFO Epoch 0: batch 1399/1399
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:36 INFO Epoch 0: batch 1400/1400
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:36 INFO Epoch 0: batch 1401/1401
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:36 INFO Epoch 0: batch 1402/1402
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:36 INFO Epoch 0: batch 1403/1403
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:36 INFO Epoch 0: batch 1404/1404
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:36 INFO Epoch 0: batch 1405/1405
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1003 
2025/02/24 00:54:36 INFO Epoch 0: batch 1406/1406
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:36 INFO Epoch 0: batch 1407/1407
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:36 INFO Epoch 0: batch 1408/1408
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0882 
2025/02/24 00:54:36 INFO Epoch 0: batch 1409/1409
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:36 INFO Epoch 0: batch 1410/1410
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:36 INFO Epoch 0: batch 1411/1411
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:36 INFO Epoch 0: batch 1412/1412
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:36 INFO Epoch 0: batch 1413/1413
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0883 
2025/02/24 00:54:36 INFO Epoch 0: batch 1414/1414
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:36 INFO Epoch 0: batch 1415/1415
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:36 INFO Epoch 0: batch 1416/1416
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:36 INFO Epoch 0: batch 1417/1417
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:36 INFO Epoch 0: batch 1418/1418
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:36 INFO Epoch 0: batch 1419/1419
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:36 INFO Epoch 0: batch 1420/1420
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:36 INFO Epoch 0: batch 1421/1421
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:36 INFO Epoch 0: batch 1422/1422
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0512 
2025/02/24 00:54:36 INFO Epoch 0: batch 1423/1423
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:36 INFO Epoch 0: batch 1424/1424
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:36 INFO Epoch 0: batch 1425/1425
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0936 
2025/02/24 00:54:36 INFO Epoch 0: batch 1426/1426
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:36 INFO Epoch 0: batch 1427/1427
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:36 INFO Epoch 0: batch 1428/1428
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0642 
2025/02/24 00:54:36 INFO Epoch 0: batch 1429/1429
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:36 INFO Epoch 0: batch 1430/1430
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:36 INFO Epoch 0: batch 1431/1431
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:36 INFO Epoch 0: batch 1432/1432
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:36 INFO Epoch 0: batch 1433/1433
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:36 INFO Epoch 0: batch 1434/1434
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:36 INFO Epoch 0: batch 1435/1435
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0596 
2025/02/24 00:54:36 INFO Epoch 0: batch 1436/1436
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1055 
2025/02/24 00:54:36 INFO Epoch 0: batch 1437/1437
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:36 INFO Epoch 0: batch 1438/1438
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0543 
2025/02/24 00:54:36 INFO Epoch 0: batch 1439/1439
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:36 INFO Epoch 0: batch 1440/1440
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:36 INFO Epoch 0: batch 1441/1441
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:36 INFO Epoch 0: batch 1442/1442
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:36 INFO Epoch 0: batch 1443/1443
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:36 INFO Epoch 0: batch 1444/1444
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:36 INFO Epoch 0: batch 1445/1445
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:36 INFO Epoch 0: batch 1446/1446
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0557 
2025/02/24 00:54:36 INFO Epoch 0: batch 1447/1447
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:36 INFO Epoch 0: batch 1448/1448
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:36 INFO Epoch 0: batch 1449/1449
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:36 INFO Epoch 0: batch 1450/1450
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:36 INFO Epoch 0: batch 1451/1451
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0842 
2025/02/24 00:54:36 INFO Epoch 0: batch 1452/1452
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:36 INFO Epoch 0: batch 1453/1453
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:36 INFO Epoch 0: batch 1454/1454
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:36 INFO Epoch 0: batch 1455/1455
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:36 INFO Epoch 0: batch 1456/1456
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0815 
2025/02/24 00:54:36 INFO Epoch 0: batch 1457/1457
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:36 INFO Epoch 0: batch 1458/1458
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:36 INFO Epoch 0: batch 1459/1459
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0573 
2025/02/24 00:54:36 INFO Epoch 0: batch 1460/1460
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:36 INFO Epoch 0: batch 1461/1461
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:36 INFO Epoch 0: batch 1462/1462
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:36 INFO Epoch 0: batch 1463/1463
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0935 
2025/02/24 00:54:36 INFO Epoch 0: batch 1464/1464
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:36 INFO Epoch 0: batch 1465/1465
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:36 INFO Epoch 0: batch 1466/1466
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0857 
2025/02/24 00:54:36 INFO Epoch 0: batch 1467/1467
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:36 INFO Epoch 0: batch 1468/1468
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:36 INFO Epoch 0: batch 1469/1469
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:36 INFO Epoch 0: batch 1470/1470
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:36 INFO Epoch 0: batch 1471/1471
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:36 INFO Epoch 0: batch 1472/1472
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:36 INFO Epoch 0: batch 1473/1473
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:36 INFO Epoch 0: batch 1474/1474
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:36 INFO Epoch 0: batch 1475/1475
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:36 INFO Epoch 0: batch 1476/1476
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:36 INFO Epoch 0: batch 1477/1477
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:36 INFO Epoch 0: batch 1478/1478
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:36 INFO Epoch 0: batch 1479/1479
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:36 INFO Epoch 0: batch 1480/1480
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0799 
2025/02/24 00:54:36 INFO Epoch 0: batch 1481/1481
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0571 
2025/02/24 00:54:36 INFO Epoch 0: batch 1482/1482
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:36 INFO Epoch 0: batch 1483/1483
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:36 INFO Epoch 0: batch 1484/1484
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0670 
2025/02/24 00:54:36 INFO Epoch 0: batch 1485/1485
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:36 INFO Epoch 0: batch 1486/1486
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:36 INFO Epoch 0: batch 1487/1487
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:36 INFO Epoch 0: batch 1488/1488
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:36 INFO Epoch 0: batch 1489/1489
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:36 INFO Epoch 0: batch 1490/1490
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:36 INFO Epoch 0: batch 1491/1491
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:36 INFO Epoch 0: batch 1492/1492
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:36 INFO Epoch 0: batch 1493/1493
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:36 INFO Epoch 0: batch 1494/1494
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:36 INFO Epoch 0: batch 1495/1495
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:36 INFO Epoch 0: batch 1496/1496
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:36 INFO Epoch 0: batch 1497/1497
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0857 
2025/02/24 00:54:36 INFO Epoch 0: batch 1498/1498
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:36 INFO Epoch 0: batch 1499/1499
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:36 INFO Epoch 0: batch 1500/1500
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:36 INFO Epoch 0: batch 1501/1501
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0831 
2025/02/24 00:54:36 INFO Epoch 0: batch 1502/1502
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:36 INFO Epoch 0: batch 1503/1503
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:36 INFO Epoch 0: batch 1504/1504
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:36 INFO Epoch 0: batch 1505/1505
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:36 INFO Epoch 0: batch 1506/1506
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:36 INFO Epoch 0: batch 1507/1507
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:36 INFO Epoch 0: batch 1508/1508
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:36 INFO Epoch 0: batch 1509/1509
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:36 INFO Epoch 0: batch 1510/1510
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:36 INFO Epoch 0: batch 1511/1511
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:36 INFO Epoch 0: batch 1512/1512
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:36 INFO Epoch 0: batch 1513/1513
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:36 INFO Epoch 0: batch 1514/1514
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:36 INFO Epoch 0: batch 1515/1515
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:36 INFO Epoch 0: batch 1516/1516
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0989 
2025/02/24 00:54:36 INFO Epoch 0: batch 1517/1517
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:36 INFO Epoch 0: batch 1518/1518
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:36 INFO Epoch 0: batch 1519/1519
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:36 INFO Epoch 0: batch 1520/1520
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:36 INFO Epoch 0: batch 1521/1521
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:36 INFO Epoch 0: batch 1522/1522
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:36 INFO Epoch 0: batch 1523/1523
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:36 INFO Epoch 0: batch 1524/1524
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:36 INFO Epoch 0: batch 1525/1525
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:36 INFO Epoch 0: batch 1526/1526
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:36 INFO Epoch 0: batch 1527/1527
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:36 INFO Epoch 0: batch 1528/1528
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0980 
2025/02/24 00:54:36 INFO Epoch 0: batch 1529/1529
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:36 INFO Epoch 0: batch 1530/1530
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0565 
2025/02/24 00:54:36 INFO Epoch 0: batch 1531/1531
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:36 INFO Epoch 0: batch 1532/1532
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:36 INFO Epoch 0: batch 1533/1533
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:36 INFO Epoch 0: batch 1534/1534
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:36 INFO Epoch 0: batch 1535/1535
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:36 INFO Epoch 0: batch 1536/1536
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:36 INFO Epoch 0: batch 1537/1537
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:36 INFO Epoch 0: batch 1538/1538
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:36 INFO Epoch 0: batch 1539/1539
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:36 INFO Epoch 0: batch 1540/1540
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:36 INFO Epoch 0: batch 1541/1541
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:36 INFO Epoch 0: batch 1542/1542
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:36 INFO Epoch 0: batch 1543/1543
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:36 INFO Epoch 0: batch 1544/1544
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:36 INFO Epoch 0: batch 1545/1545
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:36 INFO Epoch 0: batch 1546/1546
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:36 INFO Epoch 0: batch 1547/1547
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0546 
2025/02/24 00:54:36 INFO Epoch 0: batch 1548/1548
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0842 
2025/02/24 00:54:36 INFO Epoch 0: batch 1549/1549
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:36 INFO Epoch 0: batch 1550/1550
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:36 INFO Epoch 0: batch 1551/1551
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0941 
2025/02/24 00:54:36 INFO Epoch 0: batch 1552/1552
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:36 INFO Epoch 0: batch 1553/1553
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:36 INFO Epoch 0: batch 1554/1554
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:36 INFO Epoch 0: batch 1555/1555
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:36 INFO Epoch 0: batch 1556/1556
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1004 
2025/02/24 00:54:36 INFO Epoch 0: batch 1557/1557
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:36 INFO Epoch 0: batch 1558/1558
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:36 INFO Epoch 0: batch 1559/1559
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:36 INFO Epoch 0: batch 1560/1560
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:36 INFO Epoch 0: batch 1561/1561
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0514 
2025/02/24 00:54:36 INFO Epoch 0: batch 1562/1562
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:36 INFO Epoch 0: batch 1563/1563
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:36 INFO Epoch 0: batch 1564/1564
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:36 INFO Epoch 0: batch 1565/1565
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0577 
2025/02/24 00:54:36 INFO Epoch 0: batch 1566/1566
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:36 INFO Epoch 0: batch 1567/1567
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:36 INFO Epoch 0: batch 1568/1568
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0891 
2025/02/24 00:54:36 INFO Epoch 0: batch 1569/1569
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:36 INFO Epoch 0: batch 1570/1570
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:36 INFO Epoch 0: batch 1571/1571
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:36 INFO Epoch 0: batch 1572/1572
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:36 INFO Epoch 0: batch 1573/1573
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:36 INFO Epoch 0: batch 1574/1574
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:36 INFO Epoch 0: batch 1575/1575
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:36 INFO Epoch 0: batch 1576/1576
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:36 INFO Epoch 0: batch 1577/1577
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:36 INFO Epoch 0: batch 1578/1578
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:36 INFO Epoch 0: batch 1579/1579
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.1205 
2025/02/24 00:54:36 INFO Epoch 0: batch 1580/1580
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:36 INFO Epoch 0: batch 1581/1581
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:36 INFO Epoch 0: batch 1582/1582
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:36 INFO Epoch 0: batch 1583/1583
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:36 INFO Epoch 0: batch 1584/1584
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0552 
2025/02/24 00:54:36 INFO Epoch 0: batch 1585/1585
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:36 INFO Epoch 0: batch 1586/1586
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:36 INFO Epoch 0: batch 1587/1587
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:36 INFO Epoch 0: batch 1588/1588
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:36 INFO Epoch 0: batch 1589/1589
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:36 INFO Epoch 0: batch 1590/1590
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0804 
2025/02/24 00:54:36 INFO Epoch 0: batch 1591/1591
2025/02/24 00:54:36 INFO          m 0.00010 
2025/02/24 00:54:36 INFO          Training stage 1 Training_loss 0.0555 
2025/02/24 00:54:37 INFO Epoch 0: batch 1592/1592
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:37 INFO Epoch 0: batch 1593/1593
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0919 
2025/02/24 00:54:37 INFO Epoch 0: batch 1594/1594
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:37 INFO Epoch 0: batch 1595/1595
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0563 
2025/02/24 00:54:37 INFO Epoch 0: batch 1596/1596
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:37 INFO Epoch 0: batch 1597/1597
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:37 INFO Epoch 0: batch 1598/1598
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:37 INFO Epoch 0: batch 1599/1599
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:37 INFO Epoch 0: batch 1600/1600
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:37 INFO Epoch 0: batch 1601/1601
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:37 INFO Epoch 0: batch 1602/1602
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:37 INFO Epoch 0: batch 1603/1603
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0850 
2025/02/24 00:54:37 INFO Epoch 0: batch 1604/1604
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:37 INFO Epoch 0: batch 1605/1605
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:37 INFO Epoch 0: batch 1606/1606
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:37 INFO Epoch 0: batch 1607/1607
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:37 INFO Epoch 0: batch 1608/1608
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:37 INFO Epoch 0: batch 1609/1609
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:37 INFO Epoch 0: batch 1610/1610
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0633 
2025/02/24 00:54:37 INFO Epoch 0: batch 1611/1611
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:37 INFO Epoch 0: batch 1612/1612
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:37 INFO Epoch 0: batch 1613/1613
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:37 INFO Epoch 0: batch 1614/1614
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0570 
2025/02/24 00:54:37 INFO Epoch 0: batch 1615/1615
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:37 INFO Epoch 0: batch 1616/1616
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0910 
2025/02/24 00:54:37 INFO Epoch 0: batch 1617/1617
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0549 
2025/02/24 00:54:37 INFO Epoch 0: batch 1618/1618
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:37 INFO Epoch 0: batch 1619/1619
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:37 INFO Epoch 0: batch 1620/1620
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:37 INFO Epoch 0: batch 1621/1621
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:37 INFO Epoch 0: batch 1622/1622
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:37 INFO Epoch 0: batch 1623/1623
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:37 INFO Epoch 0: batch 1624/1624
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:37 INFO Epoch 0: batch 1625/1625
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:37 INFO Epoch 0: batch 1626/1626
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0590 
2025/02/24 00:54:37 INFO Epoch 0: batch 1627/1627
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:37 INFO Epoch 0: batch 1628/1628
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:37 INFO Epoch 0: batch 1629/1629
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:37 INFO Epoch 0: batch 1630/1630
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:37 INFO Epoch 0: batch 1631/1631
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0470 
2025/02/24 00:54:37 INFO Epoch 0: batch 1632/1632
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:37 INFO Epoch 0: batch 1633/1633
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:37 INFO Epoch 0: batch 1634/1634
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0622 
2025/02/24 00:54:37 INFO Epoch 0: batch 1635/1635
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:37 INFO Epoch 0: batch 1636/1636
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:37 INFO Epoch 0: batch 1637/1637
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:37 INFO Epoch 0: batch 1638/1638
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:37 INFO Epoch 0: batch 1639/1639
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:37 INFO Epoch 0: batch 1640/1640
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0874 
2025/02/24 00:54:37 INFO Epoch 0: batch 1641/1641
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:37 INFO Epoch 0: batch 1642/1642
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0916 
2025/02/24 00:54:37 INFO Epoch 0: batch 1643/1643
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0825 
2025/02/24 00:54:37 INFO Epoch 0: batch 1644/1644
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:37 INFO Epoch 0: batch 1645/1645
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:37 INFO Epoch 0: batch 1646/1646
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:37 INFO Epoch 0: batch 1647/1647
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:37 INFO Epoch 0: batch 1648/1648
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0816 
2025/02/24 00:54:37 INFO Epoch 0: batch 1649/1649
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0552 
2025/02/24 00:54:37 INFO Epoch 0: batch 1650/1650
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:37 INFO Epoch 0: batch 1651/1651
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:37 INFO Epoch 0: batch 1652/1652
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:37 INFO Epoch 0: batch 1653/1653
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:37 INFO Epoch 0: batch 1654/1654
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:37 INFO Epoch 0: batch 1655/1655
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:37 INFO Epoch 0: batch 1656/1656
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0604 
2025/02/24 00:54:37 INFO Epoch 0: batch 1657/1657
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:37 INFO Epoch 0: batch 1658/1658
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0881 
2025/02/24 00:54:37 INFO Epoch 0: batch 1659/1659
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:37 INFO Epoch 0: batch 1660/1660
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:37 INFO Epoch 0: batch 1661/1661
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:37 INFO Epoch 0: batch 1662/1662
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:37 INFO Epoch 0: batch 1663/1663
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0898 
2025/02/24 00:54:37 INFO Epoch 0: batch 1664/1664
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0825 
2025/02/24 00:54:37 INFO Epoch 0: batch 1665/1665
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:37 INFO Epoch 0: batch 1666/1666
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:37 INFO Epoch 0: batch 1667/1667
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:37 INFO Epoch 0: batch 1668/1668
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:37 INFO Epoch 0: batch 1669/1669
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:37 INFO Epoch 0: batch 1670/1670
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:37 INFO Epoch 0: batch 1671/1671
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:37 INFO Epoch 0: batch 1672/1672
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:37 INFO Epoch 0: batch 1673/1673
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0670 
2025/02/24 00:54:37 INFO Epoch 0: batch 1674/1674
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:37 INFO Epoch 0: batch 1675/1675
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:37 INFO Epoch 0: batch 1676/1676
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:37 INFO Epoch 0: batch 1677/1677
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:37 INFO Epoch 0: batch 1678/1678
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:37 INFO Epoch 0: batch 1679/1679
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0519 
2025/02/24 00:54:37 INFO Epoch 0: batch 1680/1680
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0552 
2025/02/24 00:54:37 INFO Epoch 0: batch 1681/1681
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:37 INFO Epoch 0: batch 1682/1682
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:37 INFO Epoch 0: batch 1683/1683
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:37 INFO Epoch 0: batch 1684/1684
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:37 INFO Epoch 0: batch 1685/1685
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:37 INFO Epoch 0: batch 1686/1686
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0907 
2025/02/24 00:54:37 INFO Epoch 0: batch 1687/1687
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.1023 
2025/02/24 00:54:37 INFO Epoch 0: batch 1688/1688
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:37 INFO Epoch 0: batch 1689/1689
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0836 
2025/02/24 00:54:37 INFO Epoch 0: batch 1690/1690
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:37 INFO Epoch 0: batch 1691/1691
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:37 INFO Epoch 0: batch 1692/1692
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0585 
2025/02/24 00:54:37 INFO Epoch 0: batch 1693/1693
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:37 INFO Epoch 0: batch 1694/1694
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:37 INFO Epoch 0: batch 1695/1695
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:37 INFO Epoch 0: batch 1696/1696
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:37 INFO Epoch 0: batch 1697/1697
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:37 INFO Epoch 0: batch 1698/1698
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:37 INFO Epoch 0: batch 1699/1699
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:37 INFO Epoch 0: batch 1700/1700
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:37 INFO Epoch 0: batch 1701/1701
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:37 INFO Epoch 0: batch 1702/1702
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:37 INFO Epoch 0: batch 1703/1703
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:37 INFO Epoch 0: batch 1704/1704
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0976 
2025/02/24 00:54:37 INFO Epoch 0: batch 1705/1705
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:37 INFO Epoch 0: batch 1706/1706
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:37 INFO Epoch 0: batch 1707/1707
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:37 INFO Epoch 0: batch 1708/1708
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:37 INFO Epoch 0: batch 1709/1709
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:37 INFO Epoch 0: batch 1710/1710
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:37 INFO Epoch 0: batch 1711/1711
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:37 INFO Epoch 0: batch 1712/1712
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:37 INFO Epoch 0: batch 1713/1713
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:37 INFO Epoch 0: batch 1714/1714
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0955 
2025/02/24 00:54:37 INFO Epoch 0: batch 1715/1715
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:37 INFO Epoch 0: batch 1716/1716
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0543 
2025/02/24 00:54:37 INFO Epoch 0: batch 1717/1717
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:37 INFO Epoch 0: batch 1718/1718
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:37 INFO Epoch 0: batch 1719/1719
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0570 
2025/02/24 00:54:37 INFO Epoch 0: batch 1720/1720
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:37 INFO Epoch 0: batch 1721/1721
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:37 INFO Epoch 0: batch 1722/1722
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:37 INFO Epoch 0: batch 1723/1723
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:37 INFO Epoch 0: batch 1724/1724
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0795 
2025/02/24 00:54:37 INFO Epoch 0: batch 1725/1725
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0580 
2025/02/24 00:54:37 INFO Epoch 0: batch 1726/1726
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:37 INFO Epoch 0: batch 1727/1727
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:37 INFO Epoch 0: batch 1728/1728
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:37 INFO Epoch 0: batch 1729/1729
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:37 INFO Epoch 0: batch 1730/1730
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0539 
2025/02/24 00:54:37 INFO Epoch 0: batch 1731/1731
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:37 INFO Epoch 0: batch 1732/1732
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:37 INFO Epoch 0: batch 1733/1733
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:37 INFO Epoch 0: batch 1734/1734
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:37 INFO Epoch 0: batch 1735/1735
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:37 INFO Epoch 0: batch 1736/1736
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:37 INFO Epoch 0: batch 1737/1737
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:37 INFO Epoch 0: batch 1738/1738
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:37 INFO Epoch 0: batch 1739/1739
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:37 INFO Epoch 0: batch 1740/1740
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:37 INFO Epoch 0: batch 1741/1741
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:37 INFO Epoch 0: batch 1742/1742
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:37 INFO Epoch 0: batch 1743/1743
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:37 INFO Epoch 0: batch 1744/1744
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:37 INFO Epoch 0: batch 1745/1745
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:37 INFO Epoch 0: batch 1746/1746
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:37 INFO Epoch 0: batch 1747/1747
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:37 INFO Epoch 0: batch 1748/1748
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:37 INFO Epoch 0: batch 1749/1749
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0929 
2025/02/24 00:54:37 INFO Epoch 0: batch 1750/1750
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:37 INFO Epoch 0: batch 1751/1751
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0806 
2025/02/24 00:54:37 INFO Epoch 0: batch 1752/1752
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:37 INFO Epoch 0: batch 1753/1753
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:37 INFO Epoch 0: batch 1754/1754
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0929 
2025/02/24 00:54:37 INFO Epoch 0: batch 1755/1755
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:37 INFO Epoch 0: batch 1756/1756
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:37 INFO Epoch 0: batch 1757/1757
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:37 INFO Epoch 0: batch 1758/1758
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:37 INFO Epoch 0: batch 1759/1759
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:37 INFO Epoch 0: batch 1760/1760
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0910 
2025/02/24 00:54:37 INFO Epoch 0: batch 1761/1761
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0816 
2025/02/24 00:54:37 INFO Epoch 0: batch 1762/1762
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0806 
2025/02/24 00:54:37 INFO Epoch 0: batch 1763/1763
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:37 INFO Epoch 0: batch 1764/1764
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:37 INFO Epoch 0: batch 1765/1765
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:37 INFO Epoch 0: batch 1766/1766
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:37 INFO Epoch 0: batch 1767/1767
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:37 INFO Epoch 0: batch 1768/1768
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:37 INFO Epoch 0: batch 1769/1769
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:37 INFO Epoch 0: batch 1770/1770
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:37 INFO Epoch 0: batch 1771/1771
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:37 INFO Epoch 0: batch 1772/1772
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.1014 
2025/02/24 00:54:37 INFO Epoch 0: batch 1773/1773
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:37 INFO Epoch 0: batch 1774/1774
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0870 
2025/02/24 00:54:37 INFO Epoch 0: batch 1775/1775
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:37 INFO Epoch 0: batch 1776/1776
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:37 INFO Epoch 0: batch 1777/1777
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:37 INFO Epoch 0: batch 1778/1778
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:37 INFO Epoch 0: batch 1779/1779
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0582 
2025/02/24 00:54:37 INFO Epoch 0: batch 1780/1780
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:37 INFO Epoch 0: batch 1781/1781
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0607 
2025/02/24 00:54:37 INFO Epoch 0: batch 1782/1782
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:37 INFO Epoch 0: batch 1783/1783
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:37 INFO Epoch 0: batch 1784/1784
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:37 INFO Epoch 0: batch 1785/1785
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:37 INFO Epoch 0: batch 1786/1786
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:37 INFO Epoch 0: batch 1787/1787
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:37 INFO Epoch 0: batch 1788/1788
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:37 INFO Epoch 0: batch 1789/1789
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:37 INFO Epoch 0: batch 1790/1790
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:37 INFO Epoch 0: batch 1791/1791
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0937 
2025/02/24 00:54:37 INFO Epoch 0: batch 1792/1792
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:37 INFO Epoch 0: batch 1793/1793
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:37 INFO Epoch 0: batch 1794/1794
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:37 INFO Epoch 0: batch 1795/1795
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0846 
2025/02/24 00:54:37 INFO Epoch 0: batch 1796/1796
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:37 INFO Epoch 0: batch 1797/1797
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:37 INFO Epoch 0: batch 1798/1798
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:37 INFO Epoch 0: batch 1799/1799
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:37 INFO Epoch 0: batch 1800/1800
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:37 INFO Epoch 0: batch 1801/1801
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:37 INFO Epoch 0: batch 1802/1802
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:37 INFO Epoch 0: batch 1803/1803
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0926 
2025/02/24 00:54:37 INFO Epoch 0: batch 1804/1804
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:37 INFO Epoch 0: batch 1805/1805
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:37 INFO Epoch 0: batch 1806/1806
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:37 INFO Epoch 0: batch 1807/1807
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:37 INFO Epoch 0: batch 1808/1808
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0481 
2025/02/24 00:54:37 INFO Epoch 0: batch 1809/1809
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:37 INFO Epoch 0: batch 1810/1810
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:37 INFO Epoch 0: batch 1811/1811
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0577 
2025/02/24 00:54:37 INFO Epoch 0: batch 1812/1812
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:37 INFO Epoch 0: batch 1813/1813
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:37 INFO Epoch 0: batch 1814/1814
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0555 
2025/02/24 00:54:37 INFO Epoch 0: batch 1815/1815
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:37 INFO Epoch 0: batch 1816/1816
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:37 INFO Epoch 0: batch 1817/1817
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:37 INFO Epoch 0: batch 1818/1818
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:37 INFO Epoch 0: batch 1819/1819
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:37 INFO Epoch 0: batch 1820/1820
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:37 INFO Epoch 0: batch 1821/1821
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:37 INFO Epoch 0: batch 1822/1822
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:37 INFO Epoch 0: batch 1823/1823
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:37 INFO Epoch 0: batch 1824/1824
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:37 INFO Epoch 0: batch 1825/1825
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0562 
2025/02/24 00:54:37 INFO Epoch 0: batch 1826/1826
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0804 
2025/02/24 00:54:37 INFO Epoch 0: batch 1827/1827
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:37 INFO Epoch 0: batch 1828/1828
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0534 
2025/02/24 00:54:37 INFO Epoch 0: batch 1829/1829
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:37 INFO Epoch 0: batch 1830/1830
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:37 INFO Epoch 0: batch 1831/1831
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:37 INFO Epoch 0: batch 1832/1832
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:37 INFO Epoch 0: batch 1833/1833
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:37 INFO Epoch 0: batch 1834/1834
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:37 INFO Epoch 0: batch 1835/1835
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:37 INFO Epoch 0: batch 1836/1836
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0804 
2025/02/24 00:54:37 INFO Epoch 0: batch 1837/1837
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:37 INFO Epoch 0: batch 1838/1838
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:37 INFO Epoch 0: batch 1839/1839
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0469 
2025/02/24 00:54:37 INFO Epoch 0: batch 1840/1840
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0519 
2025/02/24 00:54:37 INFO Epoch 0: batch 1841/1841
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0925 
2025/02/24 00:54:37 INFO Epoch 0: batch 1842/1842
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:37 INFO Epoch 0: batch 1843/1843
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:37 INFO Epoch 0: batch 1844/1844
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:37 INFO Epoch 0: batch 1845/1845
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:37 INFO Epoch 0: batch 1846/1846
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:37 INFO Epoch 0: batch 1847/1847
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:37 INFO Epoch 0: batch 1848/1848
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:37 INFO Epoch 0: batch 1849/1849
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:37 INFO Epoch 0: batch 1850/1850
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:37 INFO Epoch 0: batch 1851/1851
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:37 INFO Epoch 0: batch 1852/1852
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0517 
2025/02/24 00:54:37 INFO Epoch 0: batch 1853/1853
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:37 INFO Epoch 0: batch 1854/1854
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0540 
2025/02/24 00:54:37 INFO Epoch 0: batch 1855/1855
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:37 INFO Epoch 0: batch 1856/1856
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:37 INFO Epoch 0: batch 1857/1857
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0864 
2025/02/24 00:54:37 INFO Epoch 0: batch 1858/1858
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:37 INFO Epoch 0: batch 1859/1859
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:37 INFO Epoch 0: batch 1860/1860
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.1021 
2025/02/24 00:54:37 INFO Epoch 0: batch 1861/1861
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:37 INFO Epoch 0: batch 1862/1862
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:37 INFO Epoch 0: batch 1863/1863
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0476 
2025/02/24 00:54:37 INFO Epoch 0: batch 1864/1864
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.1021 
2025/02/24 00:54:37 INFO Epoch 0: batch 1865/1865
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0984 
2025/02/24 00:54:37 INFO Epoch 0: batch 1866/1866
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0920 
2025/02/24 00:54:37 INFO Epoch 0: batch 1867/1867
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:37 INFO Epoch 0: batch 1868/1868
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:37 INFO Epoch 0: batch 1869/1869
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:37 INFO Epoch 0: batch 1870/1870
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:37 INFO Epoch 0: batch 1871/1871
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:37 INFO Epoch 0: batch 1872/1872
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:37 INFO Epoch 0: batch 1873/1873
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0922 
2025/02/24 00:54:37 INFO Epoch 0: batch 1874/1874
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:37 INFO Epoch 0: batch 1875/1875
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:37 INFO Epoch 0: batch 1876/1876
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:37 INFO Epoch 0: batch 1877/1877
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0555 
2025/02/24 00:54:37 INFO Epoch 0: batch 1878/1878
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:37 INFO Epoch 0: batch 1879/1879
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:37 INFO Epoch 0: batch 1880/1880
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0587 
2025/02/24 00:54:37 INFO Epoch 0: batch 1881/1881
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:37 INFO Epoch 0: batch 1882/1882
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:37 INFO Epoch 0: batch 1883/1883
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:37 INFO Epoch 0: batch 1884/1884
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:37 INFO Epoch 0: batch 1885/1885
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:37 INFO Epoch 0: batch 1886/1886
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:37 INFO Epoch 0: batch 1887/1887
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0633 
2025/02/24 00:54:37 INFO Epoch 0: batch 1888/1888
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:37 INFO Epoch 0: batch 1889/1889
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:37 INFO Epoch 0: batch 1890/1890
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:37 INFO Epoch 0: batch 1891/1891
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:37 INFO Epoch 0: batch 1892/1892
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:37 INFO Epoch 0: batch 1893/1893
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0971 
2025/02/24 00:54:37 INFO Epoch 0: batch 1894/1894
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0944 
2025/02/24 00:54:37 INFO Epoch 0: batch 1895/1895
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:37 INFO Epoch 0: batch 1896/1896
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:37 INFO Epoch 0: batch 1897/1897
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:37 INFO Epoch 0: batch 1898/1898
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:37 INFO Epoch 0: batch 1899/1899
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:37 INFO Epoch 0: batch 1900/1900
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:37 INFO Epoch 0: batch 1901/1901
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:37 INFO Epoch 0: batch 1902/1902
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:37 INFO Epoch 0: batch 1903/1903
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:37 INFO Epoch 0: batch 1904/1904
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:37 INFO Epoch 0: batch 1905/1905
2025/02/24 00:54:37 INFO          m 0.00010 
2025/02/24 00:54:37 INFO          Training stage 1 Training_loss 0.0561 
2025/02/24 00:54:38 INFO Epoch 0: batch 1906/1906
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:38 INFO Epoch 0: batch 1907/1907
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:38 INFO Epoch 0: batch 1908/1908
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0836 
2025/02/24 00:54:38 INFO Epoch 0: batch 1909/1909
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:38 INFO Epoch 0: batch 1910/1910
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:38 INFO Epoch 0: batch 1911/1911
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:38 INFO Epoch 0: batch 1912/1912
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:38 INFO Epoch 0: batch 1913/1913
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:38 INFO Epoch 0: batch 1914/1914
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:38 INFO Epoch 0: batch 1915/1915
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:38 INFO Epoch 0: batch 1916/1916
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.1031 
2025/02/24 00:54:38 INFO Epoch 0: batch 1917/1917
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:38 INFO Epoch 0: batch 1918/1918
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:38 INFO Epoch 0: batch 1919/1919
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:38 INFO Epoch 0: batch 1920/1920
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:38 INFO Epoch 0: batch 1921/1921
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0604 
2025/02/24 00:54:38 INFO Epoch 0: batch 1922/1922
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:38 INFO Epoch 0: batch 1923/1923
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:38 INFO Epoch 0: batch 1924/1924
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:38 INFO Epoch 0: batch 1925/1925
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:38 INFO Epoch 0: batch 1926/1926
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:38 INFO Epoch 0: batch 1927/1927
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:38 INFO Epoch 0: batch 1928/1928
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:38 INFO Epoch 0: batch 1929/1929
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:38 INFO Epoch 0: batch 1930/1930
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:38 INFO Epoch 0: batch 1931/1931
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:38 INFO Epoch 0: batch 1932/1932
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:38 INFO Epoch 0: batch 1933/1933
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:38 INFO Epoch 0: batch 1934/1934
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:38 INFO Epoch 0: batch 1935/1935
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0453 
2025/02/24 00:54:38 INFO Epoch 0: batch 1936/1936
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0963 
2025/02/24 00:54:38 INFO Epoch 0: batch 1937/1937
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:38 INFO Epoch 0: batch 1938/1938
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0961 
2025/02/24 00:54:38 INFO Epoch 0: batch 1939/1939
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:38 INFO Epoch 0: batch 1940/1940
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:38 INFO Epoch 0: batch 1941/1941
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:38 INFO Epoch 0: batch 1942/1942
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:38 INFO Epoch 0: batch 1943/1943
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:38 INFO Epoch 0: batch 1944/1944
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:38 INFO Epoch 0: batch 1945/1945
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:38 INFO Epoch 0: batch 1946/1946
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:38 INFO Epoch 0: batch 1947/1947
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:38 INFO Epoch 0: batch 1948/1948
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0951 
2025/02/24 00:54:38 INFO Epoch 0: batch 1949/1949
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:38 INFO Epoch 0: batch 1950/1950
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:38 INFO Epoch 0: batch 1951/1951
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:38 INFO Epoch 0: batch 1952/1952
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:38 INFO Epoch 0: batch 1953/1953
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:38 INFO Epoch 0: batch 1954/1954
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:38 INFO Epoch 0: batch 1955/1955
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:38 INFO Epoch 0: batch 1956/1956
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:38 INFO Epoch 0: batch 1957/1957
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:38 INFO Epoch 0: batch 1958/1958
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:38 INFO Epoch 0: batch 1959/1959
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:38 INFO Epoch 0: batch 1960/1960
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:38 INFO Epoch 0: batch 1961/1961
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0532 
2025/02/24 00:54:38 INFO Epoch 0: batch 1962/1962
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:38 INFO Epoch 0: batch 1963/1963
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:38 INFO Epoch 0: batch 1964/1964
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0958 
2025/02/24 00:54:38 INFO Epoch 0: batch 1965/1965
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:38 INFO Epoch 0: batch 1966/1966
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0544 
2025/02/24 00:54:38 INFO Epoch 0: batch 1967/1967
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:38 INFO Epoch 0: batch 1968/1968
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:38 INFO Epoch 0: batch 1969/1969
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0521 
2025/02/24 00:54:38 INFO Epoch 0: batch 1970/1970
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:38 INFO Epoch 0: batch 1971/1971
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0592 
2025/02/24 00:54:38 INFO Epoch 0: batch 1972/1972
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:38 INFO Epoch 0: batch 1973/1973
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:38 INFO Epoch 0: batch 1974/1974
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:38 INFO Epoch 0: batch 1975/1975
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0853 
2025/02/24 00:54:38 INFO Epoch 0: batch 1976/1976
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0578 
2025/02/24 00:54:38 INFO Epoch 0: batch 1977/1977
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:38 INFO Epoch 0: batch 1978/1978
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:38 INFO Epoch 0: batch 1979/1979
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0806 
2025/02/24 00:54:38 INFO Epoch 0: batch 1980/1980
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:38 INFO Epoch 0: batch 1981/1981
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:38 INFO Epoch 0: batch 1982/1982
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0475 
2025/02/24 00:54:38 INFO Epoch 0: batch 1983/1983
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:38 INFO Epoch 0: batch 1984/1984
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:38 INFO Epoch 0: batch 1985/1985
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:38 INFO Epoch 0: batch 1986/1986
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:38 INFO Epoch 0: batch 1987/1987
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:38 INFO Epoch 0: batch 1988/1988
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:38 INFO Epoch 0: batch 1989/1989
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:38 INFO Epoch 0: batch 1990/1990
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:38 INFO Epoch 0: batch 1991/1991
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:38 INFO Epoch 0: batch 1992/1992
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:38 INFO Epoch 0: batch 1993/1993
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:38 INFO Epoch 0: batch 1994/1994
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:38 INFO Epoch 0: batch 1995/1995
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0628 
2025/02/24 00:54:38 INFO Epoch 0: batch 1996/1996
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:38 INFO Epoch 0: batch 1997/1997
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:38 INFO Epoch 0: batch 1998/1998
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0560 
2025/02/24 00:54:38 INFO Epoch 0: batch 1999/1999
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:38 INFO Epoch 0: batch 2000/2000
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:38 INFO Epoch 0: batch 2001/2001
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0920 
2025/02/24 00:54:38 INFO Epoch 0: batch 2002/2002
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0520 
2025/02/24 00:54:38 INFO Epoch 0: batch 2003/2003
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:38 INFO Epoch 0: batch 2004/2004
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0607 
2025/02/24 00:54:38 INFO Epoch 0: batch 2005/2005
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:38 INFO Epoch 0: batch 2006/2006
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:38 INFO Epoch 0: batch 2007/2007
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:38 INFO Epoch 0: batch 2008/2008
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:38 INFO Epoch 0: batch 2009/2009
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:38 INFO Epoch 0: batch 2010/2010
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:38 INFO Epoch 0: batch 2011/2011
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:38 INFO Epoch 0: batch 2012/2012
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:38 INFO Epoch 0: batch 2013/2013
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:38 INFO Epoch 0: batch 2014/2014
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:38 INFO Epoch 0: batch 2015/2015
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:38 INFO Epoch 0: batch 2016/2016
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:38 INFO Epoch 0: batch 2017/2017
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:38 INFO Epoch 0: batch 2018/2018
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:38 INFO Epoch 0: batch 2019/2019
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0502 
2025/02/24 00:54:38 INFO Epoch 0: batch 2020/2020
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:38 INFO Epoch 0: batch 2021/2021
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:38 INFO Epoch 0: batch 2022/2022
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:38 INFO Epoch 0: batch 2023/2023
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:38 INFO Epoch 0: batch 2024/2024
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:38 INFO Epoch 0: batch 2025/2025
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0814 
2025/02/24 00:54:38 INFO Epoch 0: batch 2026/2026
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:38 INFO Epoch 0: batch 2027/2027
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:38 INFO Epoch 0: batch 2028/2028
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:38 INFO Epoch 0: batch 2029/2029
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:38 INFO Epoch 0: batch 2030/2030
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:38 INFO Epoch 0: batch 2031/2031
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0626 
2025/02/24 00:54:38 INFO Epoch 0: batch 2032/2032
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:38 INFO Epoch 0: batch 2033/2033
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:38 INFO Epoch 0: batch 2034/2034
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:38 INFO Epoch 0: batch 2035/2035
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0822 
2025/02/24 00:54:38 INFO Epoch 0: batch 2036/2036
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:38 INFO Epoch 0: batch 2037/2037
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:38 INFO Epoch 0: batch 2038/2038
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:38 INFO Epoch 0: batch 2039/2039
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:38 INFO Epoch 0: batch 2040/2040
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.1035 
2025/02/24 00:54:38 INFO Epoch 0: batch 2041/2041
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:38 INFO Epoch 0: batch 2042/2042
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0903 
2025/02/24 00:54:38 INFO Epoch 0: batch 2043/2043
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:38 INFO Epoch 0: batch 2044/2044
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:38 INFO Epoch 0: batch 2045/2045
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0542 
2025/02/24 00:54:38 INFO Epoch 0: batch 2046/2046
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:38 INFO Epoch 0: batch 2047/2047
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.1051 
2025/02/24 00:54:38 INFO Epoch 0: batch 2048/2048
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0537 
2025/02/24 00:54:38 INFO Epoch 0: batch 2049/2049
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:38 INFO Epoch 0: batch 2050/2050
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0911 
2025/02/24 00:54:38 INFO Epoch 0: batch 2051/2051
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:38 INFO Epoch 0: batch 2052/2052
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:38 INFO Epoch 0: batch 2053/2053
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:38 INFO Epoch 0: batch 2054/2054
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0903 
2025/02/24 00:54:38 INFO Epoch 0: batch 2055/2055
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0916 
2025/02/24 00:54:38 INFO Epoch 0: batch 2056/2056
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:38 INFO Epoch 0: batch 2057/2057
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:38 INFO Epoch 0: batch 2058/2058
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:38 INFO Epoch 0: batch 2059/2059
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:38 INFO Epoch 0: batch 2060/2060
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:38 INFO Epoch 0: batch 2061/2061
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:38 INFO Epoch 0: batch 2062/2062
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:38 INFO Epoch 0: batch 2063/2063
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:38 INFO Epoch 0: batch 2064/2064
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:38 INFO Epoch 0: batch 2065/2065
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0530 
2025/02/24 00:54:38 INFO Epoch 0: batch 2066/2066
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.1005 
2025/02/24 00:54:38 INFO Epoch 0: batch 2067/2067
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:38 INFO Epoch 0: batch 2068/2068
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:38 INFO Epoch 0: batch 2069/2069
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:38 INFO Epoch 0: batch 2070/2070
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:38 INFO Epoch 0: batch 2071/2071
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:38 INFO Epoch 0: batch 2072/2072
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:38 INFO Epoch 0: batch 2073/2073
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:38 INFO Epoch 0: batch 2074/2074
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:38 INFO Epoch 0: batch 2075/2075
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:38 INFO Epoch 0: batch 2076/2076
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:38 INFO Epoch 0: batch 2077/2077
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:38 INFO Epoch 0: batch 2078/2078
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0642 
2025/02/24 00:54:38 INFO Epoch 0: batch 2079/2079
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:38 INFO Epoch 0: batch 2080/2080
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:38 INFO Epoch 0: batch 2081/2081
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:38 INFO Epoch 0: batch 2082/2082
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:38 INFO Epoch 0: batch 2083/2083
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:38 INFO Epoch 0: batch 2084/2084
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:38 INFO Epoch 0: batch 2085/2085
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:38 INFO Epoch 0: batch 2086/2086
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:38 INFO Epoch 0: batch 2087/2087
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0499 
2025/02/24 00:54:38 INFO Epoch 0: batch 2088/2088
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:38 INFO Epoch 0: batch 2089/2089
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0577 
2025/02/24 00:54:38 INFO Epoch 0: batch 2090/2090
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:38 INFO Epoch 0: batch 2091/2091
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:38 INFO Epoch 0: batch 2092/2092
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:38 INFO Epoch 0: batch 2093/2093
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:38 INFO Epoch 0: batch 2094/2094
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:38 INFO Epoch 0: batch 2095/2095
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:38 INFO Epoch 0: batch 2096/2096
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:38 INFO Epoch 0: batch 2097/2097
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:38 INFO Epoch 0: batch 2098/2098
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:38 INFO Epoch 0: batch 2099/2099
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:38 INFO Epoch 0: batch 2100/2100
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:38 INFO Epoch 0: batch 2101/2101
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:38 INFO Epoch 0: batch 2102/2102
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:38 INFO Epoch 0: batch 2103/2103
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:38 INFO Epoch 0: batch 2104/2104
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0894 
2025/02/24 00:54:38 INFO Epoch 0: batch 2105/2105
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:38 INFO Epoch 0: batch 2106/2106
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0800 
2025/02/24 00:54:38 INFO Epoch 0: batch 2107/2107
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:38 INFO Epoch 0: batch 2108/2108
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:38 INFO Epoch 0: batch 2109/2109
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:38 INFO Epoch 0: batch 2110/2110
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:38 INFO Epoch 0: batch 2111/2111
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:38 INFO Epoch 0: batch 2112/2112
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0811 
2025/02/24 00:54:38 INFO Epoch 0: batch 2113/2113
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0968 
2025/02/24 00:54:38 INFO Epoch 0: batch 2114/2114
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:38 INFO Epoch 0: batch 2115/2115
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:38 INFO Epoch 0: batch 2116/2116
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:38 INFO Epoch 0: batch 2117/2117
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:38 INFO Epoch 0: batch 2118/2118
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:38 INFO Epoch 0: batch 2119/2119
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0548 
2025/02/24 00:54:38 INFO Epoch 0: batch 2120/2120
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:38 INFO Epoch 0: batch 2121/2121
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:38 INFO Epoch 0: batch 2122/2122
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:38 INFO Epoch 0: batch 2123/2123
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:38 INFO Epoch 0: batch 2124/2124
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:38 INFO Epoch 0: batch 2125/2125
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0585 
2025/02/24 00:54:38 INFO Epoch 0: batch 2126/2126
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:38 INFO Epoch 0: batch 2127/2127
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:38 INFO Epoch 0: batch 2128/2128
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:38 INFO Epoch 0: batch 2129/2129
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0967 
2025/02/24 00:54:38 INFO Epoch 0: batch 2130/2130
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:38 INFO Epoch 0: batch 2131/2131
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0589 
2025/02/24 00:54:38 INFO Epoch 0: batch 2132/2132
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:38 INFO Epoch 0: batch 2133/2133
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0906 
2025/02/24 00:54:38 INFO Epoch 0: batch 2134/2134
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:38 INFO Epoch 0: batch 2135/2135
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:38 INFO Epoch 0: batch 2136/2136
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:38 INFO Epoch 0: batch 2137/2137
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:38 INFO Epoch 0: batch 2138/2138
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:38 INFO Epoch 0: batch 2139/2139
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:38 INFO Epoch 0: batch 2140/2140
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:38 INFO Epoch 0: batch 2141/2141
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:38 INFO Epoch 0: batch 2142/2142
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:38 INFO Epoch 0: batch 2143/2143
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:38 INFO Epoch 0: batch 2144/2144
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:38 INFO Epoch 0: batch 2145/2145
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:38 INFO Epoch 0: batch 2146/2146
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:38 INFO Epoch 0: batch 2147/2147
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:38 INFO Epoch 0: batch 2148/2148
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:38 INFO Epoch 0: batch 2149/2149
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:38 INFO Epoch 0: batch 2150/2150
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:38 INFO Epoch 0: batch 2151/2151
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:38 INFO Epoch 0: batch 2152/2152
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:38 INFO Epoch 0: batch 2153/2153
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0931 
2025/02/24 00:54:38 INFO Epoch 0: batch 2154/2154
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:38 INFO Epoch 0: batch 2155/2155
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:38 INFO Epoch 0: batch 2156/2156
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:38 INFO Epoch 0: batch 2157/2157
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:38 INFO Epoch 0: batch 2158/2158
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:38 INFO Epoch 0: batch 2159/2159
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:38 INFO Epoch 0: batch 2160/2160
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0943 
2025/02/24 00:54:38 INFO Epoch 0: batch 2161/2161
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:38 INFO Epoch 0: batch 2162/2162
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:38 INFO Epoch 0: batch 2163/2163
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:38 INFO Epoch 0: batch 2164/2164
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:38 INFO Epoch 0: batch 2165/2165
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:38 INFO Epoch 0: batch 2166/2166
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0575 
2025/02/24 00:54:38 INFO Epoch 0: batch 2167/2167
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:38 INFO Epoch 0: batch 2168/2168
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:38 INFO Epoch 0: batch 2169/2169
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:38 INFO Epoch 0: batch 2170/2170
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:38 INFO Epoch 0: batch 2171/2171
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:38 INFO Epoch 0: batch 2172/2172
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:38 INFO Epoch 0: batch 2173/2173
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:38 INFO Epoch 0: batch 2174/2174
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:38 INFO Epoch 0: batch 2175/2175
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:38 INFO Epoch 0: batch 2176/2176
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:38 INFO Epoch 0: batch 2177/2177
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:38 INFO Epoch 0: batch 2178/2178
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:38 INFO Epoch 0: batch 2179/2179
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:38 INFO Epoch 0: batch 2180/2180
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:38 INFO Epoch 0: batch 2181/2181
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:38 INFO Epoch 0: batch 2182/2182
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:38 INFO Epoch 0: batch 2183/2183
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:38 INFO Epoch 0: batch 2184/2184
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0935 
2025/02/24 00:54:38 INFO Epoch 0: batch 2185/2185
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:38 INFO Epoch 0: batch 2186/2186
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:38 INFO Epoch 0: batch 2187/2187
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0609 
2025/02/24 00:54:38 INFO Epoch 0: batch 2188/2188
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:38 INFO Epoch 0: batch 2189/2189
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:38 INFO Epoch 0: batch 2190/2190
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0730 
2025/02/24 00:54:38 INFO Epoch 0: batch 2191/2191
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0573 
2025/02/24 00:54:38 INFO Epoch 0: batch 2192/2192
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:38 INFO Epoch 0: batch 2193/2193
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:38 INFO Epoch 0: batch 2194/2194
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0932 
2025/02/24 00:54:38 INFO Epoch 0: batch 2195/2195
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:38 INFO Epoch 0: batch 2196/2196
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:38 INFO Epoch 0: batch 2197/2197
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:38 INFO Epoch 0: batch 2198/2198
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:38 INFO Epoch 0: batch 2199/2199
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0502 
2025/02/24 00:54:38 INFO Epoch 0: batch 2200/2200
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:38 INFO Epoch 0: batch 2201/2201
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:38 INFO Epoch 0: batch 2202/2202
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0870 
2025/02/24 00:54:38 INFO Epoch 0: batch 2203/2203
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:38 INFO Epoch 0: batch 2204/2204
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:38 INFO Epoch 0: batch 2205/2205
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:38 INFO Epoch 0: batch 2206/2206
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:38 INFO Epoch 0: batch 2207/2207
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:38 INFO Epoch 0: batch 2208/2208
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:38 INFO Epoch 0: batch 2209/2209
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:38 INFO Epoch 0: batch 2210/2210
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:38 INFO Epoch 0: batch 2211/2211
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0859 
2025/02/24 00:54:38 INFO Epoch 0: batch 2212/2212
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:38 INFO Epoch 0: batch 2213/2213
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:38 INFO Epoch 0: batch 2214/2214
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0885 
2025/02/24 00:54:38 INFO Epoch 0: batch 2215/2215
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:38 INFO Epoch 0: batch 2216/2216
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:38 INFO Epoch 0: batch 2217/2217
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:38 INFO Epoch 0: batch 2218/2218
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:38 INFO Epoch 0: batch 2219/2219
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:38 INFO Epoch 0: batch 2220/2220
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:38 INFO Epoch 0: batch 2221/2221
2025/02/24 00:54:38 INFO          m 0.00010 
2025/02/24 00:54:38 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:39 INFO Epoch 0: batch 2222/2222
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:39 INFO Epoch 0: batch 2223/2223
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:39 INFO Epoch 0: batch 2224/2224
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0914 
2025/02/24 00:54:39 INFO Epoch 0: batch 2225/2225
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0854 
2025/02/24 00:54:39 INFO Epoch 0: batch 2226/2226
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:39 INFO Epoch 0: batch 2227/2227
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:39 INFO Epoch 0: batch 2228/2228
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:39 INFO Epoch 0: batch 2229/2229
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0923 
2025/02/24 00:54:39 INFO Epoch 0: batch 2230/2230
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:39 INFO Epoch 0: batch 2231/2231
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:39 INFO Epoch 0: batch 2232/2232
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:39 INFO Epoch 0: batch 2233/2233
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:39 INFO Epoch 0: batch 2234/2234
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:39 INFO Epoch 0: batch 2235/2235
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:39 INFO Epoch 0: batch 2236/2236
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:39 INFO Epoch 0: batch 2237/2237
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:39 INFO Epoch 0: batch 2238/2238
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:39 INFO Epoch 0: batch 2239/2239
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:39 INFO Epoch 0: batch 2240/2240
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:39 INFO Epoch 0: batch 2241/2241
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:39 INFO Epoch 0: batch 2242/2242
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:39 INFO Epoch 0: batch 2243/2243
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:39 INFO Epoch 0: batch 2244/2244
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:39 INFO Epoch 0: batch 2245/2245
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:39 INFO Epoch 0: batch 2246/2246
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0878 
2025/02/24 00:54:39 INFO Epoch 0: batch 2247/2247
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:39 INFO Epoch 0: batch 2248/2248
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:39 INFO Epoch 0: batch 2249/2249
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:39 INFO Epoch 0: batch 2250/2250
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:39 INFO Epoch 0: batch 2251/2251
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0992 
2025/02/24 00:54:39 INFO Epoch 0: batch 2252/2252
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0811 
2025/02/24 00:54:39 INFO Epoch 0: batch 2253/2253
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:39 INFO Epoch 0: batch 2254/2254
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:39 INFO Epoch 0: batch 2255/2255
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:39 INFO Epoch 0: batch 2256/2256
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:39 INFO Epoch 0: batch 2257/2257
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0877 
2025/02/24 00:54:39 INFO Epoch 0: batch 2258/2258
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1006 
2025/02/24 00:54:39 INFO Epoch 0: batch 2259/2259
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:39 INFO Epoch 0: batch 2260/2260
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0901 
2025/02/24 00:54:39 INFO Epoch 0: batch 2261/2261
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0901 
2025/02/24 00:54:39 INFO Epoch 0: batch 2262/2262
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0998 
2025/02/24 00:54:39 INFO Epoch 0: batch 2263/2263
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:39 INFO Epoch 0: batch 2264/2264
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:39 INFO Epoch 0: batch 2265/2265
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:39 INFO Epoch 0: batch 2266/2266
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:39 INFO Epoch 0: batch 2267/2267
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:39 INFO Epoch 0: batch 2268/2268
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:39 INFO Epoch 0: batch 2269/2269
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:39 INFO Epoch 0: batch 2270/2270
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:39 INFO Epoch 0: batch 2271/2271
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:39 INFO Epoch 0: batch 2272/2272
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0571 
2025/02/24 00:54:39 INFO Epoch 0: batch 2273/2273
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:39 INFO Epoch 0: batch 2274/2274
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0910 
2025/02/24 00:54:39 INFO Epoch 0: batch 2275/2275
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:39 INFO Epoch 0: batch 2276/2276
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:39 INFO Epoch 0: batch 2277/2277
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0876 
2025/02/24 00:54:39 INFO Epoch 0: batch 2278/2278
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0992 
2025/02/24 00:54:39 INFO Epoch 0: batch 2279/2279
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:39 INFO Epoch 0: batch 2280/2280
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1170 
2025/02/24 00:54:39 INFO Epoch 0: batch 2281/2281
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:39 INFO Epoch 0: batch 2282/2282
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:39 INFO Epoch 0: batch 2283/2283
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:39 INFO Epoch 0: batch 2284/2284
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0949 
2025/02/24 00:54:39 INFO Epoch 0: batch 2285/2285
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:39 INFO Epoch 0: batch 2286/2286
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:39 INFO Epoch 0: batch 2287/2287
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0645 
2025/02/24 00:54:39 INFO Epoch 0: batch 2288/2288
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:39 INFO Epoch 0: batch 2289/2289
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:39 INFO Epoch 0: batch 2290/2290
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:39 INFO Epoch 0: batch 2291/2291
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:39 INFO Epoch 0: batch 2292/2292
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:39 INFO Epoch 0: batch 2293/2293
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0680 
2025/02/24 00:54:39 INFO Epoch 0: batch 2294/2294
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:39 INFO Epoch 0: batch 2295/2295
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0918 
2025/02/24 00:54:39 INFO Epoch 0: batch 2296/2296
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:39 INFO Epoch 0: batch 2297/2297
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:39 INFO Epoch 0: batch 2298/2298
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:39 INFO Epoch 0: batch 2299/2299
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:39 INFO Epoch 0: batch 2300/2300
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:39 INFO Epoch 0: batch 2301/2301
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0869 
2025/02/24 00:54:39 INFO Epoch 0: batch 2302/2302
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0831 
2025/02/24 00:54:39 INFO Epoch 0: batch 2303/2303
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:39 INFO Epoch 0: batch 2304/2304
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:39 INFO Epoch 0: batch 2305/2305
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:39 INFO Epoch 0: batch 2306/2306
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0924 
2025/02/24 00:54:39 INFO Epoch 0: batch 2307/2307
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0895 
2025/02/24 00:54:39 INFO Epoch 0: batch 2308/2308
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:39 INFO Epoch 0: batch 2309/2309
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:39 INFO Epoch 0: batch 2310/2310
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:39 INFO Epoch 0: batch 2311/2311
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:39 INFO Epoch 0: batch 2312/2312
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:39 INFO Epoch 0: batch 2313/2313
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:39 INFO Epoch 0: batch 2314/2314
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:39 INFO Epoch 0: batch 2315/2315
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:39 INFO Epoch 0: batch 2316/2316
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:39 INFO Epoch 0: batch 2317/2317
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:39 INFO Epoch 0: batch 2318/2318
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:39 INFO Epoch 0: batch 2319/2319
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:39 INFO Epoch 0: batch 2320/2320
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:39 INFO Epoch 0: batch 2321/2321
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:39 INFO Epoch 0: batch 2322/2322
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:39 INFO Epoch 0: batch 2323/2323
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:39 INFO Epoch 0: batch 2324/2324
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:39 INFO Epoch 0: batch 2325/2325
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0831 
2025/02/24 00:54:39 INFO Epoch 0: batch 2326/2326
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:39 INFO Epoch 0: batch 2327/2327
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:39 INFO Epoch 0: batch 2328/2328
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:39 INFO Epoch 0: batch 2329/2329
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:39 INFO Epoch 0: batch 2330/2330
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0559 
2025/02/24 00:54:39 INFO Epoch 0: batch 2331/2331
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:39 INFO Epoch 0: batch 2332/2332
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0596 
2025/02/24 00:54:39 INFO Epoch 0: batch 2333/2333
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0609 
2025/02/24 00:54:39 INFO Epoch 0: batch 2334/2334
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:39 INFO Epoch 0: batch 2335/2335
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:39 INFO Epoch 0: batch 2336/2336
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:39 INFO Epoch 0: batch 2337/2337
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:39 INFO Epoch 0: batch 2338/2338
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:39 INFO Epoch 0: batch 2339/2339
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:39 INFO Epoch 0: batch 2340/2340
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:39 INFO Epoch 0: batch 2341/2341
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0509 
2025/02/24 00:54:39 INFO Epoch 0: batch 2342/2342
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:39 INFO Epoch 0: batch 2343/2343
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:39 INFO Epoch 0: batch 2344/2344
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:39 INFO Epoch 0: batch 2345/2345
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:39 INFO Epoch 0: batch 2346/2346
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:39 INFO Epoch 0: batch 2347/2347
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:39 INFO Epoch 0: batch 2348/2348
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:39 INFO Epoch 0: batch 2349/2349
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:39 INFO Epoch 0: batch 2350/2350
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1119 
2025/02/24 00:54:39 INFO Epoch 0: batch 2351/2351
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:39 INFO Epoch 0: batch 2352/2352
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0921 
2025/02/24 00:54:39 INFO Epoch 0: batch 2353/2353
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:39 INFO Epoch 0: batch 2354/2354
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0822 
2025/02/24 00:54:39 INFO Epoch 0: batch 2355/2355
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0590 
2025/02/24 00:54:39 INFO Epoch 0: batch 2356/2356
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:39 INFO Epoch 0: batch 2357/2357
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0914 
2025/02/24 00:54:39 INFO Epoch 0: batch 2358/2358
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:39 INFO Epoch 0: batch 2359/2359
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0882 
2025/02/24 00:54:39 INFO Epoch 0: batch 2360/2360
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:39 INFO Epoch 0: batch 2361/2361
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:39 INFO Epoch 0: batch 2362/2362
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:39 INFO Epoch 0: batch 2363/2363
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:39 INFO Epoch 0: batch 2364/2364
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:39 INFO Epoch 0: batch 2365/2365
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0510 
2025/02/24 00:54:39 INFO Epoch 0: batch 2366/2366
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:39 INFO Epoch 0: batch 2367/2367
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:39 INFO Epoch 0: batch 2368/2368
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:39 INFO Epoch 0: batch 2369/2369
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:39 INFO Epoch 0: batch 2370/2370
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:39 INFO Epoch 0: batch 2371/2371
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:39 INFO Epoch 0: batch 2372/2372
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:39 INFO Epoch 0: batch 2373/2373
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:39 INFO Epoch 0: batch 2374/2374
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:39 INFO Epoch 0: batch 2375/2375
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0897 
2025/02/24 00:54:39 INFO Epoch 0: batch 2376/2376
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0981 
2025/02/24 00:54:39 INFO Epoch 0: batch 2377/2377
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:39 INFO Epoch 0: batch 2378/2378
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:39 INFO Epoch 0: batch 2379/2379
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:39 INFO Epoch 0: batch 2380/2380
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:39 INFO Epoch 0: batch 2381/2381
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0623 
2025/02/24 00:54:39 INFO Epoch 0: batch 2382/2382
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:39 INFO Epoch 0: batch 2383/2383
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:39 INFO Epoch 0: batch 2384/2384
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:39 INFO Epoch 0: batch 2385/2385
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:39 INFO Epoch 0: batch 2386/2386
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:39 INFO Epoch 0: batch 2387/2387
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:39 INFO Epoch 0: batch 2388/2388
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:39 INFO Epoch 0: batch 2389/2389
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:39 INFO Epoch 0: batch 2390/2390
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:39 INFO Epoch 0: batch 2391/2391
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:39 INFO Epoch 0: batch 2392/2392
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:39 INFO Epoch 0: batch 2393/2393
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:39 INFO Epoch 0: batch 2394/2394
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0544 
2025/02/24 00:54:39 INFO Epoch 0: batch 2395/2395
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:39 INFO Epoch 0: batch 2396/2396
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0854 
2025/02/24 00:54:39 INFO Epoch 0: batch 2397/2397
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:39 INFO Epoch 0: batch 2398/2398
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:39 INFO Epoch 0: batch 2399/2399
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:39 INFO Epoch 0: batch 2400/2400
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:39 INFO Epoch 0: batch 2401/2401
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:39 INFO Epoch 0: batch 2402/2402
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0931 
2025/02/24 00:54:39 INFO Epoch 0: batch 2403/2403
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:39 INFO Epoch 0: batch 2404/2404
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0534 
2025/02/24 00:54:39 INFO Epoch 0: batch 2405/2405
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:39 INFO Epoch 0: batch 2406/2406
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:39 INFO Epoch 0: batch 2407/2407
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:39 INFO Epoch 0: batch 2408/2408
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:39 INFO Epoch 0: batch 2409/2409
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:39 INFO Epoch 0: batch 2410/2410
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0886 
2025/02/24 00:54:39 INFO Epoch 0: batch 2411/2411
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:39 INFO Epoch 0: batch 2412/2412
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:39 INFO Epoch 0: batch 2413/2413
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:39 INFO Epoch 0: batch 2414/2414
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0501 
2025/02/24 00:54:39 INFO Epoch 0: batch 2415/2415
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:39 INFO Epoch 0: batch 2416/2416
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:39 INFO Epoch 0: batch 2417/2417
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:39 INFO Epoch 0: batch 2418/2418
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:39 INFO Epoch 0: batch 2419/2419
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0521 
2025/02/24 00:54:39 INFO Epoch 0: batch 2420/2420
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:39 INFO Epoch 0: batch 2421/2421
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:39 INFO Epoch 0: batch 2422/2422
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:39 INFO Epoch 0: batch 2423/2423
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0924 
2025/02/24 00:54:39 INFO Epoch 0: batch 2424/2424
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:39 INFO Epoch 0: batch 2425/2425
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1016 
2025/02/24 00:54:39 INFO Epoch 0: batch 2426/2426
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0988 
2025/02/24 00:54:39 INFO Epoch 0: batch 2427/2427
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:39 INFO Epoch 0: batch 2428/2428
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:39 INFO Epoch 0: batch 2429/2429
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:39 INFO Epoch 0: batch 2430/2430
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:39 INFO Epoch 0: batch 2431/2431
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0883 
2025/02/24 00:54:39 INFO Epoch 0: batch 2432/2432
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:39 INFO Epoch 0: batch 2433/2433
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:39 INFO Epoch 0: batch 2434/2434
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0905 
2025/02/24 00:54:39 INFO Epoch 0: batch 2435/2435
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:39 INFO Epoch 0: batch 2436/2436
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0586 
2025/02/24 00:54:39 INFO Epoch 0: batch 2437/2437
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:39 INFO Epoch 0: batch 2438/2438
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:39 INFO Epoch 0: batch 2439/2439
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:39 INFO Epoch 0: batch 2440/2440
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:39 INFO Epoch 0: batch 2441/2441
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1006 
2025/02/24 00:54:39 INFO Epoch 0: batch 2442/2442
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0795 
2025/02/24 00:54:39 INFO Epoch 0: batch 2443/2443
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0903 
2025/02/24 00:54:39 INFO Epoch 0: batch 2444/2444
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0859 
2025/02/24 00:54:39 INFO Epoch 0: batch 2445/2445
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:39 INFO Epoch 0: batch 2446/2446
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:39 INFO Epoch 0: batch 2447/2447
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1002 
2025/02/24 00:54:39 INFO Epoch 0: batch 2448/2448
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.1055 
2025/02/24 00:54:39 INFO Epoch 0: batch 2449/2449
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:39 INFO Epoch 0: batch 2450/2450
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:39 INFO Epoch 0: batch 2451/2451
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:39 INFO Epoch 0: batch 2452/2452
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:39 INFO Epoch 0: batch 2453/2453
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:39 INFO Epoch 0: batch 2454/2454
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:39 INFO Epoch 0: batch 2455/2455
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:39 INFO Epoch 0: batch 2456/2456
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:39 INFO Epoch 0: batch 2457/2457
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:39 INFO Epoch 0: batch 2458/2458
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:39 INFO Epoch 0: batch 2459/2459
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:39 INFO Epoch 0: batch 2460/2460
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0558 
2025/02/24 00:54:39 INFO Epoch 0: batch 2461/2461
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:39 INFO Epoch 0: batch 2462/2462
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:39 INFO Epoch 0: batch 2463/2463
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:39 INFO Epoch 0: batch 2464/2464
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:39 INFO Epoch 0: batch 2465/2465
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:39 INFO Epoch 0: batch 2466/2466
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0926 
2025/02/24 00:54:39 INFO Epoch 0: batch 2467/2467
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:39 INFO Epoch 0: batch 2468/2468
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0921 
2025/02/24 00:54:39 INFO Epoch 0: batch 2469/2469
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:39 INFO Epoch 0: batch 2470/2470
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:39 INFO Epoch 0: batch 2471/2471
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0912 
2025/02/24 00:54:39 INFO Epoch 0: batch 2472/2472
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:39 INFO Epoch 0: batch 2473/2473
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:39 INFO Epoch 0: batch 2474/2474
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:39 INFO Epoch 0: batch 2475/2475
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0645 
2025/02/24 00:54:39 INFO Epoch 0: batch 2476/2476
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:39 INFO Epoch 0: batch 2477/2477
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0965 
2025/02/24 00:54:39 INFO Epoch 0: batch 2478/2478
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:39 INFO Epoch 0: batch 2479/2479
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:39 INFO Epoch 0: batch 2480/2480
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:39 INFO Epoch 0: batch 2481/2481
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0599 
2025/02/24 00:54:39 INFO Epoch 0: batch 2482/2482
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0977 
2025/02/24 00:54:39 INFO Epoch 0: batch 2483/2483
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:39 INFO Epoch 0: batch 2484/2484
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:39 INFO Epoch 0: batch 2485/2485
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:39 INFO Epoch 0: batch 2486/2486
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:39 INFO Epoch 0: batch 2487/2487
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:39 INFO Epoch 0: batch 2488/2488
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:39 INFO Epoch 0: batch 2489/2489
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:39 INFO Epoch 0: batch 2490/2490
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:39 INFO Epoch 0: batch 2491/2491
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:39 INFO Epoch 0: batch 2492/2492
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:39 INFO Epoch 0: batch 2493/2493
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:39 INFO Epoch 0: batch 2494/2494
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:39 INFO Epoch 0: batch 2495/2495
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:39 INFO Epoch 0: batch 2496/2496
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:39 INFO Epoch 0: batch 2497/2497
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0586 
2025/02/24 00:54:39 INFO Epoch 0: batch 2498/2498
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:39 INFO Epoch 0: batch 2499/2499
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:39 INFO Epoch 0: batch 2500/2500
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:39 INFO Epoch 0: batch 2501/2501
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:39 INFO Epoch 0: batch 2502/2502
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:39 INFO Epoch 0: batch 2503/2503
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:39 INFO Epoch 0: batch 2504/2504
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0799 
2025/02/24 00:54:39 INFO Epoch 0: batch 2505/2505
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0848 
2025/02/24 00:54:39 INFO Epoch 0: batch 2506/2506
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:39 INFO Epoch 0: batch 2507/2507
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0584 
2025/02/24 00:54:39 INFO Epoch 0: batch 2508/2508
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:39 INFO Epoch 0: batch 2509/2509
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:39 INFO Epoch 0: batch 2510/2510
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:39 INFO Epoch 0: batch 2511/2511
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:39 INFO Epoch 0: batch 2512/2512
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:39 INFO Epoch 0: batch 2513/2513
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:39 INFO Epoch 0: batch 2514/2514
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:39 INFO Epoch 0: batch 2515/2515
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:39 INFO Epoch 0: batch 2516/2516
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:39 INFO Epoch 0: batch 2517/2517
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0929 
2025/02/24 00:54:39 INFO Epoch 0: batch 2518/2518
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0711 
2025/02/24 00:54:39 INFO Epoch 0: batch 2519/2519
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:39 INFO Epoch 0: batch 2520/2520
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:39 INFO Epoch 0: batch 2521/2521
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:39 INFO Epoch 0: batch 2522/2522
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:39 INFO Epoch 0: batch 2523/2523
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:39 INFO Epoch 0: batch 2524/2524
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0795 
2025/02/24 00:54:39 INFO Epoch 0: batch 2525/2525
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:39 INFO Epoch 0: batch 2526/2526
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:39 INFO Epoch 0: batch 2527/2527
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:39 INFO Epoch 0: batch 2528/2528
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:39 INFO Epoch 0: batch 2529/2529
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:39 INFO Epoch 0: batch 2530/2530
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:39 INFO Epoch 0: batch 2531/2531
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0633 
2025/02/24 00:54:39 INFO Epoch 0: batch 2532/2532
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:39 INFO Epoch 0: batch 2533/2533
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:39 INFO Epoch 0: batch 2534/2534
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0523 
2025/02/24 00:54:39 INFO Epoch 0: batch 2535/2535
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:39 INFO Epoch 0: batch 2536/2536
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:39 INFO Epoch 0: batch 2537/2537
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:39 INFO Epoch 0: batch 2538/2538
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:39 INFO Epoch 0: batch 2539/2539
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0604 
2025/02/24 00:54:39 INFO Epoch 0: batch 2540/2540
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:39 INFO Epoch 0: batch 2541/2541
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:39 INFO Epoch 0: batch 2542/2542
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:39 INFO Epoch 0: batch 2543/2543
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:39 INFO Epoch 0: batch 2544/2544
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:39 INFO Epoch 0: batch 2545/2545
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:39 INFO Epoch 0: batch 2546/2546
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:39 INFO Epoch 0: batch 2547/2547
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0645 
2025/02/24 00:54:39 INFO Epoch 0: batch 2548/2548
2025/02/24 00:54:39 INFO          m 0.00010 
2025/02/24 00:54:39 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:40 INFO Epoch 0: batch 2549/2549
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:40 INFO Epoch 0: batch 2550/2550
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0573 
2025/02/24 00:54:40 INFO Epoch 0: batch 2551/2551
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:40 INFO Epoch 0: batch 2552/2552
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:40 INFO Epoch 0: batch 2553/2553
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:40 INFO Epoch 0: batch 2554/2554
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:40 INFO Epoch 0: batch 2555/2555
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:40 INFO Epoch 0: batch 2556/2556
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:40 INFO Epoch 0: batch 2557/2557
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:40 INFO Epoch 0: batch 2558/2558
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:40 INFO Epoch 0: batch 2559/2559
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:40 INFO Epoch 0: batch 2560/2560
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:40 INFO Epoch 0: batch 2561/2561
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0998 
2025/02/24 00:54:40 INFO Epoch 0: batch 2562/2562
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:40 INFO Epoch 0: batch 2563/2563
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:40 INFO Epoch 0: batch 2564/2564
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:40 INFO Epoch 0: batch 2565/2565
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:40 INFO Epoch 0: batch 2566/2566
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:40 INFO Epoch 0: batch 2567/2567
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:40 INFO Epoch 0: batch 2568/2568
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:40 INFO Epoch 0: batch 2569/2569
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0516 
2025/02/24 00:54:40 INFO Epoch 0: batch 2570/2570
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0505 
2025/02/24 00:54:40 INFO Epoch 0: batch 2571/2571
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:40 INFO Epoch 0: batch 2572/2572
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:40 INFO Epoch 0: batch 2573/2573
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:40 INFO Epoch 0: batch 2574/2574
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:40 INFO Epoch 0: batch 2575/2575
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:40 INFO Epoch 0: batch 2576/2576
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:40 INFO Epoch 0: batch 2577/2577
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:40 INFO Epoch 0: batch 2578/2578
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0540 
2025/02/24 00:54:40 INFO Epoch 0: batch 2579/2579
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0941 
2025/02/24 00:54:40 INFO Epoch 0: batch 2580/2580
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:40 INFO Epoch 0: batch 2581/2581
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:40 INFO Epoch 0: batch 2582/2582
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:40 INFO Epoch 0: batch 2583/2583
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:40 INFO Epoch 0: batch 2584/2584
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:40 INFO Epoch 0: batch 2585/2585
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:40 INFO Epoch 0: batch 2586/2586
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:40 INFO Epoch 0: batch 2587/2587
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:40 INFO Epoch 0: batch 2588/2588
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:40 INFO Epoch 0: batch 2589/2589
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:40 INFO Epoch 0: batch 2590/2590
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.1030 
2025/02/24 00:54:40 INFO Epoch 0: batch 2591/2591
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:40 INFO Epoch 0: batch 2592/2592
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:40 INFO Epoch 0: batch 2593/2593
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:40 INFO Epoch 0: batch 2594/2594
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:40 INFO Epoch 0: batch 2595/2595
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:40 INFO Epoch 0: batch 2596/2596
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:40 INFO Epoch 0: batch 2597/2597
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:40 INFO Epoch 0: batch 2598/2598
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:40 INFO Epoch 0: batch 2599/2599
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:40 INFO Epoch 0: batch 2600/2600
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:40 INFO Epoch 0: batch 2601/2601
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:40 INFO Epoch 0: batch 2602/2602
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:40 INFO Epoch 0: batch 2603/2603
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:40 INFO Epoch 0: batch 2604/2604
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0566 
2025/02/24 00:54:40 INFO Epoch 0: batch 2605/2605
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:40 INFO Epoch 0: batch 2606/2606
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:40 INFO Epoch 0: batch 2607/2607
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0850 
2025/02/24 00:54:40 INFO Epoch 0: batch 2608/2608
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:40 INFO Epoch 0: batch 2609/2609
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:40 INFO Epoch 0: batch 2610/2610
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:40 INFO Epoch 0: batch 2611/2611
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0996 
2025/02/24 00:54:40 INFO Epoch 0: batch 2612/2612
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:40 INFO Epoch 0: batch 2613/2613
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:40 INFO Epoch 0: batch 2614/2614
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0551 
2025/02/24 00:54:40 INFO Epoch 0: batch 2615/2615
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:40 INFO Epoch 0: batch 2616/2616
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:40 INFO Epoch 0: batch 2617/2617
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:40 INFO Epoch 0: batch 2618/2618
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:40 INFO Epoch 0: batch 2619/2619
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:40 INFO Epoch 0: batch 2620/2620
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:40 INFO Epoch 0: batch 2621/2621
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:40 INFO Epoch 0: batch 2622/2622
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0580 
2025/02/24 00:54:40 INFO Epoch 0: batch 2623/2623
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0534 
2025/02/24 00:54:40 INFO Epoch 0: batch 2624/2624
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:40 INFO Epoch 0: batch 2625/2625
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:40 INFO Epoch 0: batch 2626/2626
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:40 INFO Epoch 0: batch 2627/2627
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:40 INFO Epoch 0: batch 2628/2628
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:40 INFO Epoch 0: batch 2629/2629
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:40 INFO Epoch 0: batch 2630/2630
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:40 INFO Epoch 0: batch 2631/2631
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:40 INFO Epoch 0: batch 2632/2632
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:40 INFO Epoch 0: batch 2633/2633
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:40 INFO Epoch 0: batch 2634/2634
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:40 INFO Epoch 0: batch 2635/2635
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0609 
2025/02/24 00:54:40 INFO Epoch 0: batch 2636/2636
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:40 INFO Epoch 0: batch 2637/2637
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:40 INFO Epoch 0: batch 2638/2638
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:40 INFO Epoch 0: batch 2639/2639
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0931 
2025/02/24 00:54:40 INFO Epoch 0: batch 2640/2640
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:40 INFO Epoch 0: batch 2641/2641
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:40 INFO Epoch 0: batch 2642/2642
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:40 INFO Epoch 0: batch 2643/2643
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:40 INFO Epoch 0: batch 2644/2644
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:40 INFO Epoch 0: batch 2645/2645
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:40 INFO Epoch 0: batch 2646/2646
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:40 INFO Epoch 0: batch 2647/2647
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:40 INFO Epoch 0: batch 2648/2648
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:40 INFO Epoch 0: batch 2649/2649
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:40 INFO Epoch 0: batch 2650/2650
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:40 INFO Epoch 0: batch 2651/2651
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0531 
2025/02/24 00:54:40 INFO Epoch 0: batch 2652/2652
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:40 INFO Epoch 0: batch 2653/2653
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:40 INFO Epoch 0: batch 2654/2654
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:40 INFO Epoch 0: batch 2655/2655
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:40 INFO Epoch 0: batch 2656/2656
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:40 INFO Epoch 0: batch 2657/2657
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:40 INFO Epoch 0: batch 2658/2658
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:40 INFO Epoch 0: batch 2659/2659
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:40 INFO Epoch 0: batch 2660/2660
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:40 INFO Epoch 0: batch 2661/2661
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:40 INFO Epoch 0: batch 2662/2662
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0557 
2025/02/24 00:54:40 INFO Epoch 0: batch 2663/2663
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:40 INFO Epoch 0: batch 2664/2664
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:40 INFO Epoch 0: batch 2665/2665
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:40 INFO Epoch 0: batch 2666/2666
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:40 INFO Epoch 0: batch 2667/2667
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:40 INFO Epoch 0: batch 2668/2668
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0814 
2025/02/24 00:54:40 INFO Epoch 0: batch 2669/2669
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:40 INFO Epoch 0: batch 2670/2670
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:40 INFO Epoch 0: batch 2671/2671
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:40 INFO Epoch 0: batch 2672/2672
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:40 INFO Epoch 0: batch 2673/2673
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:40 INFO Epoch 0: batch 2674/2674
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:40 INFO Epoch 0: batch 2675/2675
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:40 INFO Epoch 0: batch 2676/2676
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0915 
2025/02/24 00:54:40 INFO Epoch 0: batch 2677/2677
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0952 
2025/02/24 00:54:40 INFO Epoch 0: batch 2678/2678
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:40 INFO Epoch 0: batch 2679/2679
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:40 INFO Epoch 0: batch 2680/2680
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:40 INFO Epoch 0: batch 2681/2681
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0896 
2025/02/24 00:54:40 INFO Epoch 0: batch 2682/2682
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:40 INFO Epoch 0: batch 2683/2683
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:40 INFO Epoch 0: batch 2684/2684
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0614 
2025/02/24 00:54:40 INFO Epoch 0: batch 2685/2685
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:40 INFO Epoch 0: batch 2686/2686
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:40 INFO Epoch 0: batch 2687/2687
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:40 INFO Epoch 0: batch 2688/2688
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:40 INFO Epoch 0: batch 2689/2689
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:40 INFO Epoch 0: batch 2690/2690
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0870 
2025/02/24 00:54:40 INFO Epoch 0: batch 2691/2691
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.1082 
2025/02/24 00:54:40 INFO Epoch 0: batch 2692/2692
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:40 INFO Epoch 0: batch 2693/2693
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:40 INFO Epoch 0: batch 2694/2694
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:40 INFO Epoch 0: batch 2695/2695
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:40 INFO Epoch 0: batch 2696/2696
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:40 INFO Epoch 0: batch 2697/2697
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:40 INFO Epoch 0: batch 2698/2698
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:40 INFO Epoch 0: batch 2699/2699
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:40 INFO Epoch 0: batch 2700/2700
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:40 INFO Epoch 0: batch 2701/2701
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:40 INFO Epoch 0: batch 2702/2702
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:40 INFO Epoch 0: batch 2703/2703
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:40 INFO Epoch 0: batch 2704/2704
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:40 INFO Epoch 0: batch 2705/2705
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:40 INFO Epoch 0: batch 2706/2706
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:40 INFO Epoch 0: batch 2707/2707
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:40 INFO Epoch 0: batch 2708/2708
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:40 INFO Epoch 0: batch 2709/2709
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0961 
2025/02/24 00:54:40 INFO Epoch 0: batch 2710/2710
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:40 INFO Epoch 0: batch 2711/2711
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:40 INFO Epoch 0: batch 2712/2712
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:40 INFO Epoch 0: batch 2713/2713
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:40 INFO Epoch 0: batch 2714/2714
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:40 INFO Epoch 0: batch 2715/2715
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:40 INFO Epoch 0: batch 2716/2716
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0923 
2025/02/24 00:54:40 INFO Epoch 0: batch 2717/2717
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:40 INFO Epoch 0: batch 2718/2718
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:40 INFO Epoch 0: batch 2719/2719
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:40 INFO Epoch 0: batch 2720/2720
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:40 INFO Epoch 0: batch 2721/2721
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:40 INFO Epoch 0: batch 2722/2722
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:40 INFO Epoch 0: batch 2723/2723
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:40 INFO Epoch 0: batch 2724/2724
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:40 INFO Epoch 0: batch 2725/2725
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:40 INFO Epoch 0: batch 2726/2726
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:40 INFO Epoch 0: batch 2727/2727
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:40 INFO Epoch 0: batch 2728/2728
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:40 INFO Epoch 0: batch 2729/2729
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:40 INFO Epoch 0: batch 2730/2730
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:40 INFO Epoch 0: batch 2731/2731
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0950 
2025/02/24 00:54:40 INFO Epoch 0: batch 2732/2732
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0666 
2025/02/24 00:54:40 INFO Epoch 0: batch 2733/2733
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:40 INFO Epoch 0: batch 2734/2734
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:40 INFO Epoch 0: batch 2735/2735
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:40 INFO Epoch 0: batch 2736/2736
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:40 INFO Epoch 0: batch 2737/2737
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:40 INFO Epoch 0: batch 2738/2738
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:40 INFO Epoch 0: batch 2739/2739
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:40 INFO Epoch 0: batch 2740/2740
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:40 INFO Epoch 0: batch 2741/2741
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:40 INFO Epoch 0: batch 2742/2742
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:40 INFO Epoch 0: batch 2743/2743
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.1102 
2025/02/24 00:54:40 INFO Epoch 0: batch 2744/2744
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.1073 
2025/02/24 00:54:40 INFO Epoch 0: batch 2745/2745
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:40 INFO Epoch 0: batch 2746/2746
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:40 INFO Epoch 0: batch 2747/2747
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0901 
2025/02/24 00:54:40 INFO Epoch 0: batch 2748/2748
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:40 INFO Epoch 0: batch 2749/2749
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0614 
2025/02/24 00:54:40 INFO Epoch 0: batch 2750/2750
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0570 
2025/02/24 00:54:40 INFO Epoch 0: batch 2751/2751
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0919 
2025/02/24 00:54:40 INFO Epoch 0: batch 2752/2752
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:40 INFO Epoch 0: batch 2753/2753
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0942 
2025/02/24 00:54:40 INFO Epoch 0: batch 2754/2754
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0590 
2025/02/24 00:54:40 INFO Epoch 0: batch 2755/2755
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0589 
2025/02/24 00:54:40 INFO Epoch 0: batch 2756/2756
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:40 INFO Epoch 0: batch 2757/2757
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:40 INFO Epoch 0: batch 2758/2758
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:40 INFO Epoch 0: batch 2759/2759
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0517 
2025/02/24 00:54:40 INFO Epoch 0: batch 2760/2760
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:40 INFO Epoch 0: batch 2761/2761
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:40 INFO Epoch 0: batch 2762/2762
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:40 INFO Epoch 0: batch 2763/2763
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:40 INFO Epoch 0: batch 2764/2764
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:40 INFO Epoch 0: batch 2765/2765
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:40 INFO Epoch 0: batch 2766/2766
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:40 INFO Epoch 0: batch 2767/2767
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:40 INFO Epoch 0: batch 2768/2768
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:40 INFO Epoch 0: batch 2769/2769
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:40 INFO Epoch 0: batch 2770/2770
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:40 INFO Epoch 0: batch 2771/2771
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0730 
2025/02/24 00:54:40 INFO Epoch 0: batch 2772/2772
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:40 INFO Epoch 0: batch 2773/2773
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:40 INFO Epoch 0: batch 2774/2774
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:40 INFO Epoch 0: batch 2775/2775
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0558 
2025/02/24 00:54:40 INFO Epoch 0: batch 2776/2776
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0890 
2025/02/24 00:54:40 INFO Epoch 0: batch 2777/2777
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:40 INFO Epoch 0: batch 2778/2778
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:40 INFO Epoch 0: batch 2779/2779
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:40 INFO Epoch 0: batch 2780/2780
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:40 INFO Epoch 0: batch 2781/2781
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:40 INFO Epoch 0: batch 2782/2782
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:40 INFO Epoch 0: batch 2783/2783
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:40 INFO Epoch 0: batch 2784/2784
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:40 INFO Epoch 0: batch 2785/2785
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:40 INFO Epoch 0: batch 2786/2786
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0534 
2025/02/24 00:54:40 INFO Epoch 0: batch 2787/2787
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:40 INFO Epoch 0: batch 2788/2788
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:40 INFO Epoch 0: batch 2789/2789
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:40 INFO Epoch 0: batch 2790/2790
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:40 INFO Epoch 0: batch 2791/2791
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:40 INFO Epoch 0: batch 2792/2792
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:40 INFO Epoch 0: batch 2793/2793
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:40 INFO Epoch 0: batch 2794/2794
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:40 INFO Epoch 0: batch 2795/2795
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0582 
2025/02/24 00:54:40 INFO Epoch 0: batch 2796/2796
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:40 INFO Epoch 0: batch 2797/2797
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0967 
2025/02/24 00:54:40 INFO Epoch 0: batch 2798/2798
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:40 INFO Epoch 0: batch 2799/2799
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:40 INFO Epoch 0: batch 2800/2800
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0886 
2025/02/24 00:54:40 INFO Epoch 0: batch 2801/2801
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:40 INFO Epoch 0: batch 2802/2802
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:40 INFO Epoch 0: batch 2803/2803
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:40 INFO Epoch 0: batch 2804/2804
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:40 INFO Epoch 0: batch 2805/2805
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:40 INFO Epoch 0: batch 2806/2806
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:40 INFO Epoch 0: batch 2807/2807
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0852 
2025/02/24 00:54:40 INFO Epoch 0: batch 2808/2808
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:40 INFO Epoch 0: batch 2809/2809
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:40 INFO Epoch 0: batch 2810/2810
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:40 INFO Epoch 0: batch 2811/2811
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:40 INFO Epoch 0: batch 2812/2812
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:40 INFO Epoch 0: batch 2813/2813
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.1010 
2025/02/24 00:54:40 INFO Epoch 0: batch 2814/2814
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0910 
2025/02/24 00:54:40 INFO Epoch 0: batch 2815/2815
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0543 
2025/02/24 00:54:40 INFO Epoch 0: batch 2816/2816
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0848 
2025/02/24 00:54:40 INFO Epoch 0: batch 2817/2817
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:40 INFO Epoch 0: batch 2818/2818
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:40 INFO Epoch 0: batch 2819/2819
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:40 INFO Epoch 0: batch 2820/2820
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:40 INFO Epoch 0: batch 2821/2821
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0905 
2025/02/24 00:54:40 INFO Epoch 0: batch 2822/2822
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:40 INFO Epoch 0: batch 2823/2823
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:40 INFO Epoch 0: batch 2824/2824
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:40 INFO Epoch 0: batch 2825/2825
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0609 
2025/02/24 00:54:40 INFO Epoch 0: batch 2826/2826
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:40 INFO Epoch 0: batch 2827/2827
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:40 INFO Epoch 0: batch 2828/2828
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:40 INFO Epoch 0: batch 2829/2829
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:40 INFO Epoch 0: batch 2830/2830
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:40 INFO Epoch 0: batch 2831/2831
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:40 INFO Epoch 0: batch 2832/2832
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0935 
2025/02/24 00:54:40 INFO Epoch 0: batch 2833/2833
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:40 INFO Epoch 0: batch 2834/2834
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:40 INFO Epoch 0: batch 2835/2835
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:40 INFO Epoch 0: batch 2836/2836
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0551 
2025/02/24 00:54:40 INFO Epoch 0: batch 2837/2837
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:40 INFO Epoch 0: batch 2838/2838
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:40 INFO Epoch 0: batch 2839/2839
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:40 INFO Epoch 0: batch 2840/2840
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:40 INFO Epoch 0: batch 2841/2841
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:40 INFO Epoch 0: batch 2842/2842
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:40 INFO Epoch 0: batch 2843/2843
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:40 INFO Epoch 0: batch 2844/2844
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:40 INFO Epoch 0: batch 2845/2845
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:40 INFO Epoch 0: batch 2846/2846
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:40 INFO Epoch 0: batch 2847/2847
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0870 
2025/02/24 00:54:40 INFO Epoch 0: batch 2848/2848
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:40 INFO Epoch 0: batch 2849/2849
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0586 
2025/02/24 00:54:40 INFO Epoch 0: batch 2850/2850
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0530 
2025/02/24 00:54:40 INFO Epoch 0: batch 2851/2851
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:40 INFO Epoch 0: batch 2852/2852
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:40 INFO Epoch 0: batch 2853/2853
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:40 INFO Epoch 0: batch 2854/2854
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:40 INFO Epoch 0: batch 2855/2855
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:40 INFO Epoch 0: batch 2856/2856
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:40 INFO Epoch 0: batch 2857/2857
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:40 INFO Epoch 0: batch 2858/2858
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:40 INFO Epoch 0: batch 2859/2859
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:40 INFO Epoch 0: batch 2860/2860
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:40 INFO Epoch 0: batch 2861/2861
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:40 INFO Epoch 0: batch 2862/2862
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:40 INFO Epoch 0: batch 2863/2863
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:40 INFO Epoch 0: batch 2864/2864
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0955 
2025/02/24 00:54:40 INFO Epoch 0: batch 2865/2865
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0816 
2025/02/24 00:54:40 INFO Epoch 0: batch 2866/2866
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:40 INFO Epoch 0: batch 2867/2867
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:40 INFO Epoch 0: batch 2868/2868
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:40 INFO Epoch 0: batch 2869/2869
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0585 
2025/02/24 00:54:40 INFO Epoch 0: batch 2870/2870
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0873 
2025/02/24 00:54:40 INFO Epoch 0: batch 2871/2871
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:40 INFO Epoch 0: batch 2872/2872
2025/02/24 00:54:40 INFO          m 0.00010 
2025/02/24 00:54:40 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:41 INFO Epoch 0: batch 2873/2873
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:41 INFO Epoch 0: batch 2874/2874
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:41 INFO Epoch 0: batch 2875/2875
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:41 INFO Epoch 0: batch 2876/2876
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:41 INFO Epoch 0: batch 2877/2877
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:41 INFO Epoch 0: batch 2878/2878
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:41 INFO Epoch 0: batch 2879/2879
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1007 
2025/02/24 00:54:41 INFO Epoch 0: batch 2880/2880
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:41 INFO Epoch 0: batch 2881/2881
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:41 INFO Epoch 0: batch 2882/2882
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:41 INFO Epoch 0: batch 2883/2883
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0502 
2025/02/24 00:54:41 INFO Epoch 0: batch 2884/2884
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:41 INFO Epoch 0: batch 2885/2885
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:41 INFO Epoch 0: batch 2886/2886
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:41 INFO Epoch 0: batch 2887/2887
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:41 INFO Epoch 0: batch 2888/2888
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:41 INFO Epoch 0: batch 2889/2889
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:41 INFO Epoch 0: batch 2890/2890
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0895 
2025/02/24 00:54:41 INFO Epoch 0: batch 2891/2891
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:41 INFO Epoch 0: batch 2892/2892
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:41 INFO Epoch 0: batch 2893/2893
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:41 INFO Epoch 0: batch 2894/2894
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:41 INFO Epoch 0: batch 2895/2895
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:41 INFO Epoch 0: batch 2896/2896
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:41 INFO Epoch 0: batch 2897/2897
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0640 
2025/02/24 00:54:41 INFO Epoch 0: batch 2898/2898
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0831 
2025/02/24 00:54:41 INFO Epoch 0: batch 2899/2899
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:41 INFO Epoch 0: batch 2900/2900
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:41 INFO Epoch 0: batch 2901/2901
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:41 INFO Epoch 0: batch 2902/2902
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:41 INFO Epoch 0: batch 2903/2903
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:41 INFO Epoch 0: batch 2904/2904
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:41 INFO Epoch 0: batch 2905/2905
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:41 INFO Epoch 0: batch 2906/2906
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:41 INFO Epoch 0: batch 2907/2907
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:41 INFO Epoch 0: batch 2908/2908
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:41 INFO Epoch 0: batch 2909/2909
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0550 
2025/02/24 00:54:41 INFO Epoch 0: batch 2910/2910
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:41 INFO Epoch 0: batch 2911/2911
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:41 INFO Epoch 0: batch 2912/2912
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:41 INFO Epoch 0: batch 2913/2913
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:41 INFO Epoch 0: batch 2914/2914
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:41 INFO Epoch 0: batch 2915/2915
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0978 
2025/02/24 00:54:41 INFO Epoch 0: batch 2916/2916
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:41 INFO Epoch 0: batch 2917/2917
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:41 INFO Epoch 0: batch 2918/2918
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:41 INFO Epoch 0: batch 2919/2919
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:41 INFO Epoch 0: batch 2920/2920
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:41 INFO Epoch 0: batch 2921/2921
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0854 
2025/02/24 00:54:41 INFO Epoch 0: batch 2922/2922
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0645 
2025/02/24 00:54:41 INFO Epoch 0: batch 2923/2923
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:41 INFO Epoch 0: batch 2924/2924
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:41 INFO Epoch 0: batch 2925/2925
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:41 INFO Epoch 0: batch 2926/2926
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:41 INFO Epoch 0: batch 2927/2927
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:41 INFO Epoch 0: batch 2928/2928
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:41 INFO Epoch 0: batch 2929/2929
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:41 INFO Epoch 0: batch 2930/2930
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:41 INFO Epoch 0: batch 2931/2931
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:41 INFO Epoch 0: batch 2932/2932
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:41 INFO Epoch 0: batch 2933/2933
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:41 INFO Epoch 0: batch 2934/2934
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:41 INFO Epoch 0: batch 2935/2935
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:41 INFO Epoch 0: batch 2936/2936
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:41 INFO Epoch 0: batch 2937/2937
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:41 INFO Epoch 0: batch 2938/2938
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0519 
2025/02/24 00:54:41 INFO Epoch 0: batch 2939/2939
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:41 INFO Epoch 0: batch 2940/2940
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:41 INFO Epoch 0: batch 2941/2941
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:41 INFO Epoch 0: batch 2942/2942
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0467 
2025/02/24 00:54:41 INFO Epoch 0: batch 2943/2943
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:41 INFO Epoch 0: batch 2944/2944
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:41 INFO Epoch 0: batch 2945/2945
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:41 INFO Epoch 0: batch 2946/2946
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:41 INFO Epoch 0: batch 2947/2947
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:41 INFO Epoch 0: batch 2948/2948
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:41 INFO Epoch 0: batch 2949/2949
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:41 INFO Epoch 0: batch 2950/2950
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:41 INFO Epoch 0: batch 2951/2951
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0888 
2025/02/24 00:54:41 INFO Epoch 0: batch 2952/2952
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:41 INFO Epoch 0: batch 2953/2953
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:41 INFO Epoch 0: batch 2954/2954
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:41 INFO Epoch 0: batch 2955/2955
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:41 INFO Epoch 0: batch 2956/2956
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:41 INFO Epoch 0: batch 2957/2957
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:41 INFO Epoch 0: batch 2958/2958
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:41 INFO Epoch 0: batch 2959/2959
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0531 
2025/02/24 00:54:41 INFO Epoch 0: batch 2960/2960
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:41 INFO Epoch 0: batch 2961/2961
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:41 INFO Epoch 0: batch 2962/2962
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:41 INFO Epoch 0: batch 2963/2963
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:41 INFO Epoch 0: batch 2964/2964
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:41 INFO Epoch 0: batch 2965/2965
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:41 INFO Epoch 0: batch 2966/2966
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:41 INFO Epoch 0: batch 2967/2967
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0801 
2025/02/24 00:54:41 INFO Epoch 0: batch 2968/2968
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:41 INFO Epoch 0: batch 2969/2969
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:41 INFO Epoch 0: batch 2970/2970
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:41 INFO Epoch 0: batch 2971/2971
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:41 INFO Epoch 0: batch 2972/2972
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:41 INFO Epoch 0: batch 2973/2973
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:41 INFO Epoch 0: batch 2974/2974
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:41 INFO Epoch 0: batch 2975/2975
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:41 INFO Epoch 0: batch 2976/2976
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:41 INFO Epoch 0: batch 2977/2977
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:41 INFO Epoch 0: batch 2978/2978
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0582 
2025/02/24 00:54:41 INFO Epoch 0: batch 2979/2979
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0624 
2025/02/24 00:54:41 INFO Epoch 0: batch 2980/2980
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:41 INFO Epoch 0: batch 2981/2981
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0633 
2025/02/24 00:54:41 INFO Epoch 0: batch 2982/2982
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:41 INFO Epoch 0: batch 2983/2983
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:41 INFO Epoch 0: batch 2984/2984
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:41 INFO Epoch 0: batch 2985/2985
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:41 INFO Epoch 0: batch 2986/2986
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:41 INFO Epoch 0: batch 2987/2987
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0558 
2025/02/24 00:54:41 INFO Epoch 0: batch 2988/2988
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:41 INFO Epoch 0: batch 2989/2989
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:41 INFO Epoch 0: batch 2990/2990
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0836 
2025/02/24 00:54:41 INFO Epoch 0: batch 2991/2991
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:41 INFO Epoch 0: batch 2992/2992
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0596 
2025/02/24 00:54:41 INFO Epoch 0: batch 2993/2993
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:41 INFO Epoch 0: batch 2994/2994
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:41 INFO Epoch 0: batch 2995/2995
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:41 INFO Epoch 0: batch 2996/2996
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1075 
2025/02/24 00:54:41 INFO Epoch 0: batch 2997/2997
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:41 INFO Epoch 0: batch 2998/2998
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:41 INFO Epoch 0: batch 2999/2999
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:41 INFO Epoch 0: batch 3000/3000
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:41 INFO Epoch 0: batch 3001/3001
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:41 INFO Epoch 0: batch 3002/3002
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:41 INFO Epoch 0: batch 3003/3003
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:41 INFO Epoch 0: batch 3004/3004
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:41 INFO Epoch 0: batch 3005/3005
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:41 INFO Epoch 0: batch 3006/3006
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0690 
2025/02/24 00:54:41 INFO Epoch 0: batch 3007/3007
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:41 INFO Epoch 0: batch 3008/3008
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:41 INFO Epoch 0: batch 3009/3009
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:41 INFO Epoch 0: batch 3010/3010
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:41 INFO Epoch 0: batch 3011/3011
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:41 INFO Epoch 0: batch 3012/3012
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0661 
2025/02/24 00:54:41 INFO Epoch 0: batch 3013/3013
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:41 INFO Epoch 0: batch 3014/3014
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:41 INFO Epoch 0: batch 3015/3015
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0586 
2025/02/24 00:54:41 INFO Epoch 0: batch 3016/3016
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:41 INFO Epoch 0: batch 3017/3017
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:41 INFO Epoch 0: batch 3018/3018
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0592 
2025/02/24 00:54:41 INFO Epoch 0: batch 3019/3019
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:41 INFO Epoch 0: batch 3020/3020
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:41 INFO Epoch 0: batch 3021/3021
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:41 INFO Epoch 0: batch 3022/3022
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:41 INFO Epoch 0: batch 3023/3023
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:41 INFO Epoch 0: batch 3024/3024
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0624 
2025/02/24 00:54:41 INFO Epoch 0: batch 3025/3025
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0556 
2025/02/24 00:54:41 INFO Epoch 0: batch 3026/3026
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:41 INFO Epoch 0: batch 3027/3027
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:41 INFO Epoch 0: batch 3028/3028
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:41 INFO Epoch 0: batch 3029/3029
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1037 
2025/02/24 00:54:41 INFO Epoch 0: batch 3030/3030
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:41 INFO Epoch 0: batch 3031/3031
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:41 INFO Epoch 0: batch 3032/3032
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0591 
2025/02/24 00:54:41 INFO Epoch 0: batch 3033/3033
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:41 INFO Epoch 0: batch 3034/3034
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0481 
2025/02/24 00:54:41 INFO Epoch 0: batch 3035/3035
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:41 INFO Epoch 0: batch 3036/3036
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:41 INFO Epoch 0: batch 3037/3037
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:41 INFO Epoch 0: batch 3038/3038
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0645 
2025/02/24 00:54:41 INFO Epoch 0: batch 3039/3039
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0923 
2025/02/24 00:54:41 INFO Epoch 0: batch 3040/3040
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:41 INFO Epoch 0: batch 3041/3041
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:41 INFO Epoch 0: batch 3042/3042
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:41 INFO Epoch 0: batch 3043/3043
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:41 INFO Epoch 0: batch 3044/3044
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:41 INFO Epoch 0: batch 3045/3045
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0666 
2025/02/24 00:54:41 INFO Epoch 0: batch 3046/3046
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:41 INFO Epoch 0: batch 3047/3047
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:41 INFO Epoch 0: batch 3048/3048
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:41 INFO Epoch 0: batch 3049/3049
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1060 
2025/02/24 00:54:41 INFO Epoch 0: batch 3050/3050
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:41 INFO Epoch 0: batch 3051/3051
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:41 INFO Epoch 0: batch 3052/3052
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:41 INFO Epoch 0: batch 3053/3053
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0916 
2025/02/24 00:54:41 INFO Epoch 0: batch 3054/3054
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:41 INFO Epoch 0: batch 3055/3055
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:41 INFO Epoch 0: batch 3056/3056
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:41 INFO Epoch 0: batch 3057/3057
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:41 INFO Epoch 0: batch 3058/3058
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:41 INFO Epoch 0: batch 3059/3059
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:41 INFO Epoch 0: batch 3060/3060
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:41 INFO Epoch 0: batch 3061/3061
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:41 INFO Epoch 0: batch 3062/3062
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:41 INFO Epoch 0: batch 3063/3063
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:41 INFO Epoch 0: batch 3064/3064
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0922 
2025/02/24 00:54:41 INFO Epoch 0: batch 3065/3065
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0556 
2025/02/24 00:54:41 INFO Epoch 0: batch 3066/3066
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:41 INFO Epoch 0: batch 3067/3067
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:41 INFO Epoch 0: batch 3068/3068
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:41 INFO Epoch 0: batch 3069/3069
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0622 
2025/02/24 00:54:41 INFO Epoch 0: batch 3070/3070
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:41 INFO Epoch 0: batch 3071/3071
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:41 INFO Epoch 0: batch 3072/3072
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:41 INFO Epoch 0: batch 3073/3073
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0908 
2025/02/24 00:54:41 INFO Epoch 0: batch 3074/3074
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:41 INFO Epoch 0: batch 3075/3075
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1073 
2025/02/24 00:54:41 INFO Epoch 0: batch 3076/3076
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:41 INFO Epoch 0: batch 3077/3077
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:41 INFO Epoch 0: batch 3078/3078
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0612 
2025/02/24 00:54:41 INFO Epoch 0: batch 3079/3079
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:41 INFO Epoch 0: batch 3080/3080
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:41 INFO Epoch 0: batch 3081/3081
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:41 INFO Epoch 0: batch 3082/3082
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:41 INFO Epoch 0: batch 3083/3083
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:41 INFO Epoch 0: batch 3084/3084
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:41 INFO Epoch 0: batch 3085/3085
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:41 INFO Epoch 0: batch 3086/3086
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0555 
2025/02/24 00:54:41 INFO Epoch 0: batch 3087/3087
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0814 
2025/02/24 00:54:41 INFO Epoch 0: batch 3088/3088
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0813 
2025/02/24 00:54:41 INFO Epoch 0: batch 3089/3089
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:41 INFO Epoch 0: batch 3090/3090
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:41 INFO Epoch 0: batch 3091/3091
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0804 
2025/02/24 00:54:41 INFO Epoch 0: batch 3092/3092
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0565 
2025/02/24 00:54:41 INFO Epoch 0: batch 3093/3093
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:41 INFO Epoch 0: batch 3094/3094
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:41 INFO Epoch 0: batch 3095/3095
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:41 INFO Epoch 0: batch 3096/3096
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:41 INFO Epoch 0: batch 3097/3097
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:41 INFO Epoch 0: batch 3098/3098
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0540 
2025/02/24 00:54:41 INFO Epoch 0: batch 3099/3099
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0876 
2025/02/24 00:54:41 INFO Epoch 0: batch 3100/3100
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:41 INFO Epoch 0: batch 3101/3101
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:41 INFO Epoch 0: batch 3102/3102
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0567 
2025/02/24 00:54:41 INFO Epoch 0: batch 3103/3103
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:41 INFO Epoch 0: batch 3104/3104
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0932 
2025/02/24 00:54:41 INFO Epoch 0: batch 3105/3105
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:41 INFO Epoch 0: batch 3106/3106
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:41 INFO Epoch 0: batch 3107/3107
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0591 
2025/02/24 00:54:41 INFO Epoch 0: batch 3108/3108
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:41 INFO Epoch 0: batch 3109/3109
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:41 INFO Epoch 0: batch 3110/3110
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0666 
2025/02/24 00:54:41 INFO Epoch 0: batch 3111/3111
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0541 
2025/02/24 00:54:41 INFO Epoch 0: batch 3112/3112
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:41 INFO Epoch 0: batch 3113/3113
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:41 INFO Epoch 0: batch 3114/3114
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0513 
2025/02/24 00:54:41 INFO Epoch 0: batch 3115/3115
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:41 INFO Epoch 0: batch 3116/3116
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0815 
2025/02/24 00:54:41 INFO Epoch 0: batch 3117/3117
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:41 INFO Epoch 0: batch 3118/3118
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0925 
2025/02/24 00:54:41 INFO Epoch 0: batch 3119/3119
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:41 INFO Epoch 0: batch 3120/3120
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0915 
2025/02/24 00:54:41 INFO Epoch 0: batch 3121/3121
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:41 INFO Epoch 0: batch 3122/3122
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:41 INFO Epoch 0: batch 3123/3123
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:41 INFO Epoch 0: batch 3124/3124
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0981 
2025/02/24 00:54:41 INFO Epoch 0: batch 3125/3125
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:41 INFO Epoch 0: batch 3126/3126
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:41 INFO Epoch 0: batch 3127/3127
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:41 INFO Epoch 0: batch 3128/3128
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:41 INFO Epoch 0: batch 3129/3129
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:41 INFO Epoch 0: batch 3130/3130
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:41 INFO Epoch 0: batch 3131/3131
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.1016 
2025/02/24 00:54:41 INFO Epoch 0: batch 3132/3132
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:41 INFO Epoch 0: batch 3133/3133
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:41 INFO Epoch 0: batch 3134/3134
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0614 
2025/02/24 00:54:41 INFO Epoch 0: batch 3135/3135
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:41 INFO Epoch 0: batch 3136/3136
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0860 
2025/02/24 00:54:41 INFO Epoch 0: batch 3137/3137
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:41 INFO Epoch 0: batch 3138/3138
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:41 INFO Epoch 0: batch 3139/3139
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0755 
2025/02/24 00:54:41 INFO Epoch 0: batch 3140/3140
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:41 INFO Epoch 0: batch 3141/3141
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:41 INFO Epoch 0: batch 3142/3142
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:41 INFO Epoch 0: batch 3143/3143
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:41 INFO Epoch 0: batch 3144/3144
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:41 INFO Epoch 0: batch 3145/3145
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:41 INFO Epoch 0: batch 3146/3146
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:41 INFO Epoch 0: batch 3147/3147
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:41 INFO Epoch 0: batch 3148/3148
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:41 INFO Epoch 0: batch 3149/3149
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:41 INFO Epoch 0: batch 3150/3150
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:41 INFO Epoch 0: batch 3151/3151
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:41 INFO Epoch 0: batch 3152/3152
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:41 INFO Epoch 0: batch 3153/3153
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:41 INFO Epoch 0: batch 3154/3154
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:41 INFO Epoch 0: batch 3155/3155
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:41 INFO Epoch 0: batch 3156/3156
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:41 INFO Epoch 0: batch 3157/3157
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:41 INFO Epoch 0: batch 3158/3158
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:41 INFO Epoch 0: batch 3159/3159
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:41 INFO Epoch 0: batch 3160/3160
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:41 INFO Epoch 0: batch 3161/3161
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:41 INFO Epoch 0: batch 3162/3162
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:41 INFO Epoch 0: batch 3163/3163
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:41 INFO Epoch 0: batch 3164/3164
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:41 INFO Epoch 0: batch 3165/3165
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0656 
2025/02/24 00:54:41 INFO Epoch 0: batch 3166/3166
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:41 INFO Epoch 0: batch 3167/3167
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:41 INFO Epoch 0: batch 3168/3168
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:41 INFO Epoch 0: batch 3169/3169
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:41 INFO Epoch 0: batch 3170/3170
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:41 INFO Epoch 0: batch 3171/3171
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:41 INFO Epoch 0: batch 3172/3172
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:41 INFO Epoch 0: batch 3173/3173
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0956 
2025/02/24 00:54:41 INFO Epoch 0: batch 3174/3174
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:41 INFO Epoch 0: batch 3175/3175
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:41 INFO Epoch 0: batch 3176/3176
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:41 INFO Epoch 0: batch 3177/3177
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:41 INFO Epoch 0: batch 3178/3178
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:41 INFO Epoch 0: batch 3179/3179
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:41 INFO Epoch 0: batch 3180/3180
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:41 INFO Epoch 0: batch 3181/3181
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:41 INFO Epoch 0: batch 3182/3182
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:41 INFO Epoch 0: batch 3183/3183
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:41 INFO Epoch 0: batch 3184/3184
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:41 INFO Epoch 0: batch 3185/3185
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0924 
2025/02/24 00:54:41 INFO Epoch 0: batch 3186/3186
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:41 INFO Epoch 0: batch 3187/3187
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0688 
2025/02/24 00:54:41 INFO Epoch 0: batch 3188/3188
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:41 INFO Epoch 0: batch 3189/3189
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:41 INFO Epoch 0: batch 3190/3190
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:41 INFO Epoch 0: batch 3191/3191
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:41 INFO Epoch 0: batch 3192/3192
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:41 INFO Epoch 0: batch 3193/3193
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:41 INFO Epoch 0: batch 3194/3194
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:41 INFO Epoch 0: batch 3195/3195
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0579 
2025/02/24 00:54:41 INFO Epoch 0: batch 3196/3196
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:41 INFO Epoch 0: batch 3197/3197
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:41 INFO Epoch 0: batch 3198/3198
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:41 INFO Epoch 0: batch 3199/3199
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:41 INFO Epoch 0: batch 3200/3200
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0825 
2025/02/24 00:54:41 INFO Epoch 0: batch 3201/3201
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:41 INFO Epoch 0: batch 3202/3202
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0885 
2025/02/24 00:54:41 INFO Epoch 0: batch 3203/3203
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:41 INFO Epoch 0: batch 3204/3204
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:41 INFO Epoch 0: batch 3205/3205
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0990 
2025/02/24 00:54:41 INFO Epoch 0: batch 3206/3206
2025/02/24 00:54:41 INFO          m 0.00010 
2025/02/24 00:54:41 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:42 INFO Epoch 0: batch 3207/3207
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:42 INFO Epoch 0: batch 3208/3208
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:42 INFO Epoch 0: batch 3209/3209
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:42 INFO Epoch 0: batch 3210/3210
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:42 INFO Epoch 0: batch 3211/3211
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:42 INFO Epoch 0: batch 3212/3212
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:42 INFO Epoch 0: batch 3213/3213
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:42 INFO Epoch 0: batch 3214/3214
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:42 INFO Epoch 0: batch 3215/3215
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:42 INFO Epoch 0: batch 3216/3216
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:42 INFO Epoch 0: batch 3217/3217
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:42 INFO Epoch 0: batch 3218/3218
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:42 INFO Epoch 0: batch 3219/3219
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3220/3220
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0677 
2025/02/24 00:54:42 INFO Epoch 0: batch 3221/3221
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0644 
2025/02/24 00:54:42 INFO Epoch 0: batch 3222/3222
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0730 
2025/02/24 00:54:42 INFO Epoch 0: batch 3223/3223
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0982 
2025/02/24 00:54:42 INFO Epoch 0: batch 3224/3224
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:42 INFO Epoch 0: batch 3225/3225
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:42 INFO Epoch 0: batch 3226/3226
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0587 
2025/02/24 00:54:42 INFO Epoch 0: batch 3227/3227
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0569 
2025/02/24 00:54:42 INFO Epoch 0: batch 3228/3228
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:42 INFO Epoch 0: batch 3229/3229
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0819 
2025/02/24 00:54:42 INFO Epoch 0: batch 3230/3230
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:42 INFO Epoch 0: batch 3231/3231
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:42 INFO Epoch 0: batch 3232/3232
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:42 INFO Epoch 0: batch 3233/3233
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:42 INFO Epoch 0: batch 3234/3234
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:42 INFO Epoch 0: batch 3235/3235
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:42 INFO Epoch 0: batch 3236/3236
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:42 INFO Epoch 0: batch 3237/3237
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0835 
2025/02/24 00:54:42 INFO Epoch 0: batch 3238/3238
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:42 INFO Epoch 0: batch 3239/3239
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:42 INFO Epoch 0: batch 3240/3240
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:42 INFO Epoch 0: batch 3241/3241
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0882 
2025/02/24 00:54:42 INFO Epoch 0: batch 3242/3242
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0525 
2025/02/24 00:54:42 INFO Epoch 0: batch 3243/3243
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:42 INFO Epoch 0: batch 3244/3244
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:42 INFO Epoch 0: batch 3245/3245
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:42 INFO Epoch 0: batch 3246/3246
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:42 INFO Epoch 0: batch 3247/3247
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:42 INFO Epoch 0: batch 3248/3248
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3249/3249
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:42 INFO Epoch 0: batch 3250/3250
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0686 
2025/02/24 00:54:42 INFO Epoch 0: batch 3251/3251
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:42 INFO Epoch 0: batch 3252/3252
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:42 INFO Epoch 0: batch 3253/3253
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:42 INFO Epoch 0: batch 3254/3254
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:42 INFO Epoch 0: batch 3255/3255
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:42 INFO Epoch 0: batch 3256/3256
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:42 INFO Epoch 0: batch 3257/3257
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:42 INFO Epoch 0: batch 3258/3258
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:42 INFO Epoch 0: batch 3259/3259
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:42 INFO Epoch 0: batch 3260/3260
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:42 INFO Epoch 0: batch 3261/3261
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0907 
2025/02/24 00:54:42 INFO Epoch 0: batch 3262/3262
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0642 
2025/02/24 00:54:42 INFO Epoch 0: batch 3263/3263
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:42 INFO Epoch 0: batch 3264/3264
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:42 INFO Epoch 0: batch 3265/3265
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:42 INFO Epoch 0: batch 3266/3266
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:42 INFO Epoch 0: batch 3267/3267
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:42 INFO Epoch 0: batch 3268/3268
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:42 INFO Epoch 0: batch 3269/3269
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:42 INFO Epoch 0: batch 3270/3270
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:42 INFO Epoch 0: batch 3271/3271
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0822 
2025/02/24 00:54:42 INFO Epoch 0: batch 3272/3272
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:42 INFO Epoch 0: batch 3273/3273
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:42 INFO Epoch 0: batch 3274/3274
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3275/3275
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:42 INFO Epoch 0: batch 3276/3276
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:42 INFO Epoch 0: batch 3277/3277
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0867 
2025/02/24 00:54:42 INFO Epoch 0: batch 3278/3278
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:42 INFO Epoch 0: batch 3279/3279
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.1187 
2025/02/24 00:54:42 INFO Epoch 0: batch 3280/3280
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:42 INFO Epoch 0: batch 3281/3281
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:42 INFO Epoch 0: batch 3282/3282
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:42 INFO Epoch 0: batch 3283/3283
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:42 INFO Epoch 0: batch 3284/3284
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:42 INFO Epoch 0: batch 3285/3285
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.1027 
2025/02/24 00:54:42 INFO Epoch 0: batch 3286/3286
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:42 INFO Epoch 0: batch 3287/3287
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0866 
2025/02/24 00:54:42 INFO Epoch 0: batch 3288/3288
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:42 INFO Epoch 0: batch 3289/3289
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:42 INFO Epoch 0: batch 3290/3290
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:42 INFO Epoch 0: batch 3291/3291
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:42 INFO Epoch 0: batch 3292/3292
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:42 INFO Epoch 0: batch 3293/3293
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:42 INFO Epoch 0: batch 3294/3294
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0670 
2025/02/24 00:54:42 INFO Epoch 0: batch 3295/3295
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:42 INFO Epoch 0: batch 3296/3296
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:42 INFO Epoch 0: batch 3297/3297
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:42 INFO Epoch 0: batch 3298/3298
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0661 
2025/02/24 00:54:42 INFO Epoch 0: batch 3299/3299
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:42 INFO Epoch 0: batch 3300/3300
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0520 
2025/02/24 00:54:42 INFO Epoch 0: batch 3301/3301
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:42 INFO Epoch 0: batch 3302/3302
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0578 
2025/02/24 00:54:42 INFO Epoch 0: batch 3303/3303
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:42 INFO Epoch 0: batch 3304/3304
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:42 INFO Epoch 0: batch 3305/3305
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:42 INFO Epoch 0: batch 3306/3306
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:42 INFO Epoch 0: batch 3307/3307
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:42 INFO Epoch 0: batch 3308/3308
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0941 
2025/02/24 00:54:42 INFO Epoch 0: batch 3309/3309
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0958 
2025/02/24 00:54:42 INFO Epoch 0: batch 3310/3310
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:42 INFO Epoch 0: batch 3311/3311
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0993 
2025/02/24 00:54:42 INFO Epoch 0: batch 3312/3312
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:42 INFO Epoch 0: batch 3313/3313
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:42 INFO Epoch 0: batch 3314/3314
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:42 INFO Epoch 0: batch 3315/3315
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0871 
2025/02/24 00:54:42 INFO Epoch 0: batch 3316/3316
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:42 INFO Epoch 0: batch 3317/3317
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:42 INFO Epoch 0: batch 3318/3318
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:42 INFO Epoch 0: batch 3319/3319
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0956 
2025/02/24 00:54:42 INFO Epoch 0: batch 3320/3320
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:42 INFO Epoch 0: batch 3321/3321
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:42 INFO Epoch 0: batch 3322/3322
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:42 INFO Epoch 0: batch 3323/3323
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:42 INFO Epoch 0: batch 3324/3324
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:42 INFO Epoch 0: batch 3325/3325
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:42 INFO Epoch 0: batch 3326/3326
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0814 
2025/02/24 00:54:42 INFO Epoch 0: batch 3327/3327
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:42 INFO Epoch 0: batch 3328/3328
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:42 INFO Epoch 0: batch 3329/3329
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0822 
2025/02/24 00:54:42 INFO Epoch 0: batch 3330/3330
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:42 INFO Epoch 0: batch 3331/3331
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:42 INFO Epoch 0: batch 3332/3332
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0798 
2025/02/24 00:54:42 INFO Epoch 0: batch 3333/3333
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:42 INFO Epoch 0: batch 3334/3334
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:42 INFO Epoch 0: batch 3335/3335
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:42 INFO Epoch 0: batch 3336/3336
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:42 INFO Epoch 0: batch 3337/3337
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:42 INFO Epoch 0: batch 3338/3338
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:42 INFO Epoch 0: batch 3339/3339
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:42 INFO Epoch 0: batch 3340/3340
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:42 INFO Epoch 0: batch 3341/3341
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:42 INFO Epoch 0: batch 3342/3342
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:42 INFO Epoch 0: batch 3343/3343
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0795 
2025/02/24 00:54:42 INFO Epoch 0: batch 3344/3344
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0889 
2025/02/24 00:54:42 INFO Epoch 0: batch 3345/3345
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:42 INFO Epoch 0: batch 3346/3346
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:42 INFO Epoch 0: batch 3347/3347
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:42 INFO Epoch 0: batch 3348/3348
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:42 INFO Epoch 0: batch 3349/3349
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:42 INFO Epoch 0: batch 3350/3350
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0825 
2025/02/24 00:54:42 INFO Epoch 0: batch 3351/3351
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:42 INFO Epoch 0: batch 3352/3352
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0864 
2025/02/24 00:54:42 INFO Epoch 0: batch 3353/3353
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:42 INFO Epoch 0: batch 3354/3354
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:42 INFO Epoch 0: batch 3355/3355
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0858 
2025/02/24 00:54:42 INFO Epoch 0: batch 3356/3356
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:42 INFO Epoch 0: batch 3357/3357
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0872 
2025/02/24 00:54:42 INFO Epoch 0: batch 3358/3358
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0809 
2025/02/24 00:54:42 INFO Epoch 0: batch 3359/3359
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0782 
2025/02/24 00:54:42 INFO Epoch 0: batch 3360/3360
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:42 INFO Epoch 0: batch 3361/3361
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0545 
2025/02/24 00:54:42 INFO Epoch 0: batch 3362/3362
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:42 INFO Epoch 0: batch 3363/3363
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0668 
2025/02/24 00:54:42 INFO Epoch 0: batch 3364/3364
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3365/3365
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:42 INFO Epoch 0: batch 3366/3366
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:42 INFO Epoch 0: batch 3367/3367
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0792 
2025/02/24 00:54:42 INFO Epoch 0: batch 3368/3368
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0905 
2025/02/24 00:54:42 INFO Epoch 0: batch 3369/3369
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:42 INFO Epoch 0: batch 3370/3370
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:42 INFO Epoch 0: batch 3371/3371
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:42 INFO Epoch 0: batch 3372/3372
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:42 INFO Epoch 0: batch 3373/3373
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:42 INFO Epoch 0: batch 3374/3374
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0557 
2025/02/24 00:54:42 INFO Epoch 0: batch 3375/3375
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:42 INFO Epoch 0: batch 3376/3376
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0834 
2025/02/24 00:54:42 INFO Epoch 0: batch 3377/3377
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0922 
2025/02/24 00:54:42 INFO Epoch 0: batch 3378/3378
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:42 INFO Epoch 0: batch 3379/3379
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0753 
2025/02/24 00:54:42 INFO Epoch 0: batch 3380/3380
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3381/3381
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:42 INFO Epoch 0: batch 3382/3382
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0897 
2025/02/24 00:54:42 INFO Epoch 0: batch 3383/3383
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:42 INFO Epoch 0: batch 3384/3384
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:42 INFO Epoch 0: batch 3385/3385
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:42 INFO Epoch 0: batch 3386/3386
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0860 
2025/02/24 00:54:42 INFO Epoch 0: batch 3387/3387
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:42 INFO Epoch 0: batch 3388/3388
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0916 
2025/02/24 00:54:42 INFO Epoch 0: batch 3389/3389
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.1077 
2025/02/24 00:54:42 INFO Epoch 0: batch 3390/3390
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0558 
2025/02/24 00:54:42 INFO Epoch 0: batch 3391/3391
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:42 INFO Epoch 0: batch 3392/3392
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0930 
2025/02/24 00:54:42 INFO Epoch 0: batch 3393/3393
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0583 
2025/02/24 00:54:42 INFO Epoch 0: batch 3394/3394
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:42 INFO Epoch 0: batch 3395/3395
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:42 INFO Epoch 0: batch 3396/3396
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:42 INFO Epoch 0: batch 3397/3397
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0886 
2025/02/24 00:54:42 INFO Epoch 0: batch 3398/3398
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0870 
2025/02/24 00:54:42 INFO Epoch 0: batch 3399/3399
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:42 INFO Epoch 0: batch 3400/3400
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:42 INFO Epoch 0: batch 3401/3401
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:42 INFO Epoch 0: batch 3402/3402
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:42 INFO Epoch 0: batch 3403/3403
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:42 INFO Epoch 0: batch 3404/3404
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0846 
2025/02/24 00:54:42 INFO Epoch 0: batch 3405/3405
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0760 
2025/02/24 00:54:42 INFO Epoch 0: batch 3406/3406
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:42 INFO Epoch 0: batch 3407/3407
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:42 INFO Epoch 0: batch 3408/3408
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:42 INFO Epoch 0: batch 3409/3409
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:42 INFO Epoch 0: batch 3410/3410
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:42 INFO Epoch 0: batch 3411/3411
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:42 INFO Epoch 0: batch 3412/3412
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0911 
2025/02/24 00:54:42 INFO Epoch 0: batch 3413/3413
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:42 INFO Epoch 0: batch 3414/3414
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:42 INFO Epoch 0: batch 3415/3415
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:42 INFO Epoch 0: batch 3416/3416
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0843 
2025/02/24 00:54:42 INFO Epoch 0: batch 3417/3417
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0914 
2025/02/24 00:54:42 INFO Epoch 0: batch 3418/3418
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:42 INFO Epoch 0: batch 3419/3419
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:42 INFO Epoch 0: batch 3420/3420
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:42 INFO Epoch 0: batch 3421/3421
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0740 
2025/02/24 00:54:42 INFO Epoch 0: batch 3422/3422
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0804 
2025/02/24 00:54:42 INFO Epoch 0: batch 3423/3423
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:42 INFO Epoch 0: batch 3424/3424
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:42 INFO Epoch 0: batch 3425/3425
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0754 
2025/02/24 00:54:42 INFO Epoch 0: batch 3426/3426
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:42 INFO Epoch 0: batch 3427/3427
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0666 
2025/02/24 00:54:42 INFO Epoch 0: batch 3428/3428
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:42 INFO Epoch 0: batch 3429/3429
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:42 INFO Epoch 0: batch 3430/3430
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:42 INFO Epoch 0: batch 3431/3431
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:42 INFO Epoch 0: batch 3432/3432
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0622 
2025/02/24 00:54:42 INFO Epoch 0: batch 3433/3433
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:42 INFO Epoch 0: batch 3434/3434
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:42 INFO Epoch 0: batch 3435/3435
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:42 INFO Epoch 0: batch 3436/3436
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0542 
2025/02/24 00:54:42 INFO Epoch 0: batch 3437/3437
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:42 INFO Epoch 0: batch 3438/3438
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:42 INFO Epoch 0: batch 3439/3439
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:42 INFO Epoch 0: batch 3440/3440
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:42 INFO Epoch 0: batch 3441/3441
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:42 INFO Epoch 0: batch 3442/3442
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:42 INFO Epoch 0: batch 3443/3443
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:42 INFO Epoch 0: batch 3444/3444
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:42 INFO Epoch 0: batch 3445/3445
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:42 INFO Epoch 0: batch 3446/3446
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:42 INFO Epoch 0: batch 3447/3447
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:42 INFO Epoch 0: batch 3448/3448
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:42 INFO Epoch 0: batch 3449/3449
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0877 
2025/02/24 00:54:42 INFO Epoch 0: batch 3450/3450
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:42 INFO Epoch 0: batch 3451/3451
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:42 INFO Epoch 0: batch 3452/3452
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:42 INFO Epoch 0: batch 3453/3453
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:42 INFO Epoch 0: batch 3454/3454
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:42 INFO Epoch 0: batch 3455/3455
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:42 INFO Epoch 0: batch 3456/3456
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0811 
2025/02/24 00:54:42 INFO Epoch 0: batch 3457/3457
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:42 INFO Epoch 0: batch 3458/3458
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0700 
2025/02/24 00:54:42 INFO Epoch 0: batch 3459/3459
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:42 INFO Epoch 0: batch 3460/3460
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:42 INFO Epoch 0: batch 3461/3461
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:42 INFO Epoch 0: batch 3462/3462
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:42 INFO Epoch 0: batch 3463/3463
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0837 
2025/02/24 00:54:42 INFO Epoch 0: batch 3464/3464
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0860 
2025/02/24 00:54:42 INFO Epoch 0: batch 3465/3465
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:42 INFO Epoch 0: batch 3466/3466
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:42 INFO Epoch 0: batch 3467/3467
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0946 
2025/02/24 00:54:42 INFO Epoch 0: batch 3468/3468
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:42 INFO Epoch 0: batch 3469/3469
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:42 INFO Epoch 0: batch 3470/3470
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:42 INFO Epoch 0: batch 3471/3471
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:42 INFO Epoch 0: batch 3472/3472
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:42 INFO Epoch 0: batch 3473/3473
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:42 INFO Epoch 0: batch 3474/3474
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0854 
2025/02/24 00:54:42 INFO Epoch 0: batch 3475/3475
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0666 
2025/02/24 00:54:42 INFO Epoch 0: batch 3476/3476
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:42 INFO Epoch 0: batch 3477/3477
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:42 INFO Epoch 0: batch 3478/3478
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0891 
2025/02/24 00:54:42 INFO Epoch 0: batch 3479/3479
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0904 
2025/02/24 00:54:42 INFO Epoch 0: batch 3480/3480
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:42 INFO Epoch 0: batch 3481/3481
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0777 
2025/02/24 00:54:42 INFO Epoch 0: batch 3482/3482
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:42 INFO Epoch 0: batch 3483/3483
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:42 INFO Epoch 0: batch 3484/3484
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0648 
2025/02/24 00:54:42 INFO Epoch 0: batch 3485/3485
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:42 INFO Epoch 0: batch 3486/3486
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:42 INFO Epoch 0: batch 3487/3487
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:42 INFO Epoch 0: batch 3488/3488
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:42 INFO Epoch 0: batch 3489/3489
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:42 INFO Epoch 0: batch 3490/3490
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:42 INFO Epoch 0: batch 3491/3491
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:42 INFO Epoch 0: batch 3492/3492
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:42 INFO Epoch 0: batch 3493/3493
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:42 INFO Epoch 0: batch 3494/3494
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:42 INFO Epoch 0: batch 3495/3495
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0911 
2025/02/24 00:54:42 INFO Epoch 0: batch 3496/3496
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0925 
2025/02/24 00:54:42 INFO Epoch 0: batch 3497/3497
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:42 INFO Epoch 0: batch 3498/3498
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:42 INFO Epoch 0: batch 3499/3499
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0811 
2025/02/24 00:54:42 INFO Epoch 0: batch 3500/3500
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0937 
2025/02/24 00:54:42 INFO Epoch 0: batch 3501/3501
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0604 
2025/02/24 00:54:42 INFO Epoch 0: batch 3502/3502
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:42 INFO Epoch 0: batch 3503/3503
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:42 INFO Epoch 0: batch 3504/3504
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:42 INFO Epoch 0: batch 3505/3505
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:42 INFO Epoch 0: batch 3506/3506
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:42 INFO Epoch 0: batch 3507/3507
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0881 
2025/02/24 00:54:42 INFO Epoch 0: batch 3508/3508
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.1058 
2025/02/24 00:54:42 INFO Epoch 0: batch 3509/3509
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:42 INFO Epoch 0: batch 3510/3510
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0848 
2025/02/24 00:54:42 INFO Epoch 0: batch 3511/3511
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0864 
2025/02/24 00:54:42 INFO Epoch 0: batch 3512/3512
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.1035 
2025/02/24 00:54:42 INFO Epoch 0: batch 3513/3513
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:42 INFO Epoch 0: batch 3514/3514
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:42 INFO Epoch 0: batch 3515/3515
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:42 INFO Epoch 0: batch 3516/3516
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:42 INFO Epoch 0: batch 3517/3517
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:42 INFO Epoch 0: batch 3518/3518
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:42 INFO Epoch 0: batch 3519/3519
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:42 INFO Epoch 0: batch 3520/3520
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:42 INFO Epoch 0: batch 3521/3521
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0919 
2025/02/24 00:54:42 INFO Epoch 0: batch 3522/3522
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:42 INFO Epoch 0: batch 3523/3523
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:42 INFO Epoch 0: batch 3524/3524
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:42 INFO Epoch 0: batch 3525/3525
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:42 INFO Epoch 0: batch 3526/3526
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:42 INFO Epoch 0: batch 3527/3527
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:42 INFO Epoch 0: batch 3528/3528
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0935 
2025/02/24 00:54:42 INFO Epoch 0: batch 3529/3529
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:42 INFO Epoch 0: batch 3530/3530
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:42 INFO Epoch 0: batch 3531/3531
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:42 INFO Epoch 0: batch 3532/3532
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0924 
2025/02/24 00:54:42 INFO Epoch 0: batch 3533/3533
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0732 
2025/02/24 00:54:42 INFO Epoch 0: batch 3534/3534
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:42 INFO Epoch 0: batch 3535/3535
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0746 
2025/02/24 00:54:42 INFO Epoch 0: batch 3536/3536
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:42 INFO Epoch 0: batch 3537/3537
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0847 
2025/02/24 00:54:42 INFO Epoch 0: batch 3538/3538
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0875 
2025/02/24 00:54:42 INFO Epoch 0: batch 3539/3539
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:42 INFO Epoch 0: batch 3540/3540
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0708 
2025/02/24 00:54:42 INFO Epoch 0: batch 3541/3541
2025/02/24 00:54:42 INFO          m 0.00010 
2025/02/24 00:54:42 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:43 INFO Epoch 0: batch 3542/3542
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:43 INFO Epoch 0: batch 3543/3543
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:43 INFO Epoch 0: batch 3544/3544
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:43 INFO Epoch 0: batch 3545/3545
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:43 INFO Epoch 0: batch 3546/3546
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0499 
2025/02/24 00:54:43 INFO Epoch 0: batch 3547/3547
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:43 INFO Epoch 0: batch 3548/3548
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:43 INFO Epoch 0: batch 3549/3549
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:43 INFO Epoch 0: batch 3550/3550
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:43 INFO Epoch 0: batch 3551/3551
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:43 INFO Epoch 0: batch 3552/3552
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:43 INFO Epoch 0: batch 3553/3553
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:43 INFO Epoch 0: batch 3554/3554
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:43 INFO Epoch 0: batch 3555/3555
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:43 INFO Epoch 0: batch 3556/3556
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0954 
2025/02/24 00:54:43 INFO Epoch 0: batch 3557/3557
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:43 INFO Epoch 0: batch 3558/3558
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0874 
2025/02/24 00:54:43 INFO Epoch 0: batch 3559/3559
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:43 INFO Epoch 0: batch 3560/3560
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0722 
2025/02/24 00:54:43 INFO Epoch 0: batch 3561/3561
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:43 INFO Epoch 0: batch 3562/3562
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:43 INFO Epoch 0: batch 3563/3563
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0919 
2025/02/24 00:54:43 INFO Epoch 0: batch 3564/3564
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:43 INFO Epoch 0: batch 3565/3565
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:43 INFO Epoch 0: batch 3566/3566
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:43 INFO Epoch 0: batch 3567/3567
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:43 INFO Epoch 0: batch 3568/3568
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0691 
2025/02/24 00:54:43 INFO Epoch 0: batch 3569/3569
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:43 INFO Epoch 0: batch 3570/3570
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:43 INFO Epoch 0: batch 3571/3571
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:43 INFO Epoch 0: batch 3572/3572
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:43 INFO Epoch 0: batch 3573/3573
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:43 INFO Epoch 0: batch 3574/3574
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:43 INFO Epoch 0: batch 3575/3575
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0552 
2025/02/24 00:54:43 INFO Epoch 0: batch 3576/3576
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:43 INFO Epoch 0: batch 3577/3577
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:43 INFO Epoch 0: batch 3578/3578
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0917 
2025/02/24 00:54:43 INFO Epoch 0: batch 3579/3579
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:43 INFO Epoch 0: batch 3580/3580
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0854 
2025/02/24 00:54:43 INFO Epoch 0: batch 3581/3581
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:43 INFO Epoch 0: batch 3582/3582
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:43 INFO Epoch 0: batch 3583/3583
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:43 INFO Epoch 0: batch 3584/3584
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0931 
2025/02/24 00:54:43 INFO Epoch 0: batch 3585/3585
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0917 
2025/02/24 00:54:43 INFO Epoch 0: batch 3586/3586
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0809 
2025/02/24 00:54:43 INFO Epoch 0: batch 3587/3587
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0575 
2025/02/24 00:54:43 INFO Epoch 0: batch 3588/3588
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0895 
2025/02/24 00:54:43 INFO Epoch 0: batch 3589/3589
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:43 INFO Epoch 0: batch 3590/3590
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:43 INFO Epoch 0: batch 3591/3591
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0568 
2025/02/24 00:54:43 INFO Epoch 0: batch 3592/3592
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:43 INFO Epoch 0: batch 3593/3593
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:43 INFO Epoch 0: batch 3594/3594
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:43 INFO Epoch 0: batch 3595/3595
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:43 INFO Epoch 0: batch 3596/3596
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:43 INFO Epoch 0: batch 3597/3597
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0630 
2025/02/24 00:54:43 INFO Epoch 0: batch 3598/3598
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:43 INFO Epoch 0: batch 3599/3599
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0607 
2025/02/24 00:54:43 INFO Epoch 0: batch 3600/3600
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:43 INFO Epoch 0: batch 3601/3601
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0795 
2025/02/24 00:54:43 INFO Epoch 0: batch 3602/3602
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0769 
2025/02/24 00:54:43 INFO Epoch 0: batch 3603/3603
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:43 INFO Epoch 0: batch 3604/3604
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:43 INFO Epoch 0: batch 3605/3605
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0863 
2025/02/24 00:54:43 INFO Epoch 0: batch 3606/3606
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:43 INFO Epoch 0: batch 3607/3607
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:43 INFO Epoch 0: batch 3608/3608
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:43 INFO Epoch 0: batch 3609/3609
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0715 
2025/02/24 00:54:43 INFO Epoch 0: batch 3610/3610
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0830 
2025/02/24 00:54:43 INFO Epoch 0: batch 3611/3611
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:43 INFO Epoch 0: batch 3612/3612
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:43 INFO Epoch 0: batch 3613/3613
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:43 INFO Epoch 0: batch 3614/3614
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0797 
2025/02/24 00:54:43 INFO Epoch 0: batch 3615/3615
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0833 
2025/02/24 00:54:43 INFO Epoch 0: batch 3616/3616
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:43 INFO Epoch 0: batch 3617/3617
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:43 INFO Epoch 0: batch 3618/3618
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:43 INFO Epoch 0: batch 3619/3619
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:43 INFO Epoch 0: batch 3620/3620
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0855 
2025/02/24 00:54:43 INFO Epoch 0: batch 3621/3621
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0665 
2025/02/24 00:54:43 INFO Epoch 0: batch 3622/3622
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0871 
2025/02/24 00:54:43 INFO Epoch 0: batch 3623/3623
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0908 
2025/02/24 00:54:43 INFO Epoch 0: batch 3624/3624
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0607 
2025/02/24 00:54:43 INFO Epoch 0: batch 3625/3625
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0877 
2025/02/24 00:54:43 INFO Epoch 0: batch 3626/3626
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:43 INFO Epoch 0: batch 3627/3627
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0508 
2025/02/24 00:54:43 INFO Epoch 0: batch 3628/3628
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:43 INFO Epoch 0: batch 3629/3629
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:43 INFO Epoch 0: batch 3630/3630
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1019 
2025/02/24 00:54:43 INFO Epoch 0: batch 3631/3631
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0712 
2025/02/24 00:54:43 INFO Epoch 0: batch 3632/3632
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:43 INFO Epoch 0: batch 3633/3633
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:43 INFO Epoch 0: batch 3634/3634
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0836 
2025/02/24 00:54:43 INFO Epoch 0: batch 3635/3635
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:43 INFO Epoch 0: batch 3636/3636
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:43 INFO Epoch 0: batch 3637/3637
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0742 
2025/02/24 00:54:43 INFO Epoch 0: batch 3638/3638
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0594 
2025/02/24 00:54:43 INFO Epoch 0: batch 3639/3639
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:43 INFO Epoch 0: batch 3640/3640
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0839 
2025/02/24 00:54:43 INFO Epoch 0: batch 3641/3641
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0776 
2025/02/24 00:54:43 INFO Epoch 0: batch 3642/3642
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0816 
2025/02/24 00:54:43 INFO Epoch 0: batch 3643/3643
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:43 INFO Epoch 0: batch 3644/3644
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0672 
2025/02/24 00:54:43 INFO Epoch 0: batch 3645/3645
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:43 INFO Epoch 0: batch 3646/3646
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0652 
2025/02/24 00:54:43 INFO Epoch 0: batch 3647/3647
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:43 INFO Epoch 0: batch 3648/3648
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:43 INFO Epoch 0: batch 3649/3649
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:43 INFO Epoch 0: batch 3650/3650
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0619 
2025/02/24 00:54:43 INFO Epoch 0: batch 3651/3651
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:43 INFO Epoch 0: batch 3652/3652
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0980 
2025/02/24 00:54:43 INFO Epoch 0: batch 3653/3653
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0662 
2025/02/24 00:54:43 INFO Epoch 0: batch 3654/3654
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0613 
2025/02/24 00:54:43 INFO Epoch 0: batch 3655/3655
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0780 
2025/02/24 00:54:43 INFO Epoch 0: batch 3656/3656
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:43 INFO Epoch 0: batch 3657/3657
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:43 INFO Epoch 0: batch 3658/3658
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:43 INFO Epoch 0: batch 3659/3659
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0684 
2025/02/24 00:54:43 INFO Epoch 0: batch 3660/3660
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:43 INFO Epoch 0: batch 3661/3661
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:43 INFO Epoch 0: batch 3662/3662
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0822 
2025/02/24 00:54:43 INFO Epoch 0: batch 3663/3663
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0530 
2025/02/24 00:54:43 INFO Epoch 0: batch 3664/3664
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:43 INFO Epoch 0: batch 3665/3665
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:43 INFO Epoch 0: batch 3666/3666
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:43 INFO Epoch 0: batch 3667/3667
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0637 
2025/02/24 00:54:43 INFO Epoch 0: batch 3668/3668
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:43 INFO Epoch 0: batch 3669/3669
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:43 INFO Epoch 0: batch 3670/3670
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:43 INFO Epoch 0: batch 3671/3671
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0845 
2025/02/24 00:54:43 INFO Epoch 0: batch 3672/3672
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:43 INFO Epoch 0: batch 3673/3673
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:43 INFO Epoch 0: batch 3674/3674
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0840 
2025/02/24 00:54:43 INFO Epoch 0: batch 3675/3675
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:43 INFO Epoch 0: batch 3676/3676
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:43 INFO Epoch 0: batch 3677/3677
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0851 
2025/02/24 00:54:43 INFO Epoch 0: batch 3678/3678
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:43 INFO Epoch 0: batch 3679/3679
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0560 
2025/02/24 00:54:43 INFO Epoch 0: batch 3680/3680
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0791 
2025/02/24 00:54:43 INFO Epoch 0: batch 3681/3681
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:43 INFO Epoch 0: batch 3682/3682
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:43 INFO Epoch 0: batch 3683/3683
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:43 INFO Epoch 0: batch 3684/3684
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0832 
2025/02/24 00:54:43 INFO Epoch 0: batch 3685/3685
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0829 
2025/02/24 00:54:43 INFO Epoch 0: batch 3686/3686
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:43 INFO Epoch 0: batch 3687/3687
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:43 INFO Epoch 0: batch 3688/3688
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0650 
2025/02/24 00:54:43 INFO Epoch 0: batch 3689/3689
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:43 INFO Epoch 0: batch 3690/3690
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:43 INFO Epoch 0: batch 3691/3691
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0827 
2025/02/24 00:54:43 INFO Epoch 0: batch 3692/3692
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:43 INFO Epoch 0: batch 3693/3693
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:43 INFO Epoch 0: batch 3694/3694
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:43 INFO Epoch 0: batch 3695/3695
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:43 INFO Epoch 0: batch 3696/3696
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:43 INFO Epoch 0: batch 3697/3697
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:43 INFO Epoch 0: batch 3698/3698
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:43 INFO Epoch 0: batch 3699/3699
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:43 INFO Epoch 0: batch 3700/3700
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:43 INFO Epoch 0: batch 3701/3701
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0676 
2025/02/24 00:54:43 INFO Epoch 0: batch 3702/3702
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0738 
2025/02/24 00:54:43 INFO Epoch 0: batch 3703/3703
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:43 INFO Epoch 0: batch 3704/3704
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0751 
2025/02/24 00:54:43 INFO Epoch 0: batch 3705/3705
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:43 INFO Epoch 0: batch 3706/3706
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:43 INFO Epoch 0: batch 3707/3707
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0747 
2025/02/24 00:54:43 INFO Epoch 0: batch 3708/3708
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:43 INFO Epoch 0: batch 3709/3709
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:43 INFO Epoch 0: batch 3710/3710
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0957 
2025/02/24 00:54:43 INFO Epoch 0: batch 3711/3711
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:43 INFO Epoch 0: batch 3712/3712
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0807 
2025/02/24 00:54:43 INFO Epoch 0: batch 3713/3713
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:43 INFO Epoch 0: batch 3714/3714
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0772 
2025/02/24 00:54:43 INFO Epoch 0: batch 3715/3715
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:43 INFO Epoch 0: batch 3716/3716
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0879 
2025/02/24 00:54:43 INFO Epoch 0: batch 3717/3717
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:43 INFO Epoch 0: batch 3718/3718
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0911 
2025/02/24 00:54:43 INFO Epoch 0: batch 3719/3719
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0908 
2025/02/24 00:54:43 INFO Epoch 0: batch 3720/3720
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0823 
2025/02/24 00:54:43 INFO Epoch 0: batch 3721/3721
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:43 INFO Epoch 0: batch 3722/3722
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:43 INFO Epoch 0: batch 3723/3723
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1019 
2025/02/24 00:54:43 INFO Epoch 0: batch 3724/3724
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:43 INFO Epoch 0: batch 3725/3725
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:43 INFO Epoch 0: batch 3726/3726
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0794 
2025/02/24 00:54:43 INFO Epoch 0: batch 3727/3727
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0841 
2025/02/24 00:54:43 INFO Epoch 0: batch 3728/3728
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:43 INFO Epoch 0: batch 3729/3729
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:43 INFO Epoch 0: batch 3730/3730
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:43 INFO Epoch 0: batch 3731/3731
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0676 
2025/02/24 00:54:43 INFO Epoch 0: batch 3732/3732
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:43 INFO Epoch 0: batch 3733/3733
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:43 INFO Epoch 0: batch 3734/3734
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0993 
2025/02/24 00:54:43 INFO Epoch 0: batch 3735/3735
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:43 INFO Epoch 0: batch 3736/3736
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0583 
2025/02/24 00:54:43 INFO Epoch 0: batch 3737/3737
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1004 
2025/02/24 00:54:43 INFO Epoch 0: batch 3738/3738
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0815 
2025/02/24 00:54:43 INFO Epoch 0: batch 3739/3739
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:43 INFO Epoch 0: batch 3740/3740
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:43 INFO Epoch 0: batch 3741/3741
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0725 
2025/02/24 00:54:43 INFO Epoch 0: batch 3742/3742
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0836 
2025/02/24 00:54:43 INFO Epoch 0: batch 3743/3743
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:43 INFO Epoch 0: batch 3744/3744
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0869 
2025/02/24 00:54:43 INFO Epoch 0: batch 3745/3745
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:43 INFO Epoch 0: batch 3746/3746
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0622 
2025/02/24 00:54:43 INFO Epoch 0: batch 3747/3747
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0681 
2025/02/24 00:54:43 INFO Epoch 0: batch 3748/3748
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0761 
2025/02/24 00:54:43 INFO Epoch 0: batch 3749/3749
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0893 
2025/02/24 00:54:43 INFO Epoch 0: batch 3750/3750
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0838 
2025/02/24 00:54:43 INFO Epoch 0: batch 3751/3751
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0628 
2025/02/24 00:54:43 INFO Epoch 0: batch 3752/3752
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:43 INFO Epoch 0: batch 3753/3753
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:43 INFO Epoch 0: batch 3754/3754
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:43 INFO Epoch 0: batch 3755/3755
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:43 INFO Epoch 0: batch 3756/3756
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0915 
2025/02/24 00:54:43 INFO Epoch 0: batch 3757/3757
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0861 
2025/02/24 00:54:43 INFO Epoch 0: batch 3758/3758
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0638 
2025/02/24 00:54:43 INFO Epoch 0: batch 3759/3759
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0655 
2025/02/24 00:54:43 INFO Epoch 0: batch 3760/3760
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0539 
2025/02/24 00:54:43 INFO Epoch 0: batch 3761/3761
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:43 INFO Epoch 0: batch 3762/3762
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:43 INFO Epoch 0: batch 3763/3763
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0796 
2025/02/24 00:54:43 INFO Epoch 0: batch 3764/3764
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:43 INFO Epoch 0: batch 3765/3765
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:43 INFO Epoch 0: batch 3766/3766
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:43 INFO Epoch 0: batch 3767/3767
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:43 INFO Epoch 0: batch 3768/3768
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0857 
2025/02/24 00:54:43 INFO Epoch 0: batch 3769/3769
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0674 
2025/02/24 00:54:43 INFO Epoch 0: batch 3770/3770
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:43 INFO Epoch 0: batch 3771/3771
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0762 
2025/02/24 00:54:43 INFO Epoch 0: batch 3772/3772
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:43 INFO Epoch 0: batch 3773/3773
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:43 INFO Epoch 0: batch 3774/3774
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1115 
2025/02/24 00:54:43 INFO Epoch 0: batch 3775/3775
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0669 
2025/02/24 00:54:43 INFO Epoch 0: batch 3776/3776
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:43 INFO Epoch 0: batch 3777/3777
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0679 
2025/02/24 00:54:43 INFO Epoch 0: batch 3778/3778
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0947 
2025/02/24 00:54:43 INFO Epoch 0: batch 3779/3779
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0898 
2025/02/24 00:54:43 INFO Epoch 0: batch 3780/3780
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0936 
2025/02/24 00:54:43 INFO Epoch 0: batch 3781/3781
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0634 
2025/02/24 00:54:43 INFO Epoch 0: batch 3782/3782
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:43 INFO Epoch 0: batch 3783/3783
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0971 
2025/02/24 00:54:43 INFO Epoch 0: batch 3784/3784
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0581 
2025/02/24 00:54:43 INFO Epoch 0: batch 3785/3785
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0778 
2025/02/24 00:54:43 INFO Epoch 0: batch 3786/3786
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:43 INFO Epoch 0: batch 3787/3787
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:43 INFO Epoch 0: batch 3788/3788
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:43 INFO Epoch 0: batch 3789/3789
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0718 
2025/02/24 00:54:43 INFO Epoch 0: batch 3790/3790
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0880 
2025/02/24 00:54:43 INFO Epoch 0: batch 3791/3791
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0626 
2025/02/24 00:54:43 INFO Epoch 0: batch 3792/3792
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:43 INFO Epoch 0: batch 3793/3793
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0793 
2025/02/24 00:54:43 INFO Epoch 0: batch 3794/3794
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0657 
2025/02/24 00:54:43 INFO Epoch 0: batch 3795/3795
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0721 
2025/02/24 00:54:43 INFO Epoch 0: batch 3796/3796
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0705 
2025/02/24 00:54:43 INFO Epoch 0: batch 3797/3797
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0828 
2025/02/24 00:54:43 INFO Epoch 0: batch 3798/3798
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0702 
2025/02/24 00:54:43 INFO Epoch 0: batch 3799/3799
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:43 INFO Epoch 0: batch 3800/3800
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0614 
2025/02/24 00:54:43 INFO Epoch 0: batch 3801/3801
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0884 
2025/02/24 00:54:43 INFO Epoch 0: batch 3802/3802
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:43 INFO Epoch 0: batch 3803/3803
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0906 
2025/02/24 00:54:43 INFO Epoch 0: batch 3804/3804
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1064 
2025/02/24 00:54:43 INFO Epoch 0: batch 3805/3805
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:43 INFO Epoch 0: batch 3806/3806
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0737 
2025/02/24 00:54:43 INFO Epoch 0: batch 3807/3807
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.1029 
2025/02/24 00:54:43 INFO Epoch 0: batch 3808/3808
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0682 
2025/02/24 00:54:43 INFO Epoch 0: batch 3809/3809
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0947 
2025/02/24 00:54:43 INFO Epoch 0: batch 3810/3810
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0803 
2025/02/24 00:54:43 INFO Epoch 0: batch 3811/3811
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:43 INFO Epoch 0: batch 3812/3812
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:43 INFO Epoch 0: batch 3813/3813
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0865 
2025/02/24 00:54:43 INFO Epoch 0: batch 3814/3814
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0695 
2025/02/24 00:54:43 INFO Epoch 0: batch 3815/3815
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:43 INFO Epoch 0: batch 3816/3816
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0554 
2025/02/24 00:54:43 INFO Epoch 0: batch 3817/3817
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0694 
2025/02/24 00:54:43 INFO Epoch 0: batch 3818/3818
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0846 
2025/02/24 00:54:43 INFO Epoch 0: batch 3819/3819
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:43 INFO Epoch 0: batch 3820/3820
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:43 INFO Epoch 0: batch 3821/3821
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:43 INFO Epoch 0: batch 3822/3822
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0727 
2025/02/24 00:54:43 INFO Epoch 0: batch 3823/3823
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:43 INFO Epoch 0: batch 3824/3824
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:43 INFO Epoch 0: batch 3825/3825
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0844 
2025/02/24 00:54:43 INFO Epoch 0: batch 3826/3826
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0483 
2025/02/24 00:54:43 INFO Epoch 0: batch 3827/3827
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0538 
2025/02/24 00:54:43 INFO Epoch 0: batch 3828/3828
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0602 
2025/02/24 00:54:43 INFO Epoch 0: batch 3829/3829
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0730 
2025/02/24 00:54:43 INFO Epoch 0: batch 3830/3830
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:43 INFO Epoch 0: batch 3831/3831
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:43 INFO Epoch 0: batch 3832/3832
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0857 
2025/02/24 00:54:43 INFO Epoch 0: batch 3833/3833
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0639 
2025/02/24 00:54:43 INFO Epoch 0: batch 3834/3834
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:43 INFO Epoch 0: batch 3835/3835
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0821 
2025/02/24 00:54:43 INFO Epoch 0: batch 3836/3836
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0787 
2025/02/24 00:54:43 INFO Epoch 0: batch 3837/3837
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:43 INFO Epoch 0: batch 3838/3838
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0767 
2025/02/24 00:54:43 INFO Epoch 0: batch 3839/3839
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:43 INFO Epoch 0: batch 3840/3840
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0775 
2025/02/24 00:54:43 INFO Epoch 0: batch 3841/3841
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0709 
2025/02/24 00:54:43 INFO Epoch 0: batch 3842/3842
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0621 
2025/02/24 00:54:43 INFO Epoch 0: batch 3843/3843
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0632 
2025/02/24 00:54:43 INFO Epoch 0: batch 3844/3844
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0629 
2025/02/24 00:54:43 INFO Epoch 0: batch 3845/3845
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0928 
2025/02/24 00:54:43 INFO Epoch 0: batch 3846/3846
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0756 
2025/02/24 00:54:43 INFO Epoch 0: batch 3847/3847
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0659 
2025/02/24 00:54:43 INFO Epoch 0: batch 3848/3848
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0730 
2025/02/24 00:54:43 INFO Epoch 0: batch 3849/3849
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0913 
2025/02/24 00:54:43 INFO Epoch 0: batch 3850/3850
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0625 
2025/02/24 00:54:43 INFO Epoch 0: batch 3851/3851
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0583 
2025/02/24 00:54:43 INFO Epoch 0: batch 3852/3852
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0920 
2025/02/24 00:54:43 INFO Epoch 0: batch 3853/3853
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:43 INFO Epoch 0: batch 3854/3854
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:43 INFO Epoch 0: batch 3855/3855
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:43 INFO Epoch 0: batch 3856/3856
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0868 
2025/02/24 00:54:43 INFO Epoch 0: batch 3857/3857
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:43 INFO Epoch 0: batch 3858/3858
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0736 
2025/02/24 00:54:43 INFO Epoch 0: batch 3859/3859
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0673 
2025/02/24 00:54:43 INFO Epoch 0: batch 3860/3860
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0734 
2025/02/24 00:54:43 INFO Epoch 0: batch 3861/3861
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0719 
2025/02/24 00:54:43 INFO Epoch 0: batch 3862/3862
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0624 
2025/02/24 00:54:43 INFO Epoch 0: batch 3863/3863
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0766 
2025/02/24 00:54:43 INFO Epoch 0: batch 3864/3864
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0773 
2025/02/24 00:54:43 INFO Epoch 0: batch 3865/3865
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0611 
2025/02/24 00:54:43 INFO Epoch 0: batch 3866/3866
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:43 INFO Epoch 0: batch 3867/3867
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0914 
2025/02/24 00:54:43 INFO Epoch 0: batch 3868/3868
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0877 
2025/02/24 00:54:43 INFO Epoch 0: batch 3869/3869
2025/02/24 00:54:43 INFO          m 0.00010 
2025/02/24 00:54:43 INFO          Training stage 1 Training_loss 0.0849 
2025/02/24 00:54:44 INFO Epoch 0: batch 3870/3870
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0675 
2025/02/24 00:54:44 INFO Epoch 0: batch 3871/3871
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:44 INFO Epoch 0: batch 3872/3872
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0887 
2025/02/24 00:54:44 INFO Epoch 0: batch 3873/3873
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0856 
2025/02/24 00:54:44 INFO Epoch 0: batch 3874/3874
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0589 
2025/02/24 00:54:44 INFO Epoch 0: batch 3875/3875
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0749 
2025/02/24 00:54:44 INFO Epoch 0: batch 3876/3876
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0771 
2025/02/24 00:54:44 INFO Epoch 0: batch 3877/3877
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0676 
2025/02/24 00:54:44 INFO Epoch 0: batch 3878/3878
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0593 
2025/02/24 00:54:44 INFO Epoch 0: batch 3879/3879
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0744 
2025/02/24 00:54:44 INFO Epoch 0: batch 3880/3880
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0774 
2025/02/24 00:54:44 INFO Epoch 0: batch 3881/3881
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:44 INFO Epoch 0: batch 3882/3882
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0859 
2025/02/24 00:54:44 INFO Epoch 0: batch 3883/3883
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0701 
2025/02/24 00:54:44 INFO Epoch 0: batch 3884/3884
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0912 
2025/02/24 00:54:44 INFO Epoch 0: batch 3885/3885
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:44 INFO Epoch 0: batch 3886/3886
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0799 
2025/02/24 00:54:44 INFO Epoch 0: batch 3887/3887
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0616 
2025/02/24 00:54:44 INFO Epoch 0: batch 3888/3888
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0739 
2025/02/24 00:54:44 INFO Epoch 0: batch 3889/3889
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.1077 
2025/02/24 00:54:44 INFO Epoch 0: batch 3890/3890
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0878 
2025/02/24 00:54:44 INFO Epoch 0: batch 3891/3891
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0882 
2025/02/24 00:54:44 INFO Epoch 0: batch 3892/3892
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0588 
2025/02/24 00:54:44 INFO Epoch 0: batch 3893/3893
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0982 
2025/02/24 00:54:44 INFO Epoch 0: batch 3894/3894
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0918 
2025/02/24 00:54:44 INFO Epoch 0: batch 3895/3895
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:44 INFO Epoch 0: batch 3896/3896
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:44 INFO Epoch 0: batch 3897/3897
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0646 
2025/02/24 00:54:44 INFO Epoch 0: batch 3898/3898
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0768 
2025/02/24 00:54:44 INFO Epoch 0: batch 3899/3899
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0861 
2025/02/24 00:54:44 INFO Epoch 0: batch 3900/3900
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:44 INFO Epoch 0: batch 3901/3901
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:44 INFO Epoch 0: batch 3902/3902
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0704 
2025/02/24 00:54:44 INFO Epoch 0: batch 3903/3903
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:44 INFO Epoch 0: batch 3904/3904
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0710 
2025/02/24 00:54:44 INFO Epoch 0: batch 3905/3905
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0741 
2025/02/24 00:54:44 INFO Epoch 0: batch 3906/3906
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0759 
2025/02/24 00:54:44 INFO Epoch 0: batch 3907/3907
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0820 
2025/02/24 00:54:44 INFO Epoch 0: batch 3908/3908
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0714 
2025/02/24 00:54:44 INFO Epoch 0: batch 3909/3909
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0703 
2025/02/24 00:54:44 INFO Epoch 0: batch 3910/3910
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:44 INFO Epoch 0: batch 3911/3911
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0805 
2025/02/24 00:54:44 INFO Epoch 0: batch 3912/3912
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0517 
2025/02/24 00:54:44 INFO Epoch 0: batch 3913/3913
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0824 
2025/02/24 00:54:44 INFO Epoch 0: batch 3914/3914
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0583 
2025/02/24 00:54:44 INFO Epoch 0: batch 3915/3915
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:44 INFO Epoch 0: batch 3916/3916
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:44 INFO Epoch 0: batch 3917/3917
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0575 
2025/02/24 00:54:44 INFO Epoch 0: batch 3918/3918
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0790 
2025/02/24 00:54:44 INFO Epoch 0: batch 3919/3919
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:44 INFO Epoch 0: batch 3920/3920
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0929 
2025/02/24 00:54:44 INFO Epoch 0: batch 3921/3921
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:44 INFO Epoch 0: batch 3922/3922
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0802 
2025/02/24 00:54:44 INFO Epoch 0: batch 3923/3923
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0812 
2025/02/24 00:54:44 INFO Epoch 0: batch 3924/3924
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0784 
2025/02/24 00:54:44 INFO Epoch 0: batch 3925/3925
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:44 INFO Epoch 0: batch 3926/3926
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0764 
2025/02/24 00:54:44 INFO Epoch 0: batch 3927/3927
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0605 
2025/02/24 00:54:44 INFO Epoch 0: batch 3928/3928
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0658 
2025/02/24 00:54:44 INFO Epoch 0: batch 3929/3929
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0895 
2025/02/24 00:54:44 INFO Epoch 0: batch 3930/3930
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0667 
2025/02/24 00:54:44 INFO Epoch 0: batch 3931/3931
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0729 
2025/02/24 00:54:44 INFO Epoch 0: batch 3932/3932
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:44 INFO Epoch 0: batch 3933/3933
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0745 
2025/02/24 00:54:44 INFO Epoch 0: batch 3934/3934
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0748 
2025/02/24 00:54:44 INFO Epoch 0: batch 3935/3935
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0618 
2025/02/24 00:54:44 INFO Epoch 0: batch 3936/3936
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0608 
2025/02/24 00:54:44 INFO Epoch 0: batch 3937/3937
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0716 
2025/02/24 00:54:44 INFO Epoch 0: batch 3938/3938
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0596 
2025/02/24 00:54:44 INFO Epoch 0: batch 3939/3939
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0726 
2025/02/24 00:54:44 INFO Epoch 0: batch 3940/3940
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0562 
2025/02/24 00:54:44 INFO Epoch 0: batch 3941/3941
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0800 
2025/02/24 00:54:44 INFO Epoch 0: batch 3942/3942
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0788 
2025/02/24 00:54:44 INFO Epoch 0: batch 3943/3943
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0779 
2025/02/24 00:54:44 INFO Epoch 0: batch 3944/3944
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0540 
2025/02/24 00:54:44 INFO Epoch 0: batch 3945/3945
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:44 INFO Epoch 0: batch 3946/3946
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0664 
2025/02/24 00:54:44 INFO Epoch 0: batch 3947/3947
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0487 
2025/02/24 00:54:44 INFO Epoch 0: batch 3948/3948
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:44 INFO Epoch 0: batch 3949/3949
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0600 
2025/02/24 00:54:44 INFO Epoch 0: batch 3950/3950
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0609 
2025/02/24 00:54:44 INFO Epoch 0: batch 3951/3951
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.1140 
2025/02/24 00:54:44 INFO Epoch 0: batch 3952/3952
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0786 
2025/02/24 00:54:44 INFO Epoch 0: batch 3953/3953
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0689 
2025/02/24 00:54:44 INFO Epoch 0: batch 3954/3954
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:44 INFO Epoch 0: batch 3955/3955
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:44 INFO Epoch 0: batch 3956/3956
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0663 
2025/02/24 00:54:44 INFO Epoch 0: batch 3957/3957
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0752 
2025/02/24 00:54:44 INFO Epoch 0: batch 3958/3958
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:44 INFO Epoch 0: batch 3959/3959
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:44 INFO Epoch 0: batch 3960/3960
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:44 INFO Epoch 0: batch 3961/3961
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0601 
2025/02/24 00:54:44 INFO Epoch 0: batch 3962/3962
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0517 
2025/02/24 00:54:44 INFO Epoch 0: batch 3963/3963
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0697 
2025/02/24 00:54:44 INFO Epoch 0: batch 3964/3964
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0899 
2025/02/24 00:54:44 INFO Epoch 0: batch 3965/3965
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:44 INFO Epoch 0: batch 3966/3966
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0758 
2025/02/24 00:54:44 INFO Epoch 0: batch 3967/3967
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0817 
2025/02/24 00:54:44 INFO Epoch 0: batch 3968/3968
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:44 INFO Epoch 0: batch 3969/3969
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0631 
2025/02/24 00:54:44 INFO Epoch 0: batch 3970/3970
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0678 
2025/02/24 00:54:44 INFO Epoch 0: batch 3971/3971
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:44 INFO Epoch 0: batch 3972/3972
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0785 
2025/02/24 00:54:44 INFO Epoch 0: batch 3973/3973
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0763 
2025/02/24 00:54:44 INFO Epoch 0: batch 3974/3974
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0706 
2025/02/24 00:54:44 INFO Epoch 0: batch 3975/3975
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0781 
2025/02/24 00:54:44 INFO Epoch 0: batch 3976/3976
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0484 
2025/02/24 00:54:44 INFO Epoch 0: batch 3977/3977
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0660 
2025/02/24 00:54:44 INFO Epoch 0: batch 3978/3978
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0598 
2025/02/24 00:54:44 INFO Epoch 0: batch 3979/3979
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:44 INFO Epoch 0: batch 3980/3980
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0743 
2025/02/24 00:54:44 INFO Epoch 0: batch 3981/3981
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0685 
2025/02/24 00:54:44 INFO Epoch 0: batch 3982/3982
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:44 INFO Epoch 0: batch 3983/3983
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:44 INFO Epoch 0: batch 3984/3984
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:44 INFO Epoch 0: batch 3985/3985
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0615 
2025/02/24 00:54:44 INFO Epoch 0: batch 3986/3986
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0810 
2025/02/24 00:54:44 INFO Epoch 0: batch 3987/3987
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0757 
2025/02/24 00:54:44 INFO Epoch 0: batch 3988/3988
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0892 
2025/02/24 00:54:44 INFO Epoch 0: batch 3989/3989
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0860 
2025/02/24 00:54:44 INFO Epoch 0: batch 3990/3990
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0641 
2025/02/24 00:54:44 INFO Epoch 0: batch 3991/3991
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0651 
2025/02/24 00:54:44 INFO Epoch 0: batch 3992/3992
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0728 
2025/02/24 00:54:44 INFO Epoch 0: batch 3993/3993
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0707 
2025/02/24 00:54:44 INFO Epoch 0: batch 3994/3994
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0826 
2025/02/24 00:54:44 INFO Epoch 0: batch 3995/3995
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0692 
2025/02/24 00:54:44 INFO Epoch 0: batch 3996/3996
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0606 
2025/02/24 00:54:44 INFO Epoch 0: batch 3997/3997
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0735 
2025/02/24 00:54:44 INFO Epoch 0: batch 3998/3998
2025/02/24 00:54:44 INFO          m 0.00010 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0789 
2025/02/24 00:54:44 INFO Epoch 0: batch 3999/3999
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0717 
2025/02/24 00:54:44 INFO Epoch 0: batch 4000/4000
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0902 
2025/02/24 00:54:44 INFO Epoch 0: batch 4001/4001
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0683 
2025/02/24 00:54:44 INFO Epoch 0: batch 4002/4002
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0770 
2025/02/24 00:54:44 INFO Epoch 0: batch 4003/4003
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0559 
2025/02/24 00:54:44 INFO Epoch 0: batch 4004/4004
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0808 
2025/02/24 00:54:44 INFO Epoch 0: batch 4005/4005
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0693 
2025/02/24 00:54:44 INFO Epoch 0: batch 4006/4006
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0750 
2025/02/24 00:54:44 INFO Epoch 0: batch 4007/4007
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0653 
2025/02/24 00:54:44 INFO Epoch 0: batch 4008/4008
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0900 
2025/02/24 00:54:44 INFO Epoch 0: batch 4009/4009
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0783 
2025/02/24 00:54:44 INFO Epoch 0: batch 4010/4010
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:44 INFO Epoch 0: batch 4011/4011
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0733 
2025/02/24 00:54:44 INFO Epoch 0: batch 4012/4012
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0610 
2025/02/24 00:54:44 INFO Epoch 0: batch 4013/4013
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0572 
2025/02/24 00:54:44 INFO Epoch 0: batch 4014/4014
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0563 
2025/02/24 00:54:44 INFO Epoch 0: batch 4015/4015
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0818 
2025/02/24 00:54:44 INFO Epoch 0: batch 4016/4016
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:44 INFO Epoch 0: batch 4017/4017
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0720 
2025/02/24 00:54:44 INFO Epoch 0: batch 4018/4018
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0731 
2025/02/24 00:54:44 INFO Epoch 0: batch 4019/4019
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0620 
2025/02/24 00:54:44 INFO Epoch 0: batch 4020/4020
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0649 
2025/02/24 00:54:44 INFO Epoch 0: batch 4021/4021
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0627 
2025/02/24 00:54:44 INFO Epoch 0: batch 4022/4022
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0537 
2025/02/24 00:54:44 INFO Epoch 0: batch 4023/4023
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0522 
2025/02/24 00:54:44 INFO Epoch 0: batch 4024/4024
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0603 
2025/02/24 00:54:44 INFO Epoch 0: batch 4025/4025
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:44 INFO Epoch 0: batch 4026/4026
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0622 
2025/02/24 00:54:44 INFO Epoch 0: batch 4027/4027
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0508 
2025/02/24 00:54:44 INFO Epoch 0: batch 4028/4028
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0522 
2025/02/24 00:54:44 INFO Epoch 0: batch 4029/4029
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0765 
2025/02/24 00:54:44 INFO Epoch 0: batch 4030/4030
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0724 
2025/02/24 00:54:44 INFO Epoch 0: batch 4031/4031
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0723 
2025/02/24 00:54:44 INFO Epoch 0: batch 4032/4032
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0687 
2025/02/24 00:54:44 INFO Epoch 0: batch 4033/4033
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0654 
2025/02/24 00:54:44 INFO Epoch 0: batch 4034/4034
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0647 
2025/02/24 00:54:44 INFO Epoch 0: batch 4035/4035
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0512 
2025/02/24 00:54:44 INFO Epoch 0: batch 4036/4036
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:44 INFO Epoch 0: batch 4037/4037
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0522 
2025/02/24 00:54:44 INFO Epoch 0: batch 4038/4038
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0636 
2025/02/24 00:54:44 INFO Epoch 0: batch 4039/4039
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0698 
2025/02/24 00:54:44 INFO Epoch 0: batch 4040/4040
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0713 
2025/02/24 00:54:44 INFO Epoch 0: batch 4041/4041
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0547 
2025/02/24 00:54:44 INFO Epoch 0: batch 4042/4042
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0562 
2025/02/24 00:54:44 INFO Epoch 0: batch 4043/4043
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0699 
2025/02/24 00:54:44 INFO Epoch 0: batch 4044/4044
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0508 
2025/02/24 00:54:44 INFO Epoch 0: batch 4045/4045
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0458 
2025/02/24 00:54:44 INFO Epoch 0: batch 4046/4046
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0696 
2025/02/24 00:54:44 INFO Epoch 0: batch 4047/4047
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0539 
2025/02/24 00:54:44 INFO Epoch 0: batch 4048/4048
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0633 
2025/02/24 00:54:44 INFO Epoch 0: batch 4049/4049
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0562 
2025/02/24 00:54:44 INFO Epoch 0: batch 4050/4050
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0635 
2025/02/24 00:54:44 INFO Epoch 0: batch 4051/4051
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0643 
2025/02/24 00:54:44 INFO Epoch 0: batch 4052/4052
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0671 
2025/02/24 00:54:44 INFO Epoch 0: batch 4053/4053
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0597 
2025/02/24 00:54:44 INFO Epoch 0: batch 4054/4054
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0438 
2025/02/24 00:54:44 INFO Epoch 0: batch 4055/4055
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0427 
2025/02/24 00:54:44 INFO Epoch 0: batch 4056/4056
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0476 
2025/02/24 00:54:44 INFO Epoch 0: batch 4057/4057
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0504 
2025/02/24 00:54:44 INFO Epoch 0: batch 4058/4058
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0595 
2025/02/24 00:54:44 INFO Epoch 0: batch 4059/4059
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0502 
2025/02/24 00:54:44 INFO Epoch 0: batch 4060/4060
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0584 
2025/02/24 00:54:44 INFO Epoch 0: batch 4061/4061
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0563 
2025/02/24 00:54:44 INFO Epoch 0: batch 4062/4062
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0444 
2025/02/24 00:54:44 INFO Epoch 0: batch 4063/4063
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0406 
2025/02/24 00:54:44 INFO Epoch 0: batch 4064/4064
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0477 
2025/02/24 00:54:44 INFO Epoch 0: batch 4065/4065
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0470 
2025/02/24 00:54:44 INFO Epoch 0: batch 4066/4066
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0461 
2025/02/24 00:54:44 INFO Epoch 0: batch 4067/4067
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0562 
2025/02/24 00:54:44 INFO Epoch 0: batch 4068/4068
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0436 
2025/02/24 00:54:44 INFO Epoch 0: batch 4069/4069
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0454 
2025/02/24 00:54:44 INFO Epoch 0: batch 4070/4070
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0442 
2025/02/24 00:54:44 INFO Epoch 0: batch 4071/4071
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0476 
2025/02/24 00:54:44 INFO Epoch 0: batch 4072/4072
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0430 
2025/02/24 00:54:44 INFO Epoch 0: batch 4073/4073
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0470 
2025/02/24 00:54:44 INFO Epoch 0: batch 4074/4074
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0564 
2025/02/24 00:54:44 INFO Epoch 0: batch 4075/4075
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0334 
2025/02/24 00:54:44 INFO Epoch 0: batch 4076/4076
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0414 
2025/02/24 00:54:44 INFO Epoch 0: batch 4077/4077
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0445 
2025/02/24 00:54:44 INFO Epoch 0: batch 4078/4078
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0460 
2025/02/24 00:54:44 INFO Epoch 0: batch 4079/4079
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0617 
2025/02/24 00:54:44 INFO Epoch 0: batch 4080/4080
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0473 
2025/02/24 00:54:44 INFO Epoch 0: batch 4081/4081
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0377 
2025/02/24 00:54:44 INFO Epoch 0: batch 4082/4082
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0414 
2025/02/24 00:54:44 INFO Epoch 0: batch 4083/4083
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0440 
2025/02/24 00:54:44 INFO Epoch 0: batch 4084/4084
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0471 
2025/02/24 00:54:44 INFO Epoch 0: batch 4085/4085
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0395 
2025/02/24 00:54:44 INFO Epoch 0: batch 4086/4086
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0431 
2025/02/24 00:54:44 INFO Epoch 0: batch 4087/4087
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0419 
2025/02/24 00:54:44 INFO Epoch 0: batch 4088/4088
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0388 
2025/02/24 00:54:44 INFO Epoch 0: batch 4089/4089
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0483 
2025/02/24 00:54:44 INFO Epoch 0: batch 4090/4090
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0409 
2025/02/24 00:54:44 INFO Epoch 0: batch 4091/4091
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0367 
2025/02/24 00:54:44 INFO Epoch 0: batch 4092/4092
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0340 
2025/02/24 00:54:44 INFO Epoch 0: batch 4093/4093
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0456 
2025/02/24 00:54:44 INFO Epoch 0: batch 4094/4094
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0384 
2025/02/24 00:54:44 INFO Epoch 0: batch 4095/4095
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0395 
2025/02/24 00:54:44 INFO Epoch 0: batch 4096/4096
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0367 
2025/02/24 00:54:44 INFO Epoch 0: batch 4097/4097
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0350 
2025/02/24 00:54:44 INFO Epoch 0: batch 4098/4098
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0327 
2025/02/24 00:54:44 INFO Epoch 0: batch 4099/4099
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0456 
2025/02/24 00:54:44 INFO Epoch 0: batch 4100/4100
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0461 
2025/02/24 00:54:44 INFO Epoch 0: batch 4101/4101
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0429 
2025/02/24 00:54:44 INFO Epoch 0: batch 4102/4102
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0337 
2025/02/24 00:54:44 INFO Epoch 0: batch 4103/4103
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0423 
2025/02/24 00:54:44 INFO Epoch 0: batch 4104/4104
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0406 
2025/02/24 00:54:44 INFO Epoch 0: batch 4105/4105
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0357 
2025/02/24 00:54:44 INFO Epoch 0: batch 4106/4106
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0418 
2025/02/24 00:54:44 INFO Epoch 0: batch 4107/4107
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0299 
2025/02/24 00:54:44 INFO Epoch 0: batch 4108/4108
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0343 
2025/02/24 00:54:44 INFO Epoch 0: batch 4109/4109
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0366 
2025/02/24 00:54:44 INFO Epoch 0: batch 4110/4110
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0449 
2025/02/24 00:54:44 INFO Epoch 0: batch 4111/4111
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0420 
2025/02/24 00:54:44 INFO Epoch 0: batch 4112/4112
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0334 
2025/02/24 00:54:44 INFO Epoch 0: batch 4113/4113
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0364 
2025/02/24 00:54:44 INFO Epoch 0: batch 4114/4114
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0309 
2025/02/24 00:54:44 INFO Epoch 0: batch 4115/4115
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0389 
2025/02/24 00:54:44 INFO Epoch 0: batch 4116/4116
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0370 
2025/02/24 00:54:44 INFO Epoch 0: batch 4117/4117
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0357 
2025/02/24 00:54:44 INFO Epoch 0: batch 4118/4118
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0356 
2025/02/24 00:54:44 INFO Epoch 0: batch 4119/4119
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0434 
2025/02/24 00:54:44 INFO Epoch 0: batch 4120/4120
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0399 
2025/02/24 00:54:44 INFO Epoch 0: batch 4121/4121
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0352 
2025/02/24 00:54:44 INFO Epoch 0: batch 4122/4122
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0312 
2025/02/24 00:54:44 INFO Epoch 0: batch 4123/4123
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0391 
2025/02/24 00:54:44 INFO Epoch 0: batch 4124/4124
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0401 
2025/02/24 00:54:44 INFO Epoch 0: batch 4125/4125
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0332 
2025/02/24 00:54:44 INFO Epoch 0: batch 4126/4126
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0384 
2025/02/24 00:54:44 INFO Epoch 0: batch 4127/4127
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0476 
2025/02/24 00:54:44 INFO Epoch 0: batch 4128/4128
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0431 
2025/02/24 00:54:44 INFO Epoch 0: batch 4129/4129
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0296 
2025/02/24 00:54:44 INFO Epoch 0: batch 4130/4130
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0354 
2025/02/24 00:54:44 INFO Epoch 0: batch 4131/4131
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0414 
2025/02/24 00:54:44 INFO Epoch 0: batch 4132/4132
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0266 
2025/02/24 00:54:44 INFO Epoch 0: batch 4133/4133
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0406 
2025/02/24 00:54:44 INFO Epoch 0: batch 4134/4134
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0328 
2025/02/24 00:54:44 INFO Epoch 0: batch 4135/4135
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0290 
2025/02/24 00:54:44 INFO Epoch 0: batch 4136/4136
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0380 
2025/02/24 00:54:44 INFO Epoch 0: batch 4137/4137
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0349 
2025/02/24 00:54:44 INFO Epoch 0: batch 4138/4138
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0273 
2025/02/24 00:54:44 INFO Epoch 0: batch 4139/4139
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0428 
2025/02/24 00:54:44 INFO Epoch 0: batch 4140/4140
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0324 
2025/02/24 00:54:44 INFO Epoch 0: batch 4141/4141
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0320 
2025/02/24 00:54:44 INFO Epoch 0: batch 4142/4142
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0319 
2025/02/24 00:54:44 INFO Epoch 0: batch 4143/4143
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0434 
2025/02/24 00:54:44 INFO Epoch 0: batch 4144/4144
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0302 
2025/02/24 00:54:44 INFO Epoch 0: batch 4145/4145
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0262 
2025/02/24 00:54:44 INFO Epoch 0: batch 4146/4146
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0338 
2025/02/24 00:54:44 INFO Epoch 0: batch 4147/4147
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0330 
2025/02/24 00:54:44 INFO Epoch 0: batch 4148/4148
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0317 
2025/02/24 00:54:44 INFO Epoch 0: batch 4149/4149
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0317 
2025/02/24 00:54:44 INFO Epoch 0: batch 4150/4150
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0362 
2025/02/24 00:54:44 INFO Epoch 0: batch 4151/4151
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0292 
2025/02/24 00:54:44 INFO Epoch 0: batch 4152/4152
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0394 
2025/02/24 00:54:44 INFO Epoch 0: batch 4153/4153
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0300 
2025/02/24 00:54:44 INFO Epoch 0: batch 4154/4154
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0372 
2025/02/24 00:54:44 INFO Epoch 0: batch 4155/4155
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0288 
2025/02/24 00:54:44 INFO Epoch 0: batch 4156/4156
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0285 
2025/02/24 00:54:44 INFO Epoch 0: batch 4157/4157
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0311 
2025/02/24 00:54:44 INFO Epoch 0: batch 4158/4158
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0328 
2025/02/24 00:54:44 INFO Epoch 0: batch 4159/4159
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0293 
2025/02/24 00:54:44 INFO Epoch 0: batch 4160/4160
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0315 
2025/02/24 00:54:44 INFO Epoch 0: batch 4161/4161
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0232 
2025/02/24 00:54:44 INFO Epoch 0: batch 4162/4162
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0323 
2025/02/24 00:54:44 INFO Epoch 0: batch 4163/4163
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0378 
2025/02/24 00:54:44 INFO Epoch 0: batch 4164/4164
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0345 
2025/02/24 00:54:44 INFO Epoch 0: batch 4165/4165
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0314 
2025/02/24 00:54:44 INFO Epoch 0: batch 4166/4166
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0420 
2025/02/24 00:54:44 INFO Epoch 0: batch 4167/4167
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0299 
2025/02/24 00:54:44 INFO Epoch 0: batch 4168/4168
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0326 
2025/02/24 00:54:44 INFO Epoch 0: batch 4169/4169
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0240 
2025/02/24 00:54:44 INFO Epoch 0: batch 4170/4170
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0264 
2025/02/24 00:54:44 INFO Epoch 0: batch 4171/4171
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0239 
2025/02/24 00:54:44 INFO Epoch 0: batch 4172/4172
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0330 
2025/02/24 00:54:44 INFO Epoch 0: batch 4173/4173
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0365 
2025/02/24 00:54:44 INFO Epoch 0: batch 4174/4174
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0269 
2025/02/24 00:54:44 INFO Epoch 0: batch 4175/4175
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0251 
2025/02/24 00:54:44 INFO Epoch 0: batch 4176/4176
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0303 
2025/02/24 00:54:44 INFO Epoch 0: batch 4177/4177
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0306 
2025/02/24 00:54:44 INFO Epoch 0: batch 4178/4178
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0312 
2025/02/24 00:54:44 INFO Epoch 0: batch 4179/4179
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0260 
2025/02/24 00:54:44 INFO Epoch 0: batch 4180/4180
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0282 
2025/02/24 00:54:44 INFO Epoch 0: batch 4181/4181
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0264 
2025/02/24 00:54:44 INFO Epoch 0: batch 4182/4182
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0358 
2025/02/24 00:54:44 INFO Epoch 0: batch 4183/4183
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0258 
2025/02/24 00:54:44 INFO Epoch 0: batch 4184/4184
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0276 
2025/02/24 00:54:44 INFO Epoch 0: batch 4185/4185
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0261 
2025/02/24 00:54:44 INFO Epoch 0: batch 4186/4186
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0303 
2025/02/24 00:54:44 INFO Epoch 0: batch 4187/4187
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0280 
2025/02/24 00:54:44 INFO Epoch 0: batch 4188/4188
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0245 
2025/02/24 00:54:44 INFO Epoch 0: batch 4189/4189
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0239 
2025/02/24 00:54:44 INFO Epoch 0: batch 4190/4190
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0288 
2025/02/24 00:54:44 INFO Epoch 0: batch 4191/4191
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0281 
2025/02/24 00:54:44 INFO Epoch 0: batch 4192/4192
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0281 
2025/02/24 00:54:44 INFO Epoch 0: batch 4193/4193
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0306 
2025/02/24 00:54:44 INFO Epoch 0: batch 4194/4194
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0264 
2025/02/24 00:54:44 INFO Epoch 0: batch 4195/4195
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0247 
2025/02/24 00:54:44 INFO Epoch 0: batch 4196/4196
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0268 
2025/02/24 00:54:44 INFO Epoch 0: batch 4197/4197
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0212 
2025/02/24 00:54:44 INFO Epoch 0: batch 4198/4198
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0273 
2025/02/24 00:54:44 INFO Epoch 0: batch 4199/4199
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0223 
2025/02/24 00:54:44 INFO Epoch 0: batch 4200/4200
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0318 
2025/02/24 00:54:44 INFO Epoch 0: batch 4201/4201
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0330 
2025/02/24 00:54:44 INFO Epoch 0: batch 4202/4202
2025/02/24 00:54:44 INFO          m 0.00001 
2025/02/24 00:54:44 INFO          Training stage 1 Training_loss 0.0236 
2025/02/24 00:54:45 INFO Epoch 0: batch 4203/4203
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0252 
2025/02/24 00:54:45 INFO Epoch 0: batch 4204/4204
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0232 
2025/02/24 00:54:45 INFO Epoch 0: batch 4205/4205
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0258 
2025/02/24 00:54:45 INFO Epoch 0: batch 4206/4206
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0288 
2025/02/24 00:54:45 INFO Epoch 0: batch 4207/4207
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0332 
2025/02/24 00:54:45 INFO Epoch 0: batch 4208/4208
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0272 
2025/02/24 00:54:45 INFO Epoch 0: batch 4209/4209
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0179 
2025/02/24 00:54:45 INFO Epoch 0: batch 4210/4210
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0245 
2025/02/24 00:54:45 INFO Epoch 0: batch 4211/4211
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0233 
2025/02/24 00:54:45 INFO Epoch 0: batch 4212/4212
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0269 
2025/02/24 00:54:45 INFO Epoch 0: batch 4213/4213
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0266 
2025/02/24 00:54:45 INFO Epoch 0: batch 4214/4214
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0231 
2025/02/24 00:54:45 INFO Epoch 0: batch 4215/4215
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0243 
2025/02/24 00:54:45 INFO Epoch 0: batch 4216/4216
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0199 
2025/02/24 00:54:45 INFO Epoch 0: batch 4217/4217
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0222 
2025/02/24 00:54:45 INFO Epoch 0: batch 4218/4218
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0253 
2025/02/24 00:54:45 INFO Epoch 0: batch 4219/4219
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0206 
2025/02/24 00:54:45 INFO Epoch 0: batch 4220/4220
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0227 
2025/02/24 00:54:45 INFO Epoch 0: batch 4221/4221
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0272 
2025/02/24 00:54:45 INFO Epoch 0: batch 4222/4222
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0220 
2025/02/24 00:54:45 INFO Epoch 0: batch 4223/4223
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0249 
2025/02/24 00:54:45 INFO Epoch 0: batch 4224/4224
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0230 
2025/02/24 00:54:45 INFO Epoch 0: batch 4225/4225
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0197 
2025/02/24 00:54:45 INFO Epoch 0: batch 4226/4226
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0212 
2025/02/24 00:54:45 INFO Epoch 0: batch 4227/4227
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0260 
2025/02/24 00:54:45 INFO Epoch 0: batch 4228/4228
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0209 
2025/02/24 00:54:45 INFO Epoch 0: batch 4229/4229
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0255 
2025/02/24 00:54:45 INFO Epoch 0: batch 4230/4230
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0269 
2025/02/24 00:54:45 INFO Epoch 0: batch 4231/4231
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0226 
2025/02/24 00:54:45 INFO Epoch 0: batch 4232/4232
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0235 
2025/02/24 00:54:45 INFO Epoch 0: batch 4233/4233
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0183 
2025/02/24 00:54:45 INFO Epoch 0: batch 4234/4234
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0256 
2025/02/24 00:54:45 INFO Epoch 0: batch 4235/4235
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0303 
2025/02/24 00:54:45 INFO Epoch 0: batch 4236/4236
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0300 
2025/02/24 00:54:45 INFO Epoch 0: batch 4237/4237
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0231 
2025/02/24 00:54:45 INFO Epoch 0: batch 4238/4238
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0235 
2025/02/24 00:54:45 INFO Epoch 0: batch 4239/4239
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0260 
2025/02/24 00:54:45 INFO Epoch 0: batch 4240/4240
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0279 
2025/02/24 00:54:45 INFO Epoch 0: batch 4241/4241
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0213 
2025/02/24 00:54:45 INFO Epoch 0: batch 4242/4242
2025/02/24 00:54:45 INFO          m 0.00001 
2025/02/24 00:54:45 INFO          Training stage 1 Training_loss 0.0274 
